{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#Download libraries\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_data.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing 5 helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_columns_df(col, key, val):\n",
    "    \"\"\"\n",
    "    This functions takes a dataframe column which is in the\n",
    "    form of list of dictionaries and creates a dataframe\n",
    "    from the keys of the in the inner list of dictionaries \n",
    "    e.g. \"[{'key': A, 'val': 1}, {'key': B, 'val': 2}]\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    col : DataFrame Series, the columns whose values are the in the format\n",
    "    of a list of dictionaries.\n",
    "    \n",
    "    key : the keys in the inner dictionary from which column names are to be extracted\n",
    "    \n",
    "    val : the keys in the inner dictionary from which values in the column needs to\n",
    "    be extracted\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------------\n",
    "    DataFrame\n",
    "        With the new columns created from the keys of the inner dictionary\n",
    "        \n",
    "    \"\"\"\n",
    "    key_list = set()\n",
    "    i=0\n",
    "    # getting all the new column names\n",
    "    while i < len(col):\n",
    "        if type(col[i]) != float:\n",
    "            dic_list = eval(col[i]) #converting col value from string to list\n",
    "            for dic in range(len(dic_list)):\n",
    "                if re.match('[a-zA-Z]', dic_list[dic][str(key)][0]): #removing spanish names\n",
    "                    key_list.add(\"monthly_\"+dic_list[dic][str(key)])\n",
    "        i+=1\n",
    "    \n",
    "    all_cols_dict = defaultdict(list)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(col):\n",
    "        if type(col[i]) != float:\n",
    "            dic_list = eval(col[i]) #converting col value from string to list\n",
    "\n",
    "            for col_names in list(key_list):\n",
    "                flag = 0 #to check if a column name exists in the dictionary\n",
    "                for dic in range(len(dic_list)):\n",
    "                    if dic_list[dic][str(key)] == col_names[8:]: #getting values from the inner dictionary matching the key\n",
    "                        all_cols_dict[col_names].append(dic_list[dic][str(val)]) #putting inner dict values to new default dict\n",
    "                        flag = 1\n",
    "                        break\n",
    "                \n",
    "                if flag==0:\n",
    "                    all_cols_dict[col_names].append(None)\n",
    "\n",
    "        else:\n",
    "            for col_names in list(key_list):\n",
    "                all_cols_dict[col_names].append(None)\n",
    "\n",
    "        i+=1\n",
    "    new_cols_df = pd.DataFrame(all_cols_dict)\n",
    "    \n",
    "    # checking new df has same number of columns as given column\n",
    "    if new_cols_df.shape[0] == col.shape[0]:\n",
    "        return new_cols_df\n",
    "    else:\n",
    "        print(\"Column dimensions don't match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biba_pp(full_data):  \n",
    "    \n",
    "    \"\"\"\n",
    "    Performs the pre-processing of the columns for the biba data\n",
    "    \n",
    "    Paramters\n",
    "    ---------------\n",
    "    \n",
    "    full_data : DataFrame, with no operations done on the biba columns\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    DataFrame\n",
    "        with processed biba columns\n",
    "    \n",
    "    \"\"\"\n",
    "    biba_games_df = pd.DataFrame()\n",
    "    biba_games_df = pd.concat([full_data.loc[:, 'monthly_number_of_sessions':'distance_to_nearest_bus_stop'],\n",
    "                               full_data.loc[:, 'historic_number_of_sessions':'historic_snow']], axis = 1)\n",
    "    \n",
    "    #extracting categorical features\n",
    "    categorical_features = biba_games_df.loc[:, biba_games_df.dtypes == \"object\"]\n",
    "     \n",
    "    # creating cols from list of dictionaries\n",
    "    monthly_survey_df = dict_to_columns_df(categorical_features['monthly_survey'], 'question', 'avg_answer')\n",
    "    monthly_weekday_counts_df = dict_to_columns_df(categorical_features['monthly_weekday_counts'], 'weekday', 'count')\n",
    "    \n",
    "    biba_games_df = pd.concat([biba_games_df, monthly_survey_df, monthly_weekday_counts_df], axis = 1)\n",
    "    \n",
    "    #dropping categorical features\n",
    "    biba_games_df = biba_games_df.drop(columns = list(categorical_features.columns))\n",
    "    \n",
    "    #dropping historic hours with low fill rate\n",
    "    numerical_cols_to_remove = ['historic_hour_0', 'historic_hour_23', 'historic_hour_22', 'historic_hour_21',\n",
    "                                'historic_hour_7','historic_hour_6','historic_hour_5','historic_hour_4', \n",
    "                                'historic_hour_3','historic_hour_2','historic_hour_1', 'MonthYear']\n",
    "    \n",
    "    biba_games_df = biba_games_df.drop(columns = numerical_cols_to_remove)\n",
    "    \n",
    "    impute_biba_games_df =  biba_games_df.fillna(0)\n",
    "    \n",
    "    #removing the previous columns in the input data\n",
    "    cols_to_drop = list(df.loc[:, 'monthly_number_of_sessions': 'distance_to_nearest_bus_stop'].columns) +\\\n",
    "                    list(df.loc[:, 'historic_number_of_sessions' : 'historic_snow'].columns)\n",
    "    \n",
    "    \n",
    "    full_data = full_data.drop(columns = cols_to_drop)\n",
    "    \n",
    "    #adding processed columns\n",
    "    full_data = pd.concat([full_data, impute_biba_games_df], axis = 1)\n",
    "    \n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_neighbour(input_data):\n",
    "    \"\"\"\n",
    "    Given the original dataframe, preprocess the columns\n",
    "    related to locale information (`city` to\n",
    "    `houses_per_sq_km`). Drop columns with >30%\n",
    "    NaN values and replace remaining NaN values with 0.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : pandas.core.frame.DataFrame\n",
    "    Returns\n",
    "    -------\n",
    "    output_data : pandas.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    df_neighbour = input_data.loc[:, 'city':'houses_per_sq_km']\n",
    "    df_neighbour.drop(columns=['climate'])\n",
    "    missing = df_neighbour.isna()\n",
    "    \n",
    "    # Count number of missing values for each column\n",
    "    num_missing = missing.sum().sort_values(ascending=False)\n",
    "    \n",
    "    # Calculate proportion of missing values for each column\n",
    "    prop_missing = num_missing / df.shape[0]\n",
    "    \n",
    "    # Create a list of columns with >30% of values missing\n",
    "    to_drop = prop_missing[prop_missing > 0.3].index.to_list()\n",
    "    \n",
    "    # Add `country` to the list since all playgrounds are in the U.S.\n",
    "    # Add `city` and `county` since lat. and long. should take care of them\n",
    "    to_drop.append('country')\n",
    "    to_drop.append('city')\n",
    "    to_drop.append('county')\n",
    "    \n",
    "    # Drop columns with names in list\n",
    "    output_data = input_data.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Fill in remaining NaN values in locale-related columns with 0\n",
    "    to_impute = prop_missing[(0 < prop_missing) & (prop_missing <= 0.3)].index.to_list()\n",
    "    to_impute.remove('city')\n",
    "    to_impute.remove('county')\n",
    "    output_data[to_impute] = output_data[to_impute].fillna(0)\n",
    "    output_data['climate'] = input_data['climate']\n",
    "\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_weather(input_data):\n",
    "    \"\"\"\n",
    "    Given the original dataframe, preprocess the columns\n",
    "    related to weather information (`Democrats_08_Votes` to\n",
    "    the end + `climate`). Impute NaN of `Number_of_holidays` \n",
    "    by using the values the we have for the same month,\n",
    "    impute NaN of `Green_2016` by using values found online, or 0, \n",
    "    and replace remaining NaN values with 0.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : pandas.core.frame.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output_data : pandas.core.frame.DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_weather = input_data.loc[:, 'Democrats_08_Votes':]\n",
    "    df_weather['state'] = input_data['state']\n",
    "    df_weather['climate'] = input_data['climate']\n",
    "    df_weather['external_id'] = input_data['external_id']\n",
    "    df_weather['month'] = input_data['month']\n",
    "    df_weather['year'] = input_data['year']\n",
    "    \n",
    "    \n",
    "    #fill up NaNs for `Number_of_holidays` column\n",
    "    #I sorted the values so that the values are ordered by time, and the NaNs are at the end of each time period\n",
    "    df_weather = df_weather.sort_values(['month', 'year', 'Number_of_holidays'])\n",
    "    df_weather['Number_of_holidays'] = df_weather['Number_of_holidays'].fillna(method='ffill')\n",
    "    \n",
    "    #fill up NaNs for the `Green_2016` column\n",
    "    #I only found values for Alaska and North Carolina, so I just put 0 for the other states\n",
    "    df_weather['Green_2016'] = np.where(\n",
    "     df_weather['state'] == 'Alaska', 5735, \n",
    "         np.where(\n",
    "            df_weather['state'] == 'North Carolina', 12105,  \n",
    "             np.where(\n",
    "                df_weather['Green_2016'].isnull(), 0, df_weather['Green_2016'] \n",
    "             )\n",
    "         )\n",
    "    )\n",
    "    \n",
    "    df_weather['climate'] = df_weather['climate'].fillna(df_weather['climate'].mode()[0])\n",
    "    \n",
    "    #Substitute every remaining NaNs by 0\n",
    "    df_weather = df_weather.fillna(value=0)\n",
    "    \n",
    "    output_data = input_data.copy()\n",
    "    output_data.loc[:, 'Democrats_08_Votes':] = df_weather.loc[:, 'Democrats_08_Votes':]\n",
    "    output_data['climate'] = df_weather['climate']\n",
    "    \n",
    "    #Tests\n",
    "    \n",
    "    #Check that there are no missing values in the `Number_of_holidays` column\n",
    "    if not output_data['Number_of_holidays'].isnull().sum() == 0:\n",
    "        raise Error('There should not be NaNs in the Number_of_holidays column')\n",
    "    \n",
    "    #Check that every month has only one value for the `Number_of_holiday` column\n",
    "    number_of_error = 0\n",
    "    for month in range(12):\n",
    "        for year in [2018, 2019]:\n",
    "            sub_df = output_data[(output_data['month'] == month+1) & (output_data['year'] == year)]\n",
    "            if len(sub_df['Number_of_holidays'].unique()) > 1:\n",
    "                number_of_error += 1 \n",
    "    if not number_of_error == 0:\n",
    "        raise Error('Every month should have the same value for Number_of_holidays')\n",
    "    \n",
    "    \n",
    "               \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_categorical(input_data, to_drop=['income_class', 'density_class', 'climate']):\n",
    "    \"\"\"\n",
    "    Given the original dataframe, uses One-Hot-Encoding to encode the categorical variables\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : pandas.core.frame.DataFrame\n",
    "    to_drop : list\n",
    "        The list of the categorical variables on which we want to apply OHE\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output_data : pandas.core.frame.DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    output_data = input_data.copy()\n",
    "\n",
    "    #Apply One-Hot-Encoding to each one of the categorical variable\n",
    "    for col in to_drop:\n",
    "        ohe = OneHotEncoder(sparse=False, dtype=int)\n",
    "        sub_df = pd.DataFrame(ohe.fit_transform(input_data[[col]]), columns=ohe.categories_[0])\n",
    "        output_data = pd.concat((output_data, sub_df), axis=1)\n",
    "    #Drop the columns for which we used OHE\n",
    "    output_data.drop(columns = to_drop, inplace=True)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running preprocessing and data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_data.zip')\n",
    "clean_df = preprocess_neighbour(df) \n",
    "clean_df = biba_pp(clean_df)\n",
    "clean_df = preprocess_weather(clean_df)\n",
    "#clean_df.loc[:, clean_df.dtypes == \"object\"].columns\n",
    "clean_df = clean_categorical(clean_df)\n",
    "# filling 0 in 'days_since_first_sess'\n",
    "clean_df['days_since_first_sess'] = clean_df['days_since_first_sess'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df.drop(['unacast_session_count','external_id', 'state'],axis=1)\n",
    "y = clean_df['unacast_session_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_df.drop('unacast_session_count',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_df.columns[clean_df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running single model fit to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=1000, max_depth = 15, min_samples_split = 100, max_features = 0.10, bootstrap = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "tr_time = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.015274806817374"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_time/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37345521902158674"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18648354515924348"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting hyperparameter dictionary for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [1+i*4 for i in range(1,5)]\n",
    "min_samples_leaf = [50+i*50 for i in range(2,8)]\n",
    "max_features = [0.05*i for i in range(1,8)]\n",
    "bootstrap = True\n",
    "max_samples = [0.05*i for i in range(14,21)]\n",
    "d = {\"max_depth\":max_depth, \"min_samples_leaf\":min_samples_leaf, \"max_features\":max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[5, 9, 13, 17], [150, 200, 250, 300, 350, 400], [0.05, 0.1, 0.15000000000000002, 0.2, 0.25, 0.30000000000000004, 0.35000000000000003]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 1\n",
    "for val in d.values():\n",
    "    c *= len(val)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Randomized grid search for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "rf_cv = RandomForestRegressor(n_estimators=750, bootstrap = True)\n",
    "rgscv = RandomizedSearchCV(rf_cv,param_distributions=d,return_train_score=True ,n_iter=15 ,scoring=['neg_root_mean_squared_error'], refit=False)\n",
    "search = rgscv.fit(X, y)\n",
    "t1 = time.time()\n",
    "cv_time = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599.4347654660543"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_time/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting and printing RGSCV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rgscv_results = pd.DataFrame(data=d).sort_values(by='rank_test_neg_root_mean_squared_error')\n",
    "rf_rgscv_results=rf_rgscv_results.iloc[:,:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>split0_test_neg_root_mean_squared_error</th>\n",
       "      <th>split1_test_neg_root_mean_squared_error</th>\n",
       "      <th>split2_test_neg_root_mean_squared_error</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_neg_root_mean_squared_error</th>\n",
       "      <th>std_test_neg_root_mean_squared_error</th>\n",
       "      <th>rank_test_neg_root_mean_squared_error</th>\n",
       "      <th>split0_train_neg_root_mean_squared_error</th>\n",
       "      <th>split1_train_neg_root_mean_squared_error</th>\n",
       "      <th>split2_train_neg_root_mean_squared_error</th>\n",
       "      <th>split3_train_neg_root_mean_squared_error</th>\n",
       "      <th>split4_train_neg_root_mean_squared_error</th>\n",
       "      <th>mean_train_neg_root_mean_squared_error</th>\n",
       "      <th>std_train_neg_root_mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1016.926774</td>\n",
       "      <td>3.763795</td>\n",
       "      <td>0.587974</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13</td>\n",
       "      <td>-464.515447</td>\n",
       "      <td>-302.730338</td>\n",
       "      <td>-629.580331</td>\n",
       "      <td>...</td>\n",
       "      <td>-455.094796</td>\n",
       "      <td>159.378756</td>\n",
       "      <td>1</td>\n",
       "      <td>-481.215124</td>\n",
       "      <td>-512.288838</td>\n",
       "      <td>-433.786685</td>\n",
       "      <td>-435.254739</td>\n",
       "      <td>-519.565405</td>\n",
       "      <td>-476.422158</td>\n",
       "      <td>36.560282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1197.509361</td>\n",
       "      <td>8.609965</td>\n",
       "      <td>0.597603</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>150</td>\n",
       "      <td>0.35</td>\n",
       "      <td>13</td>\n",
       "      <td>-464.434362</td>\n",
       "      <td>-302.716681</td>\n",
       "      <td>-629.421185</td>\n",
       "      <td>...</td>\n",
       "      <td>-455.160011</td>\n",
       "      <td>159.241920</td>\n",
       "      <td>2</td>\n",
       "      <td>-481.438013</td>\n",
       "      <td>-512.404457</td>\n",
       "      <td>-433.465274</td>\n",
       "      <td>-435.162117</td>\n",
       "      <td>-519.539372</td>\n",
       "      <td>-476.401847</td>\n",
       "      <td>36.678772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>773.598454</td>\n",
       "      <td>0.646408</td>\n",
       "      <td>0.293532</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9</td>\n",
       "      <td>-469.116574</td>\n",
       "      <td>-308.985715</td>\n",
       "      <td>-632.902140</td>\n",
       "      <td>...</td>\n",
       "      <td>-460.035437</td>\n",
       "      <td>157.964256</td>\n",
       "      <td>3</td>\n",
       "      <td>-486.421906</td>\n",
       "      <td>-517.017877</td>\n",
       "      <td>-439.159816</td>\n",
       "      <td>-440.049705</td>\n",
       "      <td>-524.077024</td>\n",
       "      <td>-481.345266</td>\n",
       "      <td>36.357245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170.133290</td>\n",
       "      <td>1.544780</td>\n",
       "      <td>0.782840</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>150</td>\n",
       "      <td>0.05</td>\n",
       "      <td>17</td>\n",
       "      <td>-469.553148</td>\n",
       "      <td>-310.363621</td>\n",
       "      <td>-633.059468</td>\n",
       "      <td>...</td>\n",
       "      <td>-460.885842</td>\n",
       "      <td>158.575530</td>\n",
       "      <td>4</td>\n",
       "      <td>-486.676589</td>\n",
       "      <td>-517.196068</td>\n",
       "      <td>-439.685469</td>\n",
       "      <td>-440.214125</td>\n",
       "      <td>-525.015812</td>\n",
       "      <td>-481.757612</td>\n",
       "      <td>36.461703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>326.690148</td>\n",
       "      <td>2.641367</td>\n",
       "      <td>0.684469</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17</td>\n",
       "      <td>-471.175422</td>\n",
       "      <td>-313.376754</td>\n",
       "      <td>-634.705612</td>\n",
       "      <td>...</td>\n",
       "      <td>-462.867679</td>\n",
       "      <td>157.827871</td>\n",
       "      <td>5</td>\n",
       "      <td>-489.015941</td>\n",
       "      <td>-519.653478</td>\n",
       "      <td>-442.311804</td>\n",
       "      <td>-442.694866</td>\n",
       "      <td>-526.770448</td>\n",
       "      <td>-484.089307</td>\n",
       "      <td>36.248093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>626.061902</td>\n",
       "      <td>3.289099</td>\n",
       "      <td>0.294340</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>250</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9</td>\n",
       "      <td>-471.471676</td>\n",
       "      <td>-313.456268</td>\n",
       "      <td>-635.223201</td>\n",
       "      <td>...</td>\n",
       "      <td>-463.548105</td>\n",
       "      <td>157.226865</td>\n",
       "      <td>6</td>\n",
       "      <td>-489.649715</td>\n",
       "      <td>-520.223689</td>\n",
       "      <td>-442.509509</td>\n",
       "      <td>-444.068146</td>\n",
       "      <td>-527.718017</td>\n",
       "      <td>-484.833815</td>\n",
       "      <td>36.243282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>452.836061</td>\n",
       "      <td>2.845391</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>250</td>\n",
       "      <td>0.15</td>\n",
       "      <td>13</td>\n",
       "      <td>-472.613154</td>\n",
       "      <td>-315.706580</td>\n",
       "      <td>-635.963329</td>\n",
       "      <td>...</td>\n",
       "      <td>-464.642483</td>\n",
       "      <td>157.018427</td>\n",
       "      <td>7</td>\n",
       "      <td>-490.870122</td>\n",
       "      <td>-521.446642</td>\n",
       "      <td>-444.231599</td>\n",
       "      <td>-444.534980</td>\n",
       "      <td>-528.691804</td>\n",
       "      <td>-485.955029</td>\n",
       "      <td>36.240060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>297.650893</td>\n",
       "      <td>2.421671</td>\n",
       "      <td>0.532775</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13</td>\n",
       "      <td>-474.514704</td>\n",
       "      <td>-318.194485</td>\n",
       "      <td>-636.889917</td>\n",
       "      <td>...</td>\n",
       "      <td>-466.500964</td>\n",
       "      <td>156.712289</td>\n",
       "      <td>8</td>\n",
       "      <td>-493.145293</td>\n",
       "      <td>-523.082607</td>\n",
       "      <td>-445.983079</td>\n",
       "      <td>-445.964647</td>\n",
       "      <td>-530.364993</td>\n",
       "      <td>-487.708124</td>\n",
       "      <td>36.287801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128.459541</td>\n",
       "      <td>0.376328</td>\n",
       "      <td>0.356902</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>200</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9</td>\n",
       "      <td>-475.063084</td>\n",
       "      <td>-319.331639</td>\n",
       "      <td>-637.667586</td>\n",
       "      <td>...</td>\n",
       "      <td>-467.553307</td>\n",
       "      <td>156.666474</td>\n",
       "      <td>9</td>\n",
       "      <td>-493.409384</td>\n",
       "      <td>-523.399621</td>\n",
       "      <td>-446.763380</td>\n",
       "      <td>-446.792077</td>\n",
       "      <td>-530.814128</td>\n",
       "      <td>-488.235718</td>\n",
       "      <td>36.093540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>557.549278</td>\n",
       "      <td>4.709319</td>\n",
       "      <td>0.420704</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>350</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17</td>\n",
       "      <td>-476.147388</td>\n",
       "      <td>-321.006546</td>\n",
       "      <td>-638.344953</td>\n",
       "      <td>...</td>\n",
       "      <td>-468.683273</td>\n",
       "      <td>155.995321</td>\n",
       "      <td>10</td>\n",
       "      <td>-495.083086</td>\n",
       "      <td>-525.064618</td>\n",
       "      <td>-448.743420</td>\n",
       "      <td>-449.001338</td>\n",
       "      <td>-532.649134</td>\n",
       "      <td>-490.108319</td>\n",
       "      <td>35.936752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>283.391844</td>\n",
       "      <td>3.060726</td>\n",
       "      <td>0.468838</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13</td>\n",
       "      <td>-476.188292</td>\n",
       "      <td>-320.986796</td>\n",
       "      <td>-638.698006</td>\n",
       "      <td>...</td>\n",
       "      <td>-469.151098</td>\n",
       "      <td>156.154999</td>\n",
       "      <td>11</td>\n",
       "      <td>-495.353369</td>\n",
       "      <td>-525.078266</td>\n",
       "      <td>-448.632753</td>\n",
       "      <td>-449.346685</td>\n",
       "      <td>-533.233301</td>\n",
       "      <td>-490.328875</td>\n",
       "      <td>36.032380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>148.148195</td>\n",
       "      <td>1.888351</td>\n",
       "      <td>0.597160</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>250</td>\n",
       "      <td>0.05</td>\n",
       "      <td>17</td>\n",
       "      <td>-477.298112</td>\n",
       "      <td>-323.563505</td>\n",
       "      <td>-639.429293</td>\n",
       "      <td>...</td>\n",
       "      <td>-470.503540</td>\n",
       "      <td>155.748619</td>\n",
       "      <td>12</td>\n",
       "      <td>-496.718256</td>\n",
       "      <td>-526.531755</td>\n",
       "      <td>-450.095449</td>\n",
       "      <td>-449.918645</td>\n",
       "      <td>-534.047731</td>\n",
       "      <td>-491.462367</td>\n",
       "      <td>36.077978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>672.326354</td>\n",
       "      <td>10.626753</td>\n",
       "      <td>0.370686</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>400</td>\n",
       "      <td>0.25</td>\n",
       "      <td>17</td>\n",
       "      <td>-477.084776</td>\n",
       "      <td>-324.416485</td>\n",
       "      <td>-639.249653</td>\n",
       "      <td>...</td>\n",
       "      <td>-470.695897</td>\n",
       "      <td>154.941618</td>\n",
       "      <td>13</td>\n",
       "      <td>-496.387690</td>\n",
       "      <td>-527.362315</td>\n",
       "      <td>-450.321315</td>\n",
       "      <td>-451.156665</td>\n",
       "      <td>-535.437761</td>\n",
       "      <td>-492.133149</td>\n",
       "      <td>36.226472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>272.502183</td>\n",
       "      <td>3.040256</td>\n",
       "      <td>0.451223</td>\n",
       "      <td>0.033719</td>\n",
       "      <td>350</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17</td>\n",
       "      <td>-479.257349</td>\n",
       "      <td>-326.124391</td>\n",
       "      <td>-640.126858</td>\n",
       "      <td>...</td>\n",
       "      <td>-472.389562</td>\n",
       "      <td>154.924291</td>\n",
       "      <td>14</td>\n",
       "      <td>-499.094421</td>\n",
       "      <td>-528.431073</td>\n",
       "      <td>-451.656711</td>\n",
       "      <td>-452.098750</td>\n",
       "      <td>-536.013751</td>\n",
       "      <td>-493.458941</td>\n",
       "      <td>36.121496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>232.522281</td>\n",
       "      <td>2.142132</td>\n",
       "      <td>0.164691</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>350</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>-479.470970</td>\n",
       "      <td>-326.826116</td>\n",
       "      <td>-641.478443</td>\n",
       "      <td>...</td>\n",
       "      <td>-472.798714</td>\n",
       "      <td>154.689245</td>\n",
       "      <td>15</td>\n",
       "      <td>-498.998460</td>\n",
       "      <td>-528.714310</td>\n",
       "      <td>-452.983585</td>\n",
       "      <td>-452.414844</td>\n",
       "      <td>-535.880253</td>\n",
       "      <td>-493.798290</td>\n",
       "      <td>35.764484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1     1016.926774      3.763795         0.587974        0.011191   \n",
       "6     1197.509361      8.609965         0.597603        0.012514   \n",
       "14     773.598454      0.646408         0.293532        0.005846   \n",
       "0      170.133290      1.544780         0.782840        0.004134   \n",
       "10     326.690148      2.641367         0.684469        0.002193   \n",
       "2      626.061902      3.289099         0.294340        0.006392   \n",
       "13     452.836061      2.845391         0.520202        0.003601   \n",
       "12     297.650893      2.421671         0.532775        0.007687   \n",
       "7      128.459541      0.376328         0.356902        0.003815   \n",
       "3      557.549278      4.709319         0.420704        0.003590   \n",
       "11     283.391844      3.060726         0.468838        0.003992   \n",
       "9      148.148195      1.888351         0.597160        0.003507   \n",
       "4      672.326354     10.626753         0.370686        0.006386   \n",
       "8      272.502183      3.040256         0.451223        0.033719   \n",
       "5      232.522281      2.142132         0.164691        0.001930   \n",
       "\n",
       "   param_min_samples_leaf param_max_features param_max_depth  \\\n",
       "1                     150                0.3              13   \n",
       "6                     150               0.35              13   \n",
       "14                    200                0.3               9   \n",
       "0                     150               0.05              17   \n",
       "10                    200                0.1              17   \n",
       "2                     250               0.25               9   \n",
       "13                    250               0.15              13   \n",
       "12                    250                0.1              13   \n",
       "7                     200               0.05               9   \n",
       "3                     350                0.2              17   \n",
       "11                    300                0.1              13   \n",
       "9                     250               0.05              17   \n",
       "4                     400               0.25              17   \n",
       "8                     350                0.1              17   \n",
       "5                     350               0.15               5   \n",
       "\n",
       "    split0_test_neg_root_mean_squared_error  \\\n",
       "1                               -464.515447   \n",
       "6                               -464.434362   \n",
       "14                              -469.116574   \n",
       "0                               -469.553148   \n",
       "10                              -471.175422   \n",
       "2                               -471.471676   \n",
       "13                              -472.613154   \n",
       "12                              -474.514704   \n",
       "7                               -475.063084   \n",
       "3                               -476.147388   \n",
       "11                              -476.188292   \n",
       "9                               -477.298112   \n",
       "4                               -477.084776   \n",
       "8                               -479.257349   \n",
       "5                               -479.470970   \n",
       "\n",
       "    split1_test_neg_root_mean_squared_error  \\\n",
       "1                               -302.730338   \n",
       "6                               -302.716681   \n",
       "14                              -308.985715   \n",
       "0                               -310.363621   \n",
       "10                              -313.376754   \n",
       "2                               -313.456268   \n",
       "13                              -315.706580   \n",
       "12                              -318.194485   \n",
       "7                               -319.331639   \n",
       "3                               -321.006546   \n",
       "11                              -320.986796   \n",
       "9                               -323.563505   \n",
       "4                               -324.416485   \n",
       "8                               -326.124391   \n",
       "5                               -326.826116   \n",
       "\n",
       "    split2_test_neg_root_mean_squared_error  ...  \\\n",
       "1                               -629.580331  ...   \n",
       "6                               -629.421185  ...   \n",
       "14                              -632.902140  ...   \n",
       "0                               -633.059468  ...   \n",
       "10                              -634.705612  ...   \n",
       "2                               -635.223201  ...   \n",
       "13                              -635.963329  ...   \n",
       "12                              -636.889917  ...   \n",
       "7                               -637.667586  ...   \n",
       "3                               -638.344953  ...   \n",
       "11                              -638.698006  ...   \n",
       "9                               -639.429293  ...   \n",
       "4                               -639.249653  ...   \n",
       "8                               -640.126858  ...   \n",
       "5                               -641.478443  ...   \n",
       "\n",
       "    mean_test_neg_root_mean_squared_error  \\\n",
       "1                             -455.094796   \n",
       "6                             -455.160011   \n",
       "14                            -460.035437   \n",
       "0                             -460.885842   \n",
       "10                            -462.867679   \n",
       "2                             -463.548105   \n",
       "13                            -464.642483   \n",
       "12                            -466.500964   \n",
       "7                             -467.553307   \n",
       "3                             -468.683273   \n",
       "11                            -469.151098   \n",
       "9                             -470.503540   \n",
       "4                             -470.695897   \n",
       "8                             -472.389562   \n",
       "5                             -472.798714   \n",
       "\n",
       "    std_test_neg_root_mean_squared_error  \\\n",
       "1                             159.378756   \n",
       "6                             159.241920   \n",
       "14                            157.964256   \n",
       "0                             158.575530   \n",
       "10                            157.827871   \n",
       "2                             157.226865   \n",
       "13                            157.018427   \n",
       "12                            156.712289   \n",
       "7                             156.666474   \n",
       "3                             155.995321   \n",
       "11                            156.154999   \n",
       "9                             155.748619   \n",
       "4                             154.941618   \n",
       "8                             154.924291   \n",
       "5                             154.689245   \n",
       "\n",
       "    rank_test_neg_root_mean_squared_error  \\\n",
       "1                                       1   \n",
       "6                                       2   \n",
       "14                                      3   \n",
       "0                                       4   \n",
       "10                                      5   \n",
       "2                                       6   \n",
       "13                                      7   \n",
       "12                                      8   \n",
       "7                                       9   \n",
       "3                                      10   \n",
       "11                                     11   \n",
       "9                                      12   \n",
       "4                                      13   \n",
       "8                                      14   \n",
       "5                                      15   \n",
       "\n",
       "    split0_train_neg_root_mean_squared_error  \\\n",
       "1                                -481.215124   \n",
       "6                                -481.438013   \n",
       "14                               -486.421906   \n",
       "0                                -486.676589   \n",
       "10                               -489.015941   \n",
       "2                                -489.649715   \n",
       "13                               -490.870122   \n",
       "12                               -493.145293   \n",
       "7                                -493.409384   \n",
       "3                                -495.083086   \n",
       "11                               -495.353369   \n",
       "9                                -496.718256   \n",
       "4                                -496.387690   \n",
       "8                                -499.094421   \n",
       "5                                -498.998460   \n",
       "\n",
       "    split1_train_neg_root_mean_squared_error  \\\n",
       "1                                -512.288838   \n",
       "6                                -512.404457   \n",
       "14                               -517.017877   \n",
       "0                                -517.196068   \n",
       "10                               -519.653478   \n",
       "2                                -520.223689   \n",
       "13                               -521.446642   \n",
       "12                               -523.082607   \n",
       "7                                -523.399621   \n",
       "3                                -525.064618   \n",
       "11                               -525.078266   \n",
       "9                                -526.531755   \n",
       "4                                -527.362315   \n",
       "8                                -528.431073   \n",
       "5                                -528.714310   \n",
       "\n",
       "    split2_train_neg_root_mean_squared_error  \\\n",
       "1                                -433.786685   \n",
       "6                                -433.465274   \n",
       "14                               -439.159816   \n",
       "0                                -439.685469   \n",
       "10                               -442.311804   \n",
       "2                                -442.509509   \n",
       "13                               -444.231599   \n",
       "12                               -445.983079   \n",
       "7                                -446.763380   \n",
       "3                                -448.743420   \n",
       "11                               -448.632753   \n",
       "9                                -450.095449   \n",
       "4                                -450.321315   \n",
       "8                                -451.656711   \n",
       "5                                -452.983585   \n",
       "\n",
       "    split3_train_neg_root_mean_squared_error  \\\n",
       "1                                -435.254739   \n",
       "6                                -435.162117   \n",
       "14                               -440.049705   \n",
       "0                                -440.214125   \n",
       "10                               -442.694866   \n",
       "2                                -444.068146   \n",
       "13                               -444.534980   \n",
       "12                               -445.964647   \n",
       "7                                -446.792077   \n",
       "3                                -449.001338   \n",
       "11                               -449.346685   \n",
       "9                                -449.918645   \n",
       "4                                -451.156665   \n",
       "8                                -452.098750   \n",
       "5                                -452.414844   \n",
       "\n",
       "    split4_train_neg_root_mean_squared_error  \\\n",
       "1                                -519.565405   \n",
       "6                                -519.539372   \n",
       "14                               -524.077024   \n",
       "0                                -525.015812   \n",
       "10                               -526.770448   \n",
       "2                                -527.718017   \n",
       "13                               -528.691804   \n",
       "12                               -530.364993   \n",
       "7                                -530.814128   \n",
       "3                                -532.649134   \n",
       "11                               -533.233301   \n",
       "9                                -534.047731   \n",
       "4                                -535.437761   \n",
       "8                                -536.013751   \n",
       "5                                -535.880253   \n",
       "\n",
       "    mean_train_neg_root_mean_squared_error  \\\n",
       "1                              -476.422158   \n",
       "6                              -476.401847   \n",
       "14                             -481.345266   \n",
       "0                              -481.757612   \n",
       "10                             -484.089307   \n",
       "2                              -484.833815   \n",
       "13                             -485.955029   \n",
       "12                             -487.708124   \n",
       "7                              -488.235718   \n",
       "3                              -490.108319   \n",
       "11                             -490.328875   \n",
       "9                              -491.462367   \n",
       "4                              -492.133149   \n",
       "8                              -493.458941   \n",
       "5                              -493.798290   \n",
       "\n",
       "    std_train_neg_root_mean_squared_error  \n",
       "1                               36.560282  \n",
       "6                               36.678772  \n",
       "14                              36.357245  \n",
       "0                               36.461703  \n",
       "10                              36.248093  \n",
       "2                               36.243282  \n",
       "13                              36.240060  \n",
       "12                              36.287801  \n",
       "7                               36.093540  \n",
       "3                               35.936752  \n",
       "11                              36.032380  \n",
       "9                               36.077978  \n",
       "4                               36.226472  \n",
       "8                               36.121496  \n",
       "5                               35.764484  \n",
       "\n",
       "[15 rows x 22 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rgscv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rgscv_results.to_csv(\"../results/RF_v1_gscv_results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'min_samples_leaf': 150, 'max_features': 0.05, 'max_depth': 17},\n",
       " {'min_samples_leaf': 150,\n",
       "  'max_features': 0.30000000000000004,\n",
       "  'max_depth': 13},\n",
       " {'min_samples_leaf': 250, 'max_features': 0.25, 'max_depth': 9},\n",
       " {'min_samples_leaf': 350, 'max_features': 0.2, 'max_depth': 17},\n",
       " {'min_samples_leaf': 400, 'max_features': 0.25, 'max_depth': 17},\n",
       " {'min_samples_leaf': 350,\n",
       "  'max_features': 0.15000000000000002,\n",
       "  'max_depth': 5},\n",
       " {'min_samples_leaf': 150,\n",
       "  'max_features': 0.35000000000000003,\n",
       "  'max_depth': 13},\n",
       " {'min_samples_leaf': 200, 'max_features': 0.05, 'max_depth': 9},\n",
       " {'min_samples_leaf': 350, 'max_features': 0.1, 'max_depth': 17},\n",
       " {'min_samples_leaf': 250, 'max_features': 0.05, 'max_depth': 17},\n",
       " {'min_samples_leaf': 200, 'max_features': 0.1, 'max_depth': 17},\n",
       " {'min_samples_leaf': 300, 'max_features': 0.1, 'max_depth': 13},\n",
       " {'min_samples_leaf': 250, 'max_features': 0.1, 'max_depth': 13},\n",
       " {'min_samples_leaf': 250,\n",
       "  'max_features': 0.15000000000000002,\n",
       "  'max_depth': 13},\n",
       " {'min_samples_leaf': 200,\n",
       "  'max_features': 0.30000000000000004,\n",
       "  'max_depth': 9}]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_sample_leaf = []\n",
    "# max_features = []\n",
    "# max_depth = []\n",
    "# for i in search.cv_results_['params']:\n",
    "#     min_sample_leaf.append(i['min_sample_leaf'])\n",
    "#     max_features.append(i['max_features'])\n",
    "#     max_depth.append(i['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Preliminary round of modeling with SKlearns RandomForestRegressor to minimize the RMSE (finding the mean)\n",
    "    - MAE minimization in SKlearn's random forest is problmatic due to implementation, which leads to **very** long run times \n",
    "\n",
    "- Input data\n",
    "    - Missing values were mostly imputed with 0s\n",
    "    - Columns with a high proportion of missing values were dropped\n",
    "    \n",
    "- Tuning and optimization\n",
    "    - Assuming that the quality of the random forest increases linearly with the number of trees, a medium-ish number was selected to save time (n=750)\n",
    "    - optomized over `max_depth`, `min_samples_leaf`, and `max_features`. Explnation on each can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "    - train RMSE was generally between 470 to 490, and validation RMSE between 455 and 470, which suggests slight under fitting.\n",
    "    - Generally runs with higher percentage of columns used per tree performed better, however this is expected due to slight undefitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_machine_learning",
   "language": "python",
   "name": "capstone_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
