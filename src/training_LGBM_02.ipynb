{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "\n",
    "# import other functions\n",
    "from imputer import *\n",
    "from feature_eng import *\n",
    "from drop import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "|Model| Test MAE| Test MSE|\n",
    "|-----|---------|---------|\n",
    "| Simple LR | 99.675 | 190.922| \n",
    "| Ridge regression| 99.631 |190.895|\n",
    "| Simple LGBM | 53.161 | 110.994 |\n",
    "| LGBM with Hyperopt gridsearch | 42 | 141 | \n",
    "| LGBM with log transformed y | 51.2 | NA |\n",
    "\n",
    "\n",
    "**Comments :** \n",
    "- Models were run with the new pre-processing and capped target variable \n",
    "- LGBM performance improved slightly after hyperparameter tuning but the bias also increased\n",
    "- Log transforming the target did not seem to have better prediction when transformed back to original scale\n",
    "- The Ridge baseline model seemed to have a big improvement with the new data compared to the previous run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train_data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>monthly_number_of_sessions</th>\n",
       "      <th>monthly_unique_sessions</th>\n",
       "      <th>monthly_repeated_sessions</th>\n",
       "      <th>monthly_avg_length_of_session</th>\n",
       "      <th>monthly_avg_light_activity</th>\n",
       "      <th>monthly_avg_moderate_activity</th>\n",
       "      <th>monthly_avg_vigorous_activity</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_wind_9_10</th>\n",
       "      <th>avg_wind_10_11</th>\n",
       "      <th>avg_wind_11_12</th>\n",
       "      <th>avg_wind_12_above</th>\n",
       "      <th>perfect_days</th>\n",
       "      <th>unacast_session_count</th>\n",
       "      <th>hpi</th>\n",
       "      <th>state_and_local_amount_per_capita</th>\n",
       "      <th>state_amount_per_capita</th>\n",
       "      <th>local_amount_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1804425</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>244.20</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1812706</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1812706</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1812706</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1812706</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  external_id  month  year  monthly_number_of_sessions  \\\n",
       "0     1804425      8  2018                           0   \n",
       "1     1812706      2  2019                           0   \n",
       "2     1812706      3  2019                           0   \n",
       "3     1812706     11  2018                           0   \n",
       "4     1812706      9  2018                           0   \n",
       "\n",
       "   monthly_unique_sessions  monthly_repeated_sessions  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   monthly_avg_length_of_session  monthly_avg_light_activity  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "\n",
       "   monthly_avg_moderate_activity  monthly_avg_vigorous_activity  ...  \\\n",
       "0                            0.0                            0.0  ...   \n",
       "1                            0.0                            0.0  ...   \n",
       "2                            0.0                            0.0  ...   \n",
       "3                            0.0                            0.0  ...   \n",
       "4                            0.0                            0.0  ...   \n",
       "\n",
       "   avg_wind_9_10  avg_wind_10_11  avg_wind_11_12  avg_wind_12_above  \\\n",
       "0            0.0             0.0             0.0                0.0   \n",
       "1            0.0             0.0             0.0                0.0   \n",
       "2            0.0             0.0             0.0                0.0   \n",
       "3            0.0             0.0             0.0                0.0   \n",
       "4            0.0             0.0             0.0                0.0   \n",
       "\n",
       "   perfect_days  unacast_session_count     hpi  \\\n",
       "0           0.0                   90.0  244.20   \n",
       "1           4.0                   27.0  258.95   \n",
       "2           4.0                   27.0  258.95   \n",
       "3           3.0                   24.0  258.95   \n",
       "4           0.0                   12.0  258.95   \n",
       "\n",
       "   state_and_local_amount_per_capita  state_amount_per_capita  \\\n",
       "0                           0.157475                 0.009783   \n",
       "1                           0.157475                 0.009783   \n",
       "2                           0.157475                 0.009783   \n",
       "3                           0.157475                 0.009783   \n",
       "4                           0.157475                 0.009783   \n",
       "\n",
       "   local_amount_per_capita  \n",
       "0                 0.147692  \n",
       "1                 0.147692  \n",
       "2                 0.147692  \n",
       "3                 0.147692  \n",
       "4                 0.147692  \n",
       "\n",
       "[5 rows x 861 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows missing target variable\n",
    "df = drop_missing_unacast(df)\n",
    "\n",
    "# create X and y\n",
    "X = df.drop(columns = ['unacast_session_count'], axis=1)\n",
    "y = df.loc[:, 'unacast_session_count']\n",
    "# split the data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                      random_state=2020)\n",
    "# impute NaN values\n",
    "result = impute_data(X_train, X_valid)\n",
    "X_train = result[0]\n",
    "X_valid = result[1] \n",
    "# perform feature eng\n",
    "X_train = comb_cols(X_train)\n",
    "X_valid = comb_cols(X_valid)\n",
    "# perform dropping\n",
    "X_train = drop_columns(X_train)\n",
    "X_valid = drop_columns(X_valid)\n",
    "\n",
    "# perform OHE (climate, density_class, income_class)\n",
    "X_train_valid = clean_categorical(X_train, X_valid)\n",
    "X_train = X_train_valid[0]\n",
    "X_valid = X_train_valid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scores(model, X, y, error = 'mse'):\n",
    "    \"\"\"\n",
    "    Shows the mean squared error and mean absolute error for a given model\n",
    "    and predictors and response\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: The sklearn model object\n",
    "    X: numpy.ndarray        \n",
    "        The predictors(independent variables) part of the data\n",
    "    y: numpy.ndarray\n",
    "        The response(target variable)of the data\n",
    "    error: string,\n",
    "        'mse' or 'mae' depending upon the type of error\n",
    "        we are interested in\n",
    "        \n",
    "    Returns\n",
    "    ------- \n",
    "    \"\"\"            \n",
    "    y_preds = model.predict(X)\n",
    "    \n",
    "    if error == 'mse':\n",
    "        rmse = mean_squared_error(y, y_preds, squared = False)\n",
    "        print(\"Root mean squared error: %0.3f\" % rmse)\n",
    "        return\n",
    "    if error == 'mae':\n",
    "        mae = mean_absolute_error(y, y_preds)\n",
    "        print(\"Mean absolute error: %0.3f\" % mae)\n",
    "        return\n",
    "    else:\n",
    "        print(\"Wrong choice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39592, 632)\n",
      "(9898, 632)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple linear regression scores: \n",
      "Train error: \n",
      "Root mean squared error: 182.973\n",
      "Test error: \n",
      "Root mean squared error: 190.922\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('Simple linear regression scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(lr, X_train, y_train, 'mse')\n",
    "\n",
    "print('Test error: ')    \n",
    "show_scores(lr, X_valid, y_valid, 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: \n",
      "Mean absolute error: 96.979\n",
      "Test error: \n",
      "Mean absolute error: 99.675\n"
     ]
    }
   ],
   "source": [
    "print('Train error: ')\n",
    "show_scores(lr, X_train, y_train, 'mae')\n",
    "\n",
    "print('Test error: ')    \n",
    "show_scores(lr, X_valid, y_valid, 'mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations \n",
    "- Better than last run. Proabably due to improved target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ridge L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\.virtualenvs\\capstone_machine_learning-a37y-TX3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.07072e-20): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression scores: \n",
      "Train error: \n",
      "Root mean squared error: 182.989\n",
      "Test error: \n",
      "Root mean squared error: 190.895\n"
     ]
    }
   ],
   "source": [
    "ridge_lr = Ridge(max_iter=2000, random_state = 2020)\n",
    "ridge_lr.fit(X_train, y_train)\n",
    "print('Ridge regression scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(ridge_lr, X_train, y_train)\n",
    "\n",
    "print('Test error: ')    \n",
    "show_scores(ridge_lr, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: \n",
      "Mean absolute error: 96.934\n",
      "Test error: \n",
      "Mean absolute error: 99.631\n"
     ]
    }
   ],
   "source": [
    "print('Train error: ')\n",
    "show_scores(ridge_lr, X_train, y_train, 'mae')\n",
    "\n",
    "print('Test error: ')    \n",
    "show_scores(ridge_lr, X_valid, y_valid, 'mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- Same as LR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM on this data with Mean objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM scores: \n",
      "Train error: \n",
      "Root mean squared error: 89.408\n",
      "Test error: \n",
      "Root mean squared error: 110.994\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(random_state = 2020)\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "print('LGBM scores: ')\n",
    "\n",
    "print('Train error: ')\n",
    "show_scores(lgbm, X_train, y_train)\n",
    "\n",
    "print('Test error: ')\n",
    "show_scores(lgbm, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing grid search with LGBM - time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'max_depth' : [100, 500], 'n_estimators' : [100, 200] }\n",
    "\n",
    "# lgbm = LGBMRegressor(random_state = 2020)\n",
    "\n",
    "# mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "# clf_lgbm = GridSearchCV(lgbm, params, scoring = mae_scorer, n_jobs = 16)\n",
    "\n",
    "# clf_lgbm.fit(X_train, y_train)\n",
    "# print('LGBM scores: ')\n",
    "# print('Train error: ')\n",
    "# show_scores(clf_lgbm, X_train, y_train)\n",
    "\n",
    "# print('Test error: ')\n",
    "# show_scores(clf_lgbm, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_lgbm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using hyperopt - run on AWS EC2 only - time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# # File to save first results\n",
    "# out_file = '../results/lgbm_trials.csv'\n",
    "# of_connection = open(out_file, 'w')\n",
    "# writer = csv.writer(of_connection)\n",
    "\n",
    "# # Write the headers to the file\n",
    "# writer.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time'])\n",
    "# of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from hyperopt import STATUS_OK\n",
    "# from hyperopt import hp\n",
    "# from hyperopt import tpe\n",
    "# from hyperopt import Trials\n",
    "# from hyperopt import fmin\n",
    "# import time\n",
    "\n",
    "# MAX_EVALS = 500\n",
    "\n",
    "# N = 5\n",
    "\n",
    "# # Create the dataset\n",
    "# train_set = lgb.Dataset(X_train, y_train)\n",
    "# iteration = 0\n",
    "# start = time.time()\n",
    "\n",
    "# def objective(params, n_folds = N):\n",
    "    \n",
    "#     global iteration\n",
    "    \n",
    "#     params['objective'] = 'regression'\n",
    "#     print(params)\n",
    "#     cv_results = lgb.cv(params, train_set, nfold = N, stratified=False,\n",
    "#                         early_stopping_rounds = 100, metrics = 'mae', seed = 50)\n",
    "    \n",
    "#     loss = max(cv_results['l1-mean'])\n",
    "    \n",
    "#     # computing runtime\n",
    "#     run_time = time.time() - start\n",
    "    \n",
    "#     # Boosting rounds that returned the highest cv score\n",
    "#     n_estimators = int(np.argmax(cv_results['l1-mean']) + 1)\n",
    "\n",
    "#     # Write to the csv file ('a' means append)\n",
    "#     out_file = '../results/lgbm_trials.csv'\n",
    "#     of_connection = open(out_file, 'a')\n",
    "#     writer = csv.writer(of_connection)\n",
    "#     writer.writerow([loss, params, iteration, n_estimators, run_time])\n",
    "#     of_connection.close()\n",
    "    \n",
    "#     iteration+=1\n",
    "#     # Dictionary with information for evaluation\n",
    "#     return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "# space = {\n",
    "#     'boosting_type': hp.choice('boosting_type',['gbdt', 'dart', 'goss']),\n",
    "#     'num_leaves': hp.choice('num_leaves', [50, 70, 100, 150, 200, 300]),\n",
    "#     'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "#     'max_dept': hp.quniform('max_dept', 50, 200, 5)\n",
    "# }\n",
    "\n",
    "# # Algorithm\n",
    "# tpe_algorithm = tpe.suggest\n",
    "\n",
    "# # Trials object to track progress\n",
    "# bayes_trials = Trials()\n",
    "\n",
    "# # Optimize\n",
    "# best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "#             max_evals = MAX_EVALS, trials = bayes_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression_opts = dict(method='zip',archive_name='out.csv')  \n",
    "# df_lgbm.to_csv(\"../results/lgbm_trials.zip\", index = False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>params</th>\n",
       "      <th>iteration</th>\n",
       "      <th>estimators</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.060126</td>\n",
       "      <td>{'boosting_type': 'goss', 'learning_rate': 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45.307489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.200140</td>\n",
       "      <td>{'boosting_type': 'goss', 'learning_rate': 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60.516712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.636390</td>\n",
       "      <td>{'boosting_type': 'goss', 'learning_rate': 0.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>89.212210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118.014573</td>\n",
       "      <td>{'boosting_type': 'goss', 'learning_rate': 0.0...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>120.791389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118.656670</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'learning_rate': 0.0...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>165.154807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss                                             params  iteration  \\\n",
       "0  119.060126  {'boosting_type': 'goss', 'learning_rate': 0.0...          0   \n",
       "1  120.200140  {'boosting_type': 'goss', 'learning_rate': 0.0...          1   \n",
       "2  116.636390  {'boosting_type': 'goss', 'learning_rate': 0.0...          2   \n",
       "3  118.014573  {'boosting_type': 'goss', 'learning_rate': 0.0...          3   \n",
       "4  118.656670  {'boosting_type': 'gbdt', 'learning_rate': 0.0...          4   \n",
       "\n",
       "   estimators  train_time  \n",
       "0           1   45.307489  \n",
       "1           1   60.516712  \n",
       "2           1   89.212210  \n",
       "3           1  120.791389  \n",
       "4           1  165.154807  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgbm = pd.read_csv('../results/lgbm_trials.zip')\n",
    "df_lgbm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM on this data with Median objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM scores: \n",
      "Train error: \n",
      "Mean absolute error: 49.819\n",
      "Test error: \n",
      "Mean absolute error: 53.161\n"
     ]
    }
   ],
   "source": [
    "#fitting lgbm with MAE without scaling\n",
    "lgbm = LGBMRegressor(objective = 'mae', random_state = 2020)\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "print('LGBM scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(lgbm, X_train, y_train, 'mae')\n",
    "\n",
    "print('Test error: ')\n",
    "show_scores(lgbm, X_valid, y_valid, 'mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM with log transformed target and Median objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3MAAAF1CAYAAABCj7NOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dfbjmdV0n8PcnRg0f00DDgRxsqUR20yKWzauNTSuVStvNxK2gskVdTSv30sHaza2o6VqzslIX03yoRFJLCkzNsnLzodEsBaQIRhghGXxI1FLBz/5x/4buOZyZOXPO4dzzPfN6Xdd9zX1/f0+f3wNc9/t8f7/vXd0dAAAAxvJFiy4AAACAQyfMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOYD9qKoXV9X/XKd1fXlVfaqqjpo+v62qfng91j2t741Vdc56re8QtvuzVXVTVf3jMtPOqKrdG13TRjjQfi/ael9bI6uqb6yqK1c47w9U1dsPMN1xBQ47whxwRKqqXVX1z1V1c1V9oqr+sqqeXFW3/X+xu5/c3T+zwnU94kDzdPe13X337r51HWp/blX91pL1P6q7X7HWdR9iHSckeWaSk7v7yzZ42y+vqp/dyG3ObXth+71Wy107m3n73f0X3f1VG7U9gI0mzAFHsu/o7nskeUCSHUmeneSl672Rqtqy3us8TDwgyUe7+8ZFF7LUHXzMV73fo18LI9U/Uq0AqyXMAUe87v6n7r44yeOTnFNVpyT79v5U1TFV9YdTL97HquovquqLqupVSb48yR9Mt1E+q6q2VVVX1ROr6tokfzLXNv8F8yuq6t1V9U9V9Yaqus+0rdvdnri396+qHpnkOUkeP23vb6bpt90CNtX1k1X1oaq6sapeWVX3mqbtreOcqrp2ulXwJ/Z3bKrqXtPye6b1/eS0/kckeUuS+091vPxgx7mqHjTV+YmquqyqvnNu2pdW1R9U1Ser6q+m2xiXveWtqs5N8r1JnjVt+w/mjtGzq+pvk3y6qrZU1faq+oepB/byqvquufX8QFW9vaqeV1Ufr6prqupRS6ZfPS17TVV97/72u6q+c9qnT0z7+KAl526+rn8znYMfrKrrpm0/uaq+vqr+dlrHry3Z5x+qqiumed9UVQ+Ym/YtVfXB6Tr6tSS1n+O2v2vnB6d13zzt75PmljmjqnZP9f9jkt+sqqOr6hVTLVdM1/zuuWXuX1Wvm66Za6rq6Qfa/pIat1fVa5e0/UpVvWCVtZ6xpLb9Xg//Okv96nQsP1hVD1/uWB7snABsmO728vLyOuJeSXYlecQy7dcmecr0/uVJfnZ6//NJXpzkTtPrG5PUcutKsi1JJ3llkrslOXqubcs0z9uSfDjJKdM8r0vyW9O0M5Ls3l+9SZ67d9656W9L8sPT+x9KclWSBya5e5LXJ3nVktpeMtX1NUk+m+RB+zlOr0zyhiT3mJb9uyRP3F+dS5a9bfp0zK7K7Mv8nZN8c5Kbk3zVNP3C6XXXJCcnuS7J2w+w7tvOzZJj9L4kJyQ5emp7XJL7Z/bHy8cn+XSS46ZpP5Dk80n+W5KjkjwlyfWZhaG7JfnkXH3HJXnwcvud5Cun9X7LtJ/Pmvb1zsvVNXcOXpzki5N8a5J/SfL7Se6bZGuSG5N807T8Y6f1PSjJliQ/meQvp2nHTHV+97TtH0tyy95rYZnj9tzc/to5M8lXTPv9TUk+k+Rr5/b1liS/kOQuU/07kvxZknsnOT7J386d5y9K8p4k/2s6zw9McnWSb9vf9pfU8oBp+/ecPh+V5IYkp6+y1qXn6mDXwy3TMbzTNP2fktxnmf/G9ntOvLy8vDbypWcOYF/XJ7nPMu2fz+wL/QO6+/M9exanD7Ku53b3p7v7n/cz/VXd/YHu/nSS/5nke2oaIGWNvjfJ87v76u7+VJLzkpxV+/YK/u/u/ufu/pskf5NZqNvHVMvjk5zX3Td3964kv5jk+1dR0+mZBcsd3f257v6TJH+Y5AnTdv5Lkp/q7s909+VJVvv83wu6+7q9x7y7f7e7r+/uL3T3a5L8fZLT5ub/UHe/pGfPMr4is3N8v2naF5KcUlVHd/cN3X3Zfrb5+CSXdPdbuvvzSZ6XWZD4hv3VNfmZ7v6X7n5zZqHi1d19Y3d/OMlfJHnoNN+Tkvx8d1/R3bck+bkkD5l6gh6d5PLufu207V9OckiDsnT3Jd39Dz3zZ0nenNkfK/b6Qmbn5rNT/d+T5Oe6++PdvTvJC+bm/fokx3b3T0/n+erM/nBw1gpr+VCS92YWlpJZ6P9Md79zlbUuXf/Brocbk/zy9N/4a5JcmVmAXOpA5wRgwwhzAPvamuRjy7T/n8z+Ev/m6fau7StY13WHMP1DmfUGHLOiKg/s/tP65te9Jf8aUpJ9v/B/JrOgtdQxmfWuLF3X1lXWdF13f2GZdR071Td/PG57X1XPmW7L+1RVvfgg29nnmFfV2VX1vunWxU9k1hM6f4xvOw7d/Znp7d2ngP34JE9OckNVXVJVX32AfbvtGE37eF32PU7LXQsfmXv/z8t83ntOHpDkV+b24WOZ9UxtnbZ927qnPzAc7LrbR1U9qqreWbPbhz+RWUCcP0Z7uvtf5j7vs80l7x+Q2S2on5ir9znZ99o7mN9J8oTp/X+dPq+21n2s4Hr48JI/0nwos/1d6kDnBGDDCHMAk6r6+sy+jN3uWa2pZ+qZ3f3AJN+R5MfnnqfZXw/dwXruTph7/+WZ9f7dlFkvzV3n6joqs8Cz0vVen9mXzfl135J9w8JK3DTVtHRdHz7E9eyt6YSaGy10bl17pvqOn5t227Hp7p/r2Uigd+/uJ+9t3s92bmufeklekuRpSb60u78kyQeyn2fKbrei7jd197dk1lv3wWld+9u3+WfYaqp//jgd7JwdyHVJntTdXzL3Orq7/zKzWxBvO1Zz296ffeqoqrtkdovv85LcbzpGl2bfY7S09huyn3M11XrNklrv0d2P3s+6lvO7Sc6oquOTfFemMLfKWuf3dSXXw9bpGO715Zmd36UOdE4ANowwBxzxquqeVfXtmT2z9Vvd/f5l5vn2mg1cUZk9o3Tr9EpmIemBq9j091XVyVV11yQ/neS10+1+f5fki6vqzKq6U2bP49xlbrmPJNm2JBjNe3WSH6uqE6vq7pndAvaa6XawFZtquSjJ+VV1j+nL8I8nWc3Q8u/KLKQ+q6ruVFVnZBaKL5y28/okz62qu049YGcfZH0rOeZ3y+zL/Z5kNnhGZj0xB1VV96vZoCZ3y+yZwk/lX8/3UhclObOqHj6dr2dOy6zXF/sXJzmvqh481XavqnrcNO2SJA+uqv883Ub79CQH+rmEpdfOnTO7tvYkuaVmA8B860HquWiq595VtTWzcLTXu5N8chqE5OiqOqqqTpn+ULLc9m+nu/dk9nzab2YWDK9YQ63zVnI93DfJ06dr9HGZPRN36TLrOtA5AdgwwhxwJPuDqro5s7+y/0SS5yf5wf3Me1KSP87sS/07krywu982Tfv5JD853XL1Pw5h+6/KbCCPf8xsIIynJ7PRNZP89yS/kVnvzqeTzI9u+bvTvx+tqvcus96XTev+8yTXZDa4xo8cQl3zfmTa/tWZ9Vj+zrT+Q9Ldn0vynUkelVmP3wuTnN3dH5xmeVqSe2V2LF6VWSD97AFW+dIkJ0/H/Pf3s83LM3vG7x2ZhYh/m+T/rbDkL8oslF2f2S1035TZOVluO1cm+b4kvzrt23dk9rMXn1vhtg6ou38vs0E9LqyqT2bWm/SoadpNmQ3qsSPJRzO7Tg+0j/tcO919c2bX3UVJPp7ZbY0XH6Skn87serwms/8mXpvpXE3B/DuSPGSaflNm1/G9ltv+AbbxO0kekblbLFdZ621WeD28K7NjeFOS85N8d3d/dJl17fecAGykvSOxAcBho6p+IcmXdfc5i66FA6uqpyQ5q7u/adG1ABxp9MwBsHBV9dVV9e9q5rQkT0zye4uui9urquOq6mE1+73Br8qsB9O5AliALQefBQDucPfI7NbK+2c2PPwvZvb7dhx+7pzk/yY5McknMnvW9IULrQjgCOU2SwAAgAG5zRIAAGBAwhwAAMCADvtn5o455pjetm3bossAAABYiPe85z03dfexS9sP+zC3bdu27Ny5c9FlAAAALERVfWi5drdZAgAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAtiy6AADYrLZtv2RNy+/aceY6VQLAZqRnDgAAYEB65gDY9NbSQ6Z3DIDDlZ45AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxoy6ILAIDD2bbtlyy6BABYlp45AACAAQlzAAAAAxLmAAAABuSZOQCG4Nk1ANiXMAcAh6m1BNhdO85cx0oAOBy5zRIAAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADOigYa6qTqiqP62qK6rqsqp6xtT+3Kr6cFW9b3o9em6Z86rqqqq6sqq+ba7966rq/dO0F1RV3TG7BQAAsLltWcE8tyR5Zne/t6rukeQ9VfWWadovdffz5meuqpOTnJXkwUnun+SPq+oru/vWJC9Kcm6Sdya5NMkjk7xxfXYFAADgyHHQnrnuvqG73zu9vznJFUm2HmCRxyS5sLs/293XJLkqyWlVdVySe3b3O7q7k7wyyWPXvAcAAABHoJX0zN2mqrYleWiSdyV5WJKnVdXZSXZm1nv38cyC3jvnFts9tX1+er+0HYAjxLbtlyy6BADYNFY8AEpV3T3J65L8aHd/MrNbJr8iyUOS3JDkF/fOuszifYD25bZ1blXtrKqde/bsWWmJAAAAR4wVhbmqulNmQe63u/v1SdLdH+nuW7v7C0lekuS0afbdSU6YW/z4JNdP7ccv03473X1Bd5/a3acee+yxh7I/AAAAR4SVjGZZSV6a5Irufv5c+3Fzs31Xkg9M7y9OclZV3aWqTkxyUpJ3d/cNSW6uqtOndZ6d5A3rtB8AAABHlJU8M/ewJN+f5P1V9b6p7TlJnlBVD8nsVsldSZ6UJN19WVVdlOTyzEbCfOo0kmWSPCXJy5McndkolkayBAAAWIWDhrnufnuWf97t0gMsc36S85dp35nklEMpEAAAgNs7pNEsATiyGY0SAA4fKx7NEgAAgMOHMAcAADAgYQ4AAGBAnpkDgE1oLc837tpx5jpWAsAdRc8cAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgLYsugAANta27ZcsugQOc2u5RnbtOHMdKwHgQPTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADOmiYq6oTqupPq+qKqrqsqp4xtd+nqt5SVX8//XvvuWXOq6qrqurKqvq2ufavq6r3T9NeUFV1x+wWAADA5raSnrlbkjyzux+U5PQkT62qk5NsT/LW7j4pyVunz5mmnZXkwUkemeSFVXXUtK4XJTk3yUnT65HruC8AAABHjC0Hm6G7b0hyw/T+5qq6IsnWJI9JcsY02yuSvC3Js6f2C7v7s0muqaqrkpxWVbuS3LO735EkVfXKJI9N8sZ13B8AYIG2bb9kTcvv2nHmOlUCsPkd0jNzVbUtyUOTvCvJ/aagtzfw3XeabWuS6+YW2z21bZ3eL21fbjvnVtXOqtq5Z8+eQykRAADgiLDiMFdVd0/yuiQ/2t2fPNCsy7T1Adpv39h9QXef2t2nHnvssSstEQAA4IixojBXVXfKLMj9dne/fmr+SFUdN00/LsmNU/vuJCfMLX58kuun9uOXaQcAAOAQrWQ0y0ry0iRXdPfz5yZdnOSc6f05Sd4w135WVd2lqk7MbKCTd0+3Yt5cVadP6zx7bhkAAAAOwUEHQEnysCTfn+T9VfW+qe05SXYkuaiqnpjk2iSPS5LuvqyqLkpyeWYjYT61u2+dlntKkpcnOTqzgU8MfgIAALAKKxnN8u1Z/nm3JHn4fpY5P8n5y7TvTHLKoRQIAADA7R3SaJYAAAAcHoQ5AACAAa3kmTkA7gBr/XFlAODIpmcOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAPasugCAAD22rb9klUvu2vHmetYCcDhT88cAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADOigYa6qXlZVN1bVB+banltVH66q902vR89NO6+qrqqqK6vq2+bav66q3j9Ne0FV1frvDgAAwJFhJT1zL0/yyGXaf6m7HzK9Lk2Sqjo5yVlJHjwt88KqOmqa/0VJzk1y0vRabp0AAACswEHDXHf/eZKPrXB9j0lyYXd/truvSXJVktOq6rgk9+zud3R3J3llkseutmgAAIAj3Vp+NPxpVXV2kp1JntndH0+yNck75+bZPbV9fnq/tB1gWGv5cWMAgLVa7QAoL0ryFUkekuSGJL84tS/3HFwfoH1ZVXVuVe2sqp179uxZZYkAAACb16rCXHd/pLtv7e4vJHlJktOmSbuTnDA36/FJrp/aj1+mfX/rv6C7T+3uU4899tjVlAgAALCprSrMTc/A7fVdSfaOdHlxkrOq6i5VdWJmA528u7tvSHJzVZ0+jWJ5dpI3rKFuAACAI9pBn5mrqlcnOSPJMVW1O8lPJTmjqh6S2a2Su5I8KUm6+7KquijJ5UluSfLU7r51WtVTMhsZ8+gkb5xeAAAArMJBw1x3P2GZ5pceYP7zk5y/TPvOJKccUnUAAAAsa7UDoAAAALBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABrRl0QUAAKyHbdsvWfWyu3acuY6VAGwMPXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQFsWXQDAWm3bfsmql92148x1rAQAYOMIc8C6GTFUraVmAIBFOmiYq6qXJfn2JDd29ylT232SvCbJtiS7knxPd398mnZekicmuTXJ07v7TVP71yV5eZKjk1ya5Bnd3eu7O8CohCpgkUb8YxTASp6Ze3mSRy5p257krd19UpK3Tp9TVScnOSvJg6dlXlhVR03LvCjJuUlOml5L1wkAAMAKHTTMdfefJ/nYkubHJHnF9P4VSR47135hd3+2u69JclWS06rquCT37O53TL1xr5xbBgAAgEO02tEs79fdNyTJ9O99p/atSa6bm2/31LZ1er+0fVlVdW5V7ayqnXv27FlliQAAAJvXev80QS3T1gdoX1Z3X9Ddp3b3qccee+y6FQcAALBZrDbMfWS6dTLTvzdO7buTnDA33/FJrp/aj1+mHQAAgFVYbZi7OMk50/tzkrxhrv2sqrpLVZ2Y2UAn755uxby5qk6vqkpy9twyAAAAHKKV/DTBq5OckeSYqtqd5KeS7EhyUVU9Mcm1SR6XJN19WVVdlOTyJLckeWp33zqt6in5158meOP0AgAAYBUOGua6+wn7mfTw/cx/fpLzl2nfmeSUQ6oOAACAZa33ACgAAABsAGEOAABgQMIcAADAgIQ5AACAAQlzAAAAAxLmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAPasugCAABGtm37JatedteOM9exEuBIo2cOAABgQMIcAADAgIQ5AACAAXlmDgBgQdbyvF3imTs40umZAwAAGJAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAhDkAAIABbVl0AQAArM627ZesetldO85cx0qARdAzBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADAgYQ4AAGBAwhwAAMCAtiy6AAAANt627ZesetldO85cx0qA1dIzBwAAMKA19cxV1a4kNye5Nckt3X1qVd0nyWuSbEuyK8n3dPfHp/nPS/LEaf6nd/eb1rJ9OJz5iycAAHek9bjN8j91901zn7cneWt376iq7dPnZ1fVyUnOSvLgJPdP8sdV9ZXdfes61LDhfFEHAAAW6Y54Zu4xSc6Y3r8iyduSPHtqv7C7P5vkmqq6KslpSd5xB9TAJnIkBucjcZ8BADg0a31mrpO8uareU1XnTm336+4bkmT6975T+9Yk180tu3tqu52qOreqdlbVzj179qyxRAAAgM1nrT1zD+vu66vqvkneUlUfPMC8tUxbLzdjd1+Q5IIkOfXUU5edB+5oa+kdW6RR6wYA4NCsKcx19/XTvzdW1e9ldtvkR6rquO6+oaqOS3LjNPvuJCfMLX58kuvXsn02llv/AADg8LHq2yyr6m5VdY+975N8a5IPJLk4yTnTbOckecP0/uIkZ1XVXarqxCQnJXn3arcPAABwJFtLz9z9kvxeVe1dz+909x9V1V8luaiqnpjk2iSPS5LuvqyqLkpyeZJbkjx11JEsAQAAFm3VYa67r07yNcu0fzTJw/ezzPlJzl/tNgEAAJhZ62iWAAAALIAwBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQMAcAADCgLYsuAACAsWzbfsmql92148x1rASObHrmAAAABiTMAQAADEiYAwAAGJAwBwAAMCBhDgAAYEDCHAAAwID8NAEAABvGzxrA+tEzBwAAMCBhDgAAYEDCHAAAwICEOQAAgAEJcwAAAAMS5gAAAAYkzAEAAAxImAMAABiQHw0HAGAIa/nB8cSPjrP56JkDAAAYkDAHAAAwIGEOAABgQMIcAADAgIQ5AACAAQlzAAAAA/LTBAAAHBHW8tMGftZg4zhPK6dnDgAAYEDCHAAAwIDcZgkAAAfh1j8OR8IcAAAcptYSIhNBcrMT5gAA4A601kAG++OZOQAAgAEJcwAAAANymyUAAHA7Bn05/AlzAACwSS3qeT3PCW4Mt1kCAAAMSJgDAAAY0IaHuap6ZFVdWVVXVdX2jd4+AADAZrChYa6qjkry60keleTkJE+oqpM3sgYAAIDNYKN75k5LclV3X93dn0tyYZLHbHANAAAAw9vo0Sy3Jrlu7vPuJP9+g2sAAAA2obWOojnaTypsdJirZdr6djNVnZvk3Onjp6rqyju0qtU5JslNq1mwfmGdKxnAovb5SDzW62DV1zYMwPXNZuXaZjPbsOv7MP7u+IDlGjc6zO1OcsLc5+OTXL90pu6+IMkFG1XUalTVzu4+ddF1wHpzbbOZub7ZrFzbbGau7/3b6Gfm/irJSVV1YlXdOclZSS7e4BoAAACGt6E9c919S1U9LcmbkhyV5GXdfdlG1gAAALAZbPRtlunuS5NcutHbvQMc1reBwhq4ttnMXN9sVq5tNjPX935U9+3GHwEAAOAwt9HPzAEAALAOhLlDVFWPrKorq+qqqtq+6HpgvVTVCVX1p1V1RVVdVlXPWHRNsJ6q6qiq+uuq+sNF1wLrqaq+pKpeW1UfnP4f/h8WXROsh6r6sek7yQeq6tVV9cWLrulwI8wdgqo6KsmvJ3lUkpOTPKGqTl5sVbBubknyzO5+UJLTkzzV9c0m84wkVyy6CLgD/EqSP+rur07yNXGdswlU1dYkT09yanefktngiWcttqrDjzB3aE5LclV3X93dn0tyYZLHLLgmWBfdfUN3v3d6f3NmXwa2LrYqWB9VdXySM5P8xqJrgfVUVfdM8h+TvDRJuvtz3f2JxVYF62ZLkqOrakuSu2aZ36c+0glzh2ZrkuvmPu+OL7tsQlW1LclDk7xrsZXAuvnlJM9K8oVFFwLr7IFJ9iT5zek24t+oqrstuihYq+7+cJLnJbk2yQ1J/qm737zYqg4/wtyhqWXaDAfKplJVd0/yuiQ/2t2fXHQ9sFZV9e1Jbuzu9yy6FrgDbEnytUle1N0PTfLpJJ7pZ3hVde/M7oA7Mcn9k9ytqr5vsVUdfoS5Q7M7yQlzn4+P7l42kaq6U2ZB7re7+/WLrgfWycOSfGdV7crs9vhvrqrfWmxJsG52J9nd3XvvpHhtZuEORveIJNd0957u/nyS1yf5hgXXdNgR5g7NXyU5qapOrKo7Z/YQ5sULrgnWRVVVZs9cXNHdz190PbBeuvu87j6+u7dl9v/tP+luf91lU+juf0xyXVV91dT08CSXL7AkWC/XJjm9qu46fUd5eP9Vx0sAAACWSURBVAzucztbFl3ASLr7lqp6WpI3ZTaizsu6+7IFlwXr5WFJvj/J+6vqfVPbc7r70gXWBMDB/UiS357+0Hx1kh9ccD2wZt39rqp6bZL3Zjbi9l8nuWCxVR1+qtsjXwAAAKNxmyUAAMCAhDkAAIABCXMAAAADEuYAAAAGJMwBAAAMSJgDAAAYkDAHAAAwIGEOAABgQP8fLERjGawg3vQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_log = np.log(y)\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.hist(y_log, bins = 50)\n",
    "plt.title('Distribution of log-transformed target variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM scores: \n",
      "Train error: \n",
      "Mean absolute error: 47.603\n",
      "Test error: \n",
      "Mean absolute error: 51.274\n"
     ]
    }
   ],
   "source": [
    "y_train_log = np.log(y_train)\n",
    "\n",
    "lgbm = LGBMRegressor(objective = 'mae', random_state = 2020)\n",
    "lgbm.fit(X_train, y_train_log)\n",
    "\n",
    "print('LGBM scores: ')\n",
    "\n",
    "print('Train error: ')\n",
    "y_log_pred_train = lgbm.predict(X_train)\n",
    "y_preds_train = np.exp(y_log_pred_train)\n",
    "\n",
    "mae = mean_absolute_error(y_train, y_preds_train)\n",
    "print(\"Mean absolute error: %0.3f\" % mae)\n",
    "\n",
    "print('Test error: ')\n",
    "\n",
    "y_log_pred_valid = lgbm.predict(X_valid)\n",
    "y_preds_valid = np.exp(y_log_pred_valid)\n",
    "\n",
    "mae = mean_absolute_error(y_valid, y_preds_valid)\n",
    "print(\"Mean absolute error: %0.3f\" % mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling of lgbm, catboost, xgboost - time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor\n",
    "# from catboost import CatBoostRegressor\n",
    "\n",
    "# xgbr = XGBRegressor(objective = 'reg:linear', random_state = 2020)\n",
    "# xgbr.fit(X_train, y_train)\n",
    "\n",
    "# catb = CatBoostRegressor(objective = 'MAE', random_seed = 2020)\n",
    "# catb.fit(X_train, y_train)\n",
    "\n",
    "# lgbm = LGBMRegressor(objective = 'mae', random_state = 2020)\n",
    "# lgbm.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_xg = xgbr.predict(X_valid)\n",
    "# y_pred_lg = lgbm.predict(X_valid)\n",
    "# y_pred_cat = catb.predict(X_valid)\n",
    "\n",
    "# y_preds = pd.DataFrame({'xg' : y_pred_xg,\n",
    "#                         'lg' : y_pred_lg,\n",
    "#                         'cat' : y_pred_cat})\n",
    "\n",
    "# y_preds_valid = np.max(y_preds, axis = 1)\n",
    "\n",
    "# y_preds_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae = mean_absolute_error(y_valid, y_preds_valid)\n",
    "# print(\"Mean absolute error: %0.3f\" % mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LGBM with best hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM scores: \n",
      "Train error: \n",
      "Root mean squared error: 121.753\n",
      "Test error: \n",
      "Root mean squared error: 141.331\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(objective = 'mae', learning_rate = 0.19981387712135354 , max_dept = 105, num_leaves = 300, random_state = 2020)\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "print('LGBM scores: ')\n",
    "\n",
    "print('Train error: ')\n",
    "show_scores(lgbm, X_train, y_train)\n",
    "\n",
    "print('Test error: ')\n",
    "show_scores(lgbm, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: \n",
      "Mean absolute error: 27.330\n",
      "Test error: \n",
      "Mean absolute error: 42.011\n"
     ]
    }
   ],
   "source": [
    "print('Train error: ')\n",
    "show_scores(lgbm, X_train, y_train, 'mae')\n",
    "\n",
    "print('Test error: ')\n",
    "show_scores(lgbm, X_valid, y_valid, 'mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dummy data for testing - can be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_train = pd.concat([X_train, y_train], axis = 1)\n",
    "# temp_valid = pd.concat([X_valid, y_valid], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_train = temp_train.iloc[0:10000, ]\n",
    "# temp_valid = temp_valid.iloc[0:2000, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression_opts = dict(method='zip',archive_name='dummy_train_data.csv')  \n",
    "# temp_train.to_csv(\"../data/dummy_train_data.zip\", index = False, compression=compression_opts)\n",
    "\n",
    "# compression_opts = dict(method='zip',archive_name='dummy_test_data.csv')  \n",
    "# temp_valid.to_csv(\"../data/dummy_test_data.zip\", index = False, compression=compression_opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_machine_learning",
   "language": "python",
   "name": "capstone_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
