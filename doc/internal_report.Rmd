---
title: "Internal report"
author: "Saurav Chowdhury, Sirine Chahma, Reiko Okamoto, Tani Barasch"
date: "17/06/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction and purpose

- Describe the UBC MDS program and the capstone project
- Explain the project objective and how it aligns with the needs of the organization
- Describe the aim of the report: help individuals navigate our GitHub repository, summarize our findings, report performance of selected models, provide suggestions on how to move forward 

## Description of the data

- _Should these visualizations be made using the old dataset or the new one?_
- Discuss notable findings that influenced modeling decisions
- Describe the distribution of the target variable (include plot)
- Demonstrate the data sparsity (include plot)
  - Which columns contain mostly zeros?
- Illustrate the prevalence of missing values in the explanatory variables (include plot)
- Visualize the presence of missing values in the target variable (include plot)
  - Across the playgrounds
  - Across the months (this will justify why we excluded January 2018 from our analysis)
    - Other seasonal patterns worth mentioning
- Mention duplication of information sources
  - "Sex by Marital Status", "Sex by Age", "Sex by School Enrollment"
  - Column A is the sum of columns B, C and D
- Exemplify that some columns are in fact linear transformations of other columns
  - OSMnx columns: proportions versus counts - one is just a normalized version of the other 

## Rationale behind the output

- Describe what kinds of outputs were considered
  - We considered building a model that outputs either a confidence interval or probability distribution
  - Since the distribution of the target variable is skewed, we thought that these kinds of estimates would be more robust than a single-value prediction
- Explain the ultimate decision
  - We respected the fact that playground owners and managers are more comfortable working with single-value predictions
  - We built models that predicted either the mean or median session count
    - Quantile regression was pursued because the median is less sensitive to extreme values than the mean
  - Their performance was evaluated using the root mean square error (RMSE) and mean absolute error (MAE), respectively

## Rationale behind the data split

- We initially received a dataset which included 24 monthly observations for 2506 Biba-enabled playgrounds in the U.S.
- Dates ranged from January 2018 to December 2019
- Observations, with the exception of those from the last three months, were used for model training
- The latter observations were set aside and used as the test set
  - Explain why observations from January 2018 were excluded from our analysis (point to visualization in previous section)
    - Most playgrounds are missing the target value for this month
  - The training set consisted of observations from February 2018 through June 2019 
  - The validation set included observations from July 2019 through September 2019
- This split allowed us to avoid data leakage when pursuing a time-dependent model 

## Analysis with old dataset

- Data (point to the .csv file in the GitHub repository and Google Drive)
- Preprocessing
  - Drop rows missing the target value; impute other missing values with zeros
  - Point to the .py file that contains the relevant functions
- Modeling
  - Linear regression, Ridge, Lasso; SVM; random forest; different flavours of gradient boosting
  - Computation time
  - Fitting a model to data in which the dimensionality was reduced via PCA
  - Fitting a model to data in which the "super playgrounds" were removed 
  - Point to the .ipynb files that contain the relevant work

## Analysis with new dataset

- Data (point to the .csv file in the GitHub repository and Google Drive)
  - Describe the difference between the new and old dataset
    - Explain as to how and why the target variable was capped at 4,000
- Preprocessing
  - Describe the difference between the new and old techniques
    - Imputation
      - For some features, missing values were in fact synonymous with zeros
      - For others, it made more sense to replace missing values with the mean or a specific value (i.e. featured related to election results in Alaska)
    - Feature engineering and selection to reduce model complexity
      - Drop columns in which the proportion of missing values was high
      - Remove correlated features
      - Combine columns using domain knowledge
  - Point to the .py files that contain the relevant functions
- Modeling 
  - Mention that models were trained and optimized on Amazon EC2
  - Tree-based models: random forest, XGBoost, LightGBM, CatBoost
  - Time series approach
  - Mixed model
  - Tiered model
  - Point to the .ipynb files that contain the relevant work
  - Highlight the odd trend in our residuals (include residual plots of different models)

## Final product

- Link to README with usage instructions
- Description of selected models (hyperparameters)
- Rationale behind why models that predict the median session counts were included

## Limitations and suggestions

- Suggest how to work around high-count target values
- Suggest how to impute missing values
- Recommend revisiting columns that were dropped
- Discuss the potential benefits of performing further feature engineering and selection
- Discuss the limitations of our data product

## Conclusion

- Reexplain how these findings add value to the organization
- Highlight key areas for improvement
- Mention how the ongoing pandemic affects our project

## Acknowledgements

- We would like to thank Biba Ventures Inc. for sharing their resources and expertise providing unparalleled support over the course of this project
- Our mentor, Vincenzo Coia
- The UBC MDS program