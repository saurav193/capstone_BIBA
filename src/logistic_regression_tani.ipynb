{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "# import other functions\n",
    "from imputer import *\n",
    "from feature_eng import *\n",
    "from drop import *\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_performance(model, X_train, y_train, X_valid, y_valid, \n",
    "                       mode='mean'):\n",
    "    \"\"\"\n",
    "    Evaluate train and validation performance on a fitted model.\n",
    "    \n",
    "    Parameters\n",
    "    ---------     \n",
    "    model: sklearn.ensemble._gb.GradientBoostingRegressor\n",
    "        scikit-learn model\n",
    "    X_train: pandas.core.frame.DataFrame\n",
    "        X of training set\n",
    "    y_train: pandas.core.series.Series\n",
    "        y of training set\n",
    "    X_valid: pandas.core.frame.DataFrame        \n",
    "        X of validation set\n",
    "    y_valid: pandas.core.series.Series\n",
    "        y of validation set     \n",
    "    mode: string\n",
    "        'mean' or 'median'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    errors: list\n",
    "        \n",
    "    \"\"\"\n",
    "    if mode == 'mean':\n",
    "        errors = [mean_squared_error(y_train, \n",
    "                                     model.predict(X_train)) ** 0.5, \n",
    "                  mean_squared_error(y_valid, \n",
    "                                     model.predict(X_valid)) ** 0.5]\n",
    "        \n",
    "        print('Training RMSE:', errors[0])\n",
    "        print('Validation RMSE:', errors[1])\n",
    "        \n",
    "        \n",
    "    elif mode == 'median':\n",
    "        errors = [mean_absolute_error(y_train, \n",
    "                                      model.predict(X_train)), \n",
    "                  mean_absolute_error(y_valid, \n",
    "                                      model.predict(X_valid))]\n",
    "        \n",
    "        print('Training MAE:', errors[0])\n",
    "        print('Validation MAE:', errors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows missing target variable\n",
    "df = drop_missing_unacast(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove playgrounds where 'external_id' == 'CA00070678'\n",
    "df = df.query(\"external_id != 'CA00070678'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['over_300'] = df['unacast_session_count'] > 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['over_300'] == True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['over_300', 'unacast_session_count'], axis=1)\n",
    "y = df.loc[:, 'over_300']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute NaN values\n",
    "result = impute_data(X_train, X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = result[0]\n",
    "X_valid = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature engineering\n",
    "X_train = comb_cols(X_train)\n",
    "X_valid = comb_cols(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection\n",
    "X_train = drop_columns(X_train)\n",
    "X_valid = drop_columns(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform OHE (climate, density_class, income_class)\n",
    "X_train_valid = clean_categorical(X_train, X_valid)\n",
    "X_train = X_train_valid[0]\n",
    "X_valid = X_train_valid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check if there are any missing values in X_train, y_train\n",
    "print(X_train.isna().sum().sum())\n",
    "print(y_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check if there are any missing values in X_valid, y_valid\n",
    "print(X_valid.isna().sum().sum())\n",
    "print(y_valid.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=10, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 500, max_depth=10,class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9445342493433017"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8618,  464],\n",
       "       [  85,  731]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_valid, clf.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier()\n",
    "xgbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\reiko\\.virtualenvs\\capstone_machine_learning-9RBodirp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   39.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   39.1s finished\n"
     ]
    }
   ],
   "source": [
    "# fit a preliminary logistic regression model\n",
    "clf = LogisticRegression(class_weight='balanced', max_iter=700, verbose=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7955142453020813"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9489,   34],\n",
       "       [  82,  293]], dtype=int64)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_valid, xgbc.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12721    True\n",
       "17871    True\n",
       "46441    True\n",
       "48833    True\n",
       "50069    True\n",
       "         ... \n",
       "36902    True\n",
       "5882     True\n",
       "22158    True\n",
       "35672    True\n",
       "31331    True\n",
       "Name: over_500, Length: 9898, dtype: bool"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc.predict(X_valid) == y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create two sets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_data.zip')\n",
    "\n",
    "# drop rows missing target variable\n",
    "df = drop_missing_unacast(df)\n",
    "\n",
    "# remove playgrounds where 'external_id' == 'CA00070678'\n",
    "df = df.query(\"external_id != 'CA00070678'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True if unacast_session_count > 500; False otherwise\n",
    "df['over_500'] = df['unacast_session_count'] > 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df['over_500']].shape[0] + df[df['over_500']].shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hi = df[df['over_500']]\n",
    "df_lo = df[~df['over_500']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `hi` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hi = df_hi.drop(columns=['over_500', 'unacast_session_count'], axis=1)\n",
    "y_hi = df_hi.loc[:, 'unacast_session_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X_train_hi, X_valid_hi, y_train_hi, y_valid_hi = train_test_split(X_hi, y_hi, test_size=0.2)\n",
    "\n",
    "# impute NaN values\n",
    "result_hi = impute_data(X_train_hi, X_valid_hi)\n",
    "X_train_hi = result_hi[0]\n",
    "X_valid_hi = result_hi[1]\n",
    "\n",
    "# perform feature engineering\n",
    "X_train_hi = comb_cols(X_train_hi)\n",
    "X_valid_hi = comb_cols(X_valid_hi)\n",
    "\n",
    "# perform feature selection\n",
    "X_train_hi = drop_columns(X_train_hi)\n",
    "X_valid_hi = drop_columns(X_valid_hi)\n",
    "\n",
    "# perform OHE (climate, density_class, income_class)\n",
    "X_train_valid_hi = clean_categorical(X_train_hi, X_valid_hi)\n",
    "X_train_hi = X_train_valid_hi[0]\n",
    "X_valid_hi = X_train_valid_hi[1]\n",
    "\n",
    "# check if there are any missing values in X_train, y_train\n",
    "print(X_train_hi.isna().sum().sum())\n",
    "print(y_train_hi.isna().sum())\n",
    "\n",
    "# check if there are any missing values in X_valid, y_valid\n",
    "print(X_valid_hi.isna().sum().sum())\n",
    "print(y_valid_hi.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_hi, y_train_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 304.058813712788\n",
      "Validation RMSE: 479.0032637453416\n"
     ]
    }
   ],
   "source": [
    "report_performance(lr, X_train_hi, y_train_hi, X_valid_hi, y_valid_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lo = df_lo.drop(columns=['over_500', 'unacast_session_count'], axis=1)\n",
    "y_lo = df_lo.loc[:, 'unacast_session_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X_train_lo, X_valid_lo, y_train_lo, y_valid_lo = train_test_split(X_lo, y_lo, test_size=0.2)\n",
    "\n",
    "# impute NaN values\n",
    "result_lo = impute_data(X_train_lo, X_valid_lo)\n",
    "X_train_lo = result_lo[0]\n",
    "X_valid_lo = result_lo[1]\n",
    "\n",
    "# perform feature engineering\n",
    "X_train_lo = comb_cols(X_train_lo)\n",
    "X_valid_lo = comb_cols(X_valid_lo)\n",
    "\n",
    "# perform feature selection\n",
    "X_train_lo = drop_columns(X_train_lo)\n",
    "X_valid_lo = drop_columns(X_valid_lo)\n",
    "\n",
    "# perform OHE (climate, density_class, income_class)\n",
    "X_train_valid_lo = clean_categorical(X_train_lo, X_valid_lo)\n",
    "X_train_lo = X_train_valid_lo[0]\n",
    "X_valid_lo = X_train_valid_lo[1]\n",
    "\n",
    "# check if there are any missing values in X_train, y_train\n",
    "print(X_train_lo.isna().sum().sum())\n",
    "print(y_train_lo.isna().sum())\n",
    "\n",
    "# check if there are any missing values in X_valid, y_valid\n",
    "print(X_valid_lo.isna().sum().sum())\n",
    "print(y_valid_lo.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_lo, y_train_lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 53.13742745697422\n",
      "Validation RMSE: 54.236752855382875\n"
     ]
    }
   ],
   "source": [
    "report_performance(lr, X_train_lo, y_train_lo, X_valid_lo, y_valid_lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=2020,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr = XGBRegressor(n_estimators=100, verbosity=1, random_state=2020)\n",
    "xgbr.fit(X_train_hi, y_train_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 43.772364779746084\n",
      "Validation RMSE: 273.9819090342743\n"
     ]
    }
   ],
   "source": [
    "report_performance(xgbr, X_train_hi, y_train_hi, X_valid_hi, y_valid_hi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
