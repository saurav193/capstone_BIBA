{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Go to the end of the notebook for a summary of the analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.set_option('display.max_columns', 50)\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>monthly_number_of_sessions</th>\n",
       "      <th>monthly_unique_sessions</th>\n",
       "      <th>monthly_repeated_sessions</th>\n",
       "      <th>monthly_avg_length_of_session</th>\n",
       "      <th>monthly_avg_light_activity</th>\n",
       "      <th>monthly_avg_moderate_activity</th>\n",
       "      <th>monthly_avg_vigorous_activity</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_wind_9_10</th>\n",
       "      <th>avg_wind_10_11</th>\n",
       "      <th>avg_wind_11_12</th>\n",
       "      <th>avg_wind_12_above</th>\n",
       "      <th>perfect_days</th>\n",
       "      <th>unacast_session_count</th>\n",
       "      <th>hpi</th>\n",
       "      <th>state_and_local_amount_per_capita</th>\n",
       "      <th>state_amount_per_capita</th>\n",
       "      <th>local_amount_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900203</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>323.61</td>\n",
       "      <td>0.132207</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.113688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900203</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>323.61</td>\n",
       "      <td>0.132207</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.113688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900203</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>323.61</td>\n",
       "      <td>0.132207</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.113688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR00101775</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.38</td>\n",
       "      <td>0.076247</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.064281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MR00101775</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>110.38</td>\n",
       "      <td>0.076247</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.064281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  external_id  month  year  monthly_number_of_sessions  \\\n",
       "0     1900203      3  2019                           0   \n",
       "1     1900203      6  2018                           0   \n",
       "2     1900203      8  2018                           0   \n",
       "3  MR00101775      1  2019                           0   \n",
       "4  MR00101775      8  2019                           0   \n",
       "\n",
       "   monthly_unique_sessions  monthly_repeated_sessions  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   monthly_avg_length_of_session  monthly_avg_light_activity  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "\n",
       "   monthly_avg_moderate_activity  monthly_avg_vigorous_activity  ...  \\\n",
       "0                            0.0                            0.0  ...   \n",
       "1                            0.0                            0.0  ...   \n",
       "2                            0.0                            0.0  ...   \n",
       "3                            0.0                            0.0  ...   \n",
       "4                            0.0                            0.0  ...   \n",
       "\n",
       "   avg_wind_9_10  avg_wind_10_11  avg_wind_11_12  avg_wind_12_above  \\\n",
       "0            0.0             0.0             0.0                0.0   \n",
       "1            0.0             0.0             0.0                0.0   \n",
       "2            0.0             0.0             0.0                0.0   \n",
       "3            0.0             0.0             0.0                0.0   \n",
       "4            0.0             0.0             0.0                0.0   \n",
       "\n",
       "   perfect_days  unacast_session_count     hpi  \\\n",
       "0           0.0                   78.0  323.61   \n",
       "1           4.0                  111.0  323.61   \n",
       "2           2.0                  110.0  323.61   \n",
       "3           0.0                   10.0  110.38   \n",
       "4           0.0                   11.0  110.38   \n",
       "\n",
       "   state_and_local_amount_per_capita  state_amount_per_capita  \\\n",
       "0                           0.132207                 0.018519   \n",
       "1                           0.132207                 0.018519   \n",
       "2                           0.132207                 0.018519   \n",
       "3                           0.076247                 0.011966   \n",
       "4                           0.076247                 0.011966   \n",
       "\n",
       "   local_amount_per_capita  \n",
       "0                 0.113688  \n",
       "1                 0.113688  \n",
       "2                 0.113688  \n",
       "3                 0.064281  \n",
       "4                 0.064281  \n",
       "\n",
       "[5 rows x 861 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply basic preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute NaN values and drop unnecessary columns\n",
    "data = preprocessing_na(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on remaining categorical features\n",
    "data = clean_categorical(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>B20004e10</th>\n",
       "      <th>B11016e1</th>\n",
       "      <th>B12001e12</th>\n",
       "      <th>B20004e11</th>\n",
       "      <th>B19125e1</th>\n",
       "      <th>B12001e13</th>\n",
       "      <th>B23008e22</th>\n",
       "      <th>...</th>\n",
       "      <th>monthly_Thursday</th>\n",
       "      <th>HI</th>\n",
       "      <th>LI</th>\n",
       "      <th>MI</th>\n",
       "      <th>HD</th>\n",
       "      <th>LD</th>\n",
       "      <th>MD</th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900203</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>51111</td>\n",
       "      <td>1868</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>78934</td>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900203</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>51111</td>\n",
       "      <td>1868</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>78934</td>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900203</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>51111</td>\n",
       "      <td>1868</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>78934</td>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR00101775</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>45484</td>\n",
       "      <td>2613</td>\n",
       "      <td>980</td>\n",
       "      <td>30417</td>\n",
       "      <td>45578</td>\n",
       "      <td>1097</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MR00101775</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "      <td>45484</td>\n",
       "      <td>2613</td>\n",
       "      <td>980</td>\n",
       "      <td>30417</td>\n",
       "      <td>45578</td>\n",
       "      <td>1097</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 821 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  external_id  month  year  B20004e10  B11016e1  B12001e12  B20004e11  \\\n",
       "0     1900203      3  2019      51111      1868        688          0   \n",
       "1     1900203      6  2018      51111      1868        688          0   \n",
       "2     1900203      8  2018      51111      1868        688          0   \n",
       "3  MR00101775      1  2019      45484      2613        980      30417   \n",
       "4  MR00101775      8  2019      45484      2613        980      30417   \n",
       "\n",
       "   B19125e1  B12001e13  B23008e22  ...  monthly_Thursday  HI  LI  MI  HD  LD  \\\n",
       "0     78934       1342          0  ...               0.0   1   0   0   1   0   \n",
       "1     78934       1342          0  ...               0.0   1   0   0   1   0   \n",
       "2     78934       1342          0  ...               0.0   1   0   0   1   0   \n",
       "3     45578       1097         66  ...               0.0   0   1   0   0   1   \n",
       "4     45578       1097         66  ...               0.0   0   1   0   0   1   \n",
       "\n",
       "   MD  A  C  D  \n",
       "0   0  0  1  0  \n",
       "1   0  0  1  0  \n",
       "2   0  0  1  0  \n",
       "3   0  0  1  0  \n",
       "4   0  0  1  0  \n",
       "\n",
       "[5 rows x 821 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50120, 821)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of output data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `X` and `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('unacast_session_count', axis=1)\n",
    "y = data.loc[:, 'unacast_session_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, drop `external_id` and `state`\n",
    "X = X.drop(['external_id', 'state'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D                     0\n",
       "B11001e5              0\n",
       "B11005e9              0\n",
       "B13016e5              0\n",
       "B23025e6              0\n",
       "                     ..\n",
       "avg_wind_0_1          0\n",
       "precip_mm_10_above    0\n",
       "precip_mm_1_10        0\n",
       "precip_mm_0_1         0\n",
       "month                 0\n",
       "Length: 818, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are missing values in X\n",
    "X.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are missing values in y\n",
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No `NaN` values in `X` and `y` - that's good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40096, 818)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10024, 818)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a `GradientBoostingRegressor` with default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'verbose': 1,\n",
    "          'random_state': 2020}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      213669.2304            4.86m\n",
      "         2      205282.8246            4.79m\n",
      "         3      198390.9645            4.72m\n",
      "         4      191658.6878            5.01m\n",
      "         5      186589.0004            4.92m\n",
      "         6      181186.5017            4.90m\n",
      "         7      177208.5001            4.84m\n",
      "         8      174242.0719            5.04m\n",
      "         9      171638.3291            5.22m\n",
      "        10      165022.6046            5.32m\n",
      "        20      129466.3909            4.65m\n",
      "        30       99860.7850            3.98m\n",
      "        40       81710.4135            3.35m\n",
      "        50       70320.0408            2.81m\n",
      "        60       62436.7513            2.22m\n",
      "        70       58201.8945            1.67m\n",
      "        80       53252.5016            1.11m\n",
      "        90       49244.3230           33.05s\n",
      "       100       46957.9923            0.00s\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(**params)\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370204.9588049915"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate validation MSE\n",
    "y_pred = gbr.predict(X_valid)\n",
    "mean_squared_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27425744561888155"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate R^2 of the prediction on the validation set\n",
    "gbr.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another `GradientBoostingRegressor` where `n_estimators` is increased to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_1000 = {'verbose': 1,\n",
    "               'n_estimators': 1000,\n",
    "               'random_state': 2020}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      213669.2304           48.80m\n",
      "         2      205282.8246           47.63m\n",
      "         3      198390.9645           47.96m\n",
      "         4      191658.6878           49.80m\n",
      "         5      186589.0004           53.81m\n",
      "         6      181186.5017           53.67m\n",
      "         7      177208.5001           53.37m\n",
      "         8      174242.0719           53.11m\n",
      "         9      171638.3291           52.80m\n",
      "        10      165022.6046           52.90m\n",
      "        20      129466.3909           50.69m\n",
      "        30       99860.7850           51.99m\n",
      "        40       81710.4135           51.96m\n",
      "        50       70320.0408           51.28m\n",
      "        60       62436.7513           53.76m\n",
      "        70       58201.8945           53.96m\n",
      "        80       53252.5016           52.57m\n",
      "        90       49244.3230           50.99m\n",
      "       100       46957.9923           49.76m\n",
      "       200       33108.7092           43.56m\n",
      "       300       26537.4012           37.29m\n",
      "       400       22282.0518           32.59m\n",
      "       500       19214.4100           26.89m\n",
      "       600       16629.4686           21.27m\n",
      "       700       14954.9852           15.76m\n",
      "       800       13701.1824           10.43m\n",
      "       900       12449.9097            5.17m\n",
      "      1000       11590.5045            0.00s\n"
     ]
    }
   ],
   "source": [
    "gbr_1000 = GradientBoostingRegressor(**params_1000)\n",
    "\n",
    "t0 = time.time()\n",
    "gbr_1000.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "fit_time = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364149.91425749223"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate validation MSE\n",
    "y_pred_1000 = gbr_1000.predict(X_valid)\n",
    "mean_squared_error(y_valid, y_pred_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2861276364206973"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate R^2 of the prediction on the validation set\n",
    "gbr_1000.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform randomized search of optimal hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'min_samples_split': [2, 4, 6],\n",
    "              'max_depth': [3, 5, 7, 9],\n",
    "              'max_features': ['auto', 'sqrt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] min_samples_split=4, max_features=auto, max_depth=3 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      153317.5171           65.14m\n",
      "         2      142882.3344           66.35m\n",
      "         3      135685.8230           66.56m\n",
      "         4      128130.1997           66.66m\n",
      "         5      122470.8207           66.94m\n",
      "         6      118451.6037           66.95m\n",
      "         7      115259.8875           67.29m\n",
      "         8      112609.5008           67.27m\n",
      "         9      109552.1000           67.53m\n",
      "        10      107623.1704           68.16m\n",
      "        20       89430.5067           67.99m\n",
      "        30       71334.1225           69.04m\n",
      "        40       60044.3450           69.81m\n",
      "        50       52779.6393           69.76m\n",
      "        60       47767.4358           69.39m\n",
      "        70       43246.5435           68.77m\n",
      "        80       40850.4885           68.26m\n",
      "        90       39042.1967           67.94m\n",
      "       100       37326.2071           67.25m\n",
      "       200       24353.1053           53.62m\n",
      "       300       17797.7181           38.50m\n",
      "       400       14449.5789           29.30m\n",
      "       500       12265.7430           22.57m\n",
      "       600       10449.3770           17.05m\n",
      "       700        9320.8869           12.27m\n",
      "       800        8350.0983            7.91m\n",
      "       900        7601.7513            3.85m\n",
      "      1000        6869.0822            0.00s\n",
      "[CV]  min_samples_split=4, max_features=auto, max_depth=3, total=37.7min\n",
      "[CV] min_samples_split=4, max_features=auto, max_depth=3 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 37.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      241967.4629           30.65m\n",
      "         2      225379.2903           30.43m\n",
      "         3      208913.0207           30.43m\n",
      "         4      201653.9873           30.33m\n",
      "         5      188521.9523           30.30m\n",
      "         6      177523.3656           30.27m\n",
      "         7      166659.6284           30.17m\n",
      "         8      158616.3034           30.14m\n",
      "         9      150653.1653           30.08m\n",
      "        10      143361.2094           30.05m\n",
      "        20      107967.1941           29.69m\n",
      "        30       81686.2252           29.74m\n",
      "        40       65468.1422           29.55m\n",
      "        50       54354.3595           29.37m\n",
      "        60       48476.4330           29.05m\n",
      "        70       45189.1124           28.73m\n",
      "        80       42161.0303           28.38m\n",
      "        90       39027.2504           28.08m\n",
      "       100       36137.7814           27.76m\n",
      "       200       25283.7676           24.63m\n",
      "       300       19759.4666           21.70m\n",
      "       400       16222.4392           19.32m\n",
      "       500       13572.0073           16.52m\n",
      "       600       11969.1479           13.55m\n",
      "       700       10306.1348           10.32m\n",
      "       800        9152.2162            6.94m\n",
      "       900        8301.7948            3.48m\n",
      "      1000        7510.6889            0.00s\n",
      "[CV]  min_samples_split=4, max_features=auto, max_depth=3, total=35.0min\n",
      "[CV] min_samples_split=4, max_features=auto, max_depth=3 .............\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      240221.6672           44.82m\n",
      "         2      224642.3947           41.35m\n",
      "         3      208393.6742           42.52m\n",
      "         4      195086.3002           42.13m\n",
      "         5      184528.7218           40.95m\n",
      "         6      174314.2392           40.92m\n",
      "         7      165901.3321           40.43m\n",
      "         8      158411.5076           39.76m\n",
      "         9      151906.4892           39.77m\n",
      "        10      145844.8002           39.56m\n",
      "        20      113127.1241           37.26m\n",
      "        30       90269.7455           36.57m\n",
      "        40       71186.1487           38.46m\n",
      "        50       59605.9486           37.83m\n",
      "        60       52526.2487           36.92m\n",
      "        70       48008.5433           36.05m\n",
      "        80       44975.7400           35.21m\n",
      "        90       42358.3639           34.94m\n",
      "       100       40096.6931           34.23m\n",
      "       200       26770.2200           29.14m\n",
      "       300       20641.3234           25.08m\n",
      "       400       15950.1855           21.36m\n",
      "       500       13158.8593           17.69m\n",
      "       600       11330.2752           14.12m\n",
      "       700        9777.5656           10.58m\n",
      "       800        8645.2277            7.07m\n",
      "       900        7781.1475            3.52m\n",
      "      1000        7185.2461            0.00s\n",
      "[CV]  min_samples_split=4, max_features=auto, max_depth=3, total=35.3min\n",
      "[CV] min_samples_split=4, max_features=auto, max_depth=7 .............\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      139955.9308           84.32m\n",
      "         2      120636.6704           84.45m\n",
      "         3      104240.9834           84.12m\n",
      "         4       90661.3218           83.53m\n",
      "         5       79268.6824           83.62m\n",
      "         6       69584.5782           82.60m\n",
      "         7       61991.0093           81.86m\n",
      "         8       55675.0023           82.04m\n",
      "         9       50182.8420           81.37m\n",
      "        10       46064.5668           80.75m\n",
      "        20       21958.1132           80.26m\n",
      "        30       13884.9788           79.26m\n",
      "        40        9628.0516           79.44m\n",
      "        50        7428.5534           79.19m\n",
      "        60        6069.7875           78.15m\n",
      "        70        5313.4477           77.64m\n",
      "        80        4534.8533           76.82m\n",
      "        90        4101.8099           75.53m\n",
      "       100        3717.4627           74.53m\n",
      "       200        1781.1446           65.72m\n",
      "       300        1113.2378           57.46m\n",
      "       400         794.4664           49.43m\n",
      "       500         585.5602           41.22m\n",
      "       600         441.9735           33.44m\n",
      "       700         333.2927           25.51m\n",
      "       800         258.9561           17.14m\n",
      "       900         203.2628            8.81m\n",
      "      1000         158.7878            0.00s\n",
      "[CV]  min_samples_split=4, max_features=auto, max_depth=7, total=88.6min\n",
      "[CV] min_samples_split=4, max_features=auto, max_depth=7 .............\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221142.7151           85.23m\n",
      "         2      188321.1186           86.27m\n",
      "         3      161288.8493           85.65m\n",
      "         4      137749.2520           85.74m\n",
      "         5      118405.1042           87.19m\n",
      "         6      102776.3310           86.48m\n",
      "         7       90214.6173           85.99m\n",
      "         8       79317.8171           85.58m\n",
      "         9       69643.8235           85.49m\n",
      "        10       62662.3745           85.34m\n",
      "        20       26946.2717           86.15m\n",
      "        30       15279.0365           86.73m\n",
      "        40       10950.5773           85.72m\n",
      "        50        8290.1032           84.94m\n",
      "        60        6828.1246           83.82m\n",
      "        70        5755.4320           82.85m\n",
      "        80        4961.6475           81.68m\n",
      "        90        4296.6196           81.21m\n",
      "       100        3741.8642           80.14m\n",
      "       200        1683.7851           71.29m\n",
      "       300        1079.6167           62.00m\n",
      "       400         761.8538           53.95m\n",
      "       500         563.4655           45.14m\n",
      "       600         429.0603           36.27m\n",
      "       700         322.4795           27.36m\n",
      "       800         247.1127           18.22m\n",
      "       900         189.9890            8.93m\n",
      "      1000         144.3119            0.00s\n",
      "[CV]  min_samples_split=4, max_features=auto, max_depth=7, total=87.8min\n",
      "[CV] min_samples_split=4, max_features=auto, max_depth=7 .............\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219337.4996           72.52m\n",
      "         2      187813.4630           71.17m\n",
      "         3      160560.0152           71.20m\n",
      "         4      138910.8902           70.88m\n",
      "         5      121151.1839           70.63m\n",
      "         6      106756.6710           70.38m\n",
      "         7       94685.5184           70.26m\n",
      "         8       85830.1229           70.12m\n",
      "         9       79068.4560           70.00m\n",
      "        10       71525.6090           70.01m\n",
      "        20       31330.0010           70.51m\n",
      "        30       18771.5650           70.36m\n",
      "        40       12221.6774           70.15m\n",
      "        50        9320.1417           69.52m\n",
      "        60        7638.0619           68.79m\n",
      "        70        6463.8768           67.84m\n",
      "        80        5568.1654           67.05m\n",
      "        90        4848.7561           66.32m\n",
      "       100        4254.0861           65.50m\n",
      "       200        1987.4639           57.77m\n",
      "       300        1264.6727           50.53m\n",
      "       400         899.7452           43.38m\n",
      "       500         660.8410           36.20m\n",
      "       600         494.1790           29.01m\n",
      "       700         371.9100           21.81m\n",
      "       800         288.3596           14.56m\n",
      "       900         221.3388            7.29m\n",
      "      1000         174.6572            0.00s\n",
      "[CV]  min_samples_split=4, max_features=auto, max_depth=7, total=73.0min\n",
      "[CV] min_samples_split=2, max_features=sqrt, max_depth=7 .............\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      147415.2818            2.46m\n",
      "         2      138723.6092            2.50m\n",
      "         3      128922.2113            2.49m\n",
      "         4      119980.1320            2.49m\n",
      "         5      107417.6587            2.47m\n",
      "         6      100148.7136            2.47m\n",
      "         7       93359.2805            2.46m\n",
      "         8       87320.6982            2.44m\n",
      "         9       78627.5706            2.43m\n",
      "        10       72879.7611            2.42m\n",
      "        20       43247.0196            2.42m\n",
      "        30       27591.8990            2.44m\n",
      "        40       19660.0309            2.45m\n",
      "        50       15924.5838            2.42m\n",
      "        60       12676.6009            2.40m\n",
      "        70       10229.0150            2.37m\n",
      "        80        8787.4725            2.35m\n",
      "        90        7663.6492            2.32m\n",
      "       100        6963.4093            2.29m\n",
      "       200        3006.9501            2.05m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       300        1952.7888            1.80m\n",
      "       400        1389.6867            1.54m\n",
      "       500        1055.7018            1.29m\n",
      "       600         842.7764            1.03m\n",
      "       700         665.2847           46.73s\n",
      "       800         535.4185           31.21s\n",
      "       900         448.4783           15.64s\n",
      "      1000         372.9179            0.00s\n",
      "[CV]  min_samples_split=2, max_features=sqrt, max_depth=7, total= 2.6min\n",
      "[CV] min_samples_split=2, max_features=sqrt, max_depth=7 .............\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      231119.0006            2.55m\n",
      "         2      206885.3001            2.52m\n",
      "         3      186561.3483            2.49m\n",
      "         4      162252.3419            2.50m\n",
      "         5      141641.5785            2.48m\n",
      "         6      126785.6327            2.48m\n",
      "         7      113329.5210            2.46m\n",
      "         8      101487.7961            2.46m\n",
      "         9       89886.4764            2.46m\n",
      "        10       80677.5757            2.45m\n",
      "        20       44273.4174            2.44m\n",
      "        30       27760.7878            2.44m\n",
      "        40       19203.5563            2.43m\n",
      "        50       15409.9478            2.41m\n",
      "        60       12696.6497            2.39m\n",
      "        70       10651.1273            2.36m\n",
      "        80        8998.4862            2.34m\n",
      "        90        7857.3781            2.31m\n",
      "       100        6883.2789            2.28m\n",
      "       200        2939.9834            2.04m\n",
      "       300        1840.2047            1.79m\n",
      "       400        1345.2018            1.54m\n",
      "       500        1030.6132            1.29m\n",
      "       600         812.9916            1.03m\n",
      "       700         654.0344           46.70s\n",
      "       800         535.2096           31.21s\n",
      "       900         438.4678           15.64s\n",
      "      1000         358.7933            0.00s\n",
      "[CV]  min_samples_split=2, max_features=sqrt, max_depth=7, total= 2.6min\n",
      "[CV] min_samples_split=2, max_features=sqrt, max_depth=7 .............\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      231426.4103            2.43m\n",
      "         2      204700.7992            2.48m\n",
      "         3      182596.2553            2.47m\n",
      "         4      162682.1391            2.49m\n",
      "         5      145980.7143            2.48m\n",
      "         6      128991.0876            2.48m\n",
      "         7      112095.2661            2.46m\n",
      "         8      103386.3814            2.46m\n",
      "         9       92134.5792            2.45m\n",
      "        10       86089.5504            2.45m\n",
      "        20       42530.8964            2.44m\n",
      "        30       26644.7065            2.45m\n",
      "        40       18893.7696            2.45m\n",
      "        50       15023.3580            2.42m\n",
      "        60       12278.2040            2.40m\n",
      "        70       10294.5594            2.37m\n",
      "        80        9044.3196            2.34m\n",
      "        90        7898.5929            2.31m\n",
      "       100        6874.3283            2.29m\n",
      "       200        3118.7809            2.05m\n",
      "       300        1988.4015            1.80m\n",
      "       400        1423.4316            1.54m\n",
      "       500        1072.2048            1.29m\n",
      "       600         831.9145            1.04m\n",
      "       700         665.2816           46.69s\n",
      "       800         539.9810           31.25s\n",
      "       900         439.5051           15.66s\n",
      "      1000         361.9735            0.00s\n",
      "[CV]  min_samples_split=2, max_features=sqrt, max_depth=7, total= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 365.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      201432.3232            3.71m\n",
      "         2      187698.6130            3.69m\n",
      "         3      172924.2830            3.59m\n",
      "         4      165930.4164            3.59m\n",
      "         5      152832.8956            3.57m\n",
      "         6      137973.6947            3.56m\n",
      "         7      129007.9530            3.54m\n",
      "         8      119984.4184            3.54m\n",
      "         9      110339.4638            3.54m\n",
      "        10      100848.2244            3.51m\n",
      "        20       54586.3249            3.48m\n",
      "        30       35933.6346            3.48m\n",
      "        40       25765.4375            3.47m\n",
      "        50       19896.6681            3.44m\n",
      "        60       15900.4821            3.40m\n",
      "        70       13601.7552            3.39m\n",
      "        80       11404.3946            3.36m\n",
      "        90       10302.6814            3.33m\n",
      "       100        9233.4724            3.29m\n",
      "       200        4295.5839            2.94m\n",
      "       300        2765.3633            2.57m\n",
      "       400        2028.5001            2.21m\n",
      "       500        1602.7798            1.85m\n",
      "       600        1308.7908            1.48m\n",
      "       700        1064.1225            1.11m\n",
      "       800         896.4873           44.64s\n",
      "       900         767.9447           22.37s\n",
      "      1000         651.2235            0.00s\n"
     ]
    }
   ],
   "source": [
    "gbr_gs = GradientBoostingRegressor(n_estimators=1000, verbose=1, random_state=2020)\n",
    "\n",
    "rscv = RandomizedSearchCV(gbr_gs, param_grid, n_iter=3, verbose=2, cv=3, n_jobs=1, random_state=2020)\n",
    "\n",
    "search = rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': 7}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the most optimal hyperparameter settings\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2159.919200</td>\n",
       "      <td>73.135515</td>\n",
       "      <td>1.049887</td>\n",
       "      <td>0.263267</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>{'min_samples_split': 4, 'max_features': 'auto...</td>\n",
       "      <td>0.161272</td>\n",
       "      <td>0.364089</td>\n",
       "      <td>0.055305</td>\n",
       "      <td>0.193555</td>\n",
       "      <td>0.128111</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4987.493293</td>\n",
       "      <td>430.139624</td>\n",
       "      <td>1.645919</td>\n",
       "      <td>0.316282</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>7</td>\n",
       "      <td>{'min_samples_split': 4, 'max_features': 'auto...</td>\n",
       "      <td>0.190472</td>\n",
       "      <td>0.284677</td>\n",
       "      <td>0.402996</td>\n",
       "      <td>0.292715</td>\n",
       "      <td>0.086948</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157.151442</td>\n",
       "      <td>0.092279</td>\n",
       "      <td>1.505860</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>7</td>\n",
       "      <td>{'min_samples_split': 2, 'max_features': 'sqrt...</td>\n",
       "      <td>0.128976</td>\n",
       "      <td>0.545482</td>\n",
       "      <td>0.384348</td>\n",
       "      <td>0.352935</td>\n",
       "      <td>0.171483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0    2159.919200     73.135515         1.049887        0.263267   \n",
       "1    4987.493293    430.139624         1.645919        0.316282   \n",
       "2     157.151442      0.092279         1.505860        0.004716   \n",
       "\n",
       "  param_min_samples_split param_max_features param_max_depth  \\\n",
       "0                       4               auto               3   \n",
       "1                       4               auto               7   \n",
       "2                       2               sqrt               7   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'min_samples_split': 4, 'max_features': 'auto...           0.161272   \n",
       "1  {'min_samples_split': 4, 'max_features': 'auto...           0.190472   \n",
       "2  {'min_samples_split': 2, 'max_features': 'sqrt...           0.128976   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.364089           0.055305         0.193555        0.128111   \n",
       "1           0.284677           0.402996         0.292715        0.086948   \n",
       "2           0.545482           0.384348         0.352935        0.171483   \n",
       "\n",
       "   rank_test_score  \n",
       "0                3  \n",
       "1                2  \n",
       "2                1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the evaluation of the hyperparameter candidates\n",
    "result = search.cv_results_\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651.2234780126952"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call predict on the most optimal hyperparameter on the training set\n",
    "# Calculate training MSE\n",
    "mean_squared_error(y_train, search.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9971445104080854"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate R^2 of the prediction on the training set\n",
    "search.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394161.808067091"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call predict on the most optimal hyperparameter on the validation set\n",
    "# Calculate validation MSE\n",
    "mean_squared_error(y_valid, search.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2272929072871356"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate R^2 of the prediction on the validation set\n",
    "search.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try removing the playgrounds with over 70,000 lifetime sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of playgrounds to remove\n",
    "popular_sites = ['9322b009-a5d3-4c74-b355-5f044b449890', 'MR00096951', '1804229', '44aae0ac-f1b2-433b-961c-546c54867f26',\n",
    "                 'MR00103365', 'MR00115762', 'MR00101404', 'FM00174462', 'FM00169129']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49940, 821)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop these two playgrounds from the input data\n",
    "new_data = data.copy()\n",
    "new_data = new_data[~ new_data['external_id'].isin(popular_sites)]\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and Y, split into training and validation sets\n",
    "new_X = new_data.drop('unacast_session_count', axis=1)\n",
    "new_y = new_data.loc[:, 'unacast_session_count']\n",
    "\n",
    "# For now, drop `external_id` and `state`\n",
    "new_X = new_X.drop(['external_id', 'state'], axis=1)\n",
    "\n",
    "new_X_train, new_X_valid, new_y_train, new_y_valid = train_test_split(new_X, new_y, \n",
    "                                                                      test_size=0.2,\n",
    "                                                                      random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a `GradientBoostingRegressor` with default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       72059.0349            4.58m\n",
      "         2       67479.8754            4.61m\n",
      "         3       63647.6264            4.55m\n",
      "         4       60488.9997            4.56m\n",
      "         5       57637.7708            4.49m\n",
      "         6       55323.6846            4.46m\n",
      "         7       53430.0945            4.70m\n",
      "         8       51802.9598            4.89m\n",
      "         9       50416.7531            4.92m\n",
      "        10       49270.4861            4.89m\n",
      "        20       42582.4384            4.21m\n",
      "        30       38146.3113            3.75m\n",
      "        40       35631.3491            3.15m\n",
      "        50       33321.8536            2.66m\n",
      "        60       31242.3235            2.12m\n",
      "        70       29154.8346            1.63m\n",
      "        80       28138.6953            1.10m\n",
      "        90       26996.9965           32.61s\n",
      "       100       26136.0349            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=2020, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_ps = GradientBoostingRegressor(verbose=1, random_state=2020)\n",
    "gbr_ps.fit(new_X_train, new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_performance(model, X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Evaluate train and validation performance on a fitted model.\n",
    "    \n",
    "    Parameters\n",
    "    ---------     \n",
    "    model: sklearn.ensemble._gb.GradientBoostingRegressor\n",
    "        scikit-learn model\n",
    "    X_train: pandas.core.frame.DataFrame\n",
    "        X of training set\n",
    "    y_train: pandas.core.series.Series\n",
    "        y of training set\n",
    "    X_valid: pandas.core.frame.DataFrame        \n",
    "        X of validation set\n",
    "    y_valid: pandas.core.series.Series\n",
    "        y of validation set     \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    errors: list\n",
    "        \n",
    "    \"\"\"\n",
    "    errors = [mean_squared_error(y_train, model.predict(X_train)), \n",
    "              mean_squared_error(y_valid, model.predict(X_valid))]\n",
    "    \n",
    "    print('Training mean squared error:', errors[0])\n",
    "    print('Validation mean squared error:', errors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean squared error: 26136.034904114495\n",
      "Validation mean squared error: 22786.46644219538\n"
     ]
    }
   ],
   "source": [
    "report_performance(gbr_ps, new_X_train, new_y_train, new_X_valid, new_y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same data, create another `GradientBoostingRegressor` where `n_estimators` is increased to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       72059.0349           54.59m\n",
      "         2       67479.8754           58.34m\n",
      "         3       63647.6264           58.31m\n",
      "         4       60488.9997           58.19m\n",
      "         5       57637.7708           58.43m\n",
      "         6       55323.6846           58.36m\n",
      "         7       53430.0945           58.10m\n",
      "         8       51802.9598           58.09m\n",
      "         9       50416.7531           57.63m\n",
      "        10       49270.4861           57.29m\n",
      "        20       42582.4384           56.48m\n",
      "        30       38146.3113           60.49m\n",
      "        40       35631.3491           59.07m\n",
      "        50       33321.8536           57.77m\n",
      "        60       31242.3235           56.38m\n",
      "        70       29154.8346           55.39m\n",
      "        80       28138.6953           56.23m\n",
      "        90       26996.9965           56.51m\n",
      "       100       26136.0349           55.57m\n",
      "       200       19999.9568           45.09m\n",
      "       300       16288.3391           37.19m\n",
      "       400       13560.4540           31.10m\n",
      "       500       11362.1142           25.61m\n",
      "       600       10260.1055           20.19m\n",
      "       700        9118.8819           14.98m\n",
      "       800        8589.1771            9.91m\n",
      "       900        7825.9014            4.96m\n",
      "      1000        7246.4176            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=2020, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_ps_1000 = GradientBoostingRegressor(n_estimators=1000, verbose=1, random_state=2020)\n",
    "gbr_ps_1000.fit(new_X_train, new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean squared error: 7246.417608647951\n",
      "Validation mean squared error: 17570.52261992865\n"
     ]
    }
   ],
   "source": [
    "report_performance(gbr_ps_1000, new_X_train, new_y_train, new_X_valid, new_y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try creating a rudimentary `XGBRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = XGBRegressor()\n",
    "t0 = time.time()\n",
    "xgbr.fit(new_X_train, new_y_train)\n",
    "t1 = time.time()\n",
    "fit_time = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean squared error: 2865.0722273839897\n",
      "Validation mean squared error: 15932.369947959685\n"
     ]
    }
   ],
   "source": [
    "report_performance(xgbr, new_X_train, new_y_train, new_X_valid, new_y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.27326512336731\n"
     ]
    }
   ],
   "source": [
    "# Print how long it took to fit the model (in seconds)\n",
    "print(fit_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of the preliminary analysis**\n",
    "\n",
    "- In this preliminary round of modeling, two different regressors were considered: `GradientBoostingRegressor` and `XGBRegressor`\n",
    "- When a `GradientBoostingRegressor` with the default settings (i.e. `n_estimators=100`) were fit to the preprocessed data, the validation RMSE was 608. Considering that the RMSE of the initial linear regression model (fit by George) was 289, the results suggests that the initial boosting model performed poorly.\n",
    "- Next, basic hyperparameter tuning was performed using `RandomizedSearchCV`. For all models, `n_estimator=1000`. \n",
    "    - `{'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': 7}` generated the best results.\n",
    "    - The best model appeared to be overfit. Although gradient boosting is robust to overfitting, `n_estimators` could be lowered. \n",
    "    - The validation RMSE of the best model was 628.\n",
    "- After finding out that there are some playgrounds in the dataset with historic session counts greater than 70,000, another round of modeling was performed with these playgrounds removed from the data.\n",
    "    - `GradientBoostingRegressor` with default settings:\n",
    "        - Validation RMSE: 150\n",
    "    - `GradientBoostingRegressor` with `n_estimator=1000`:\n",
    "        - Validation RMSE: 132\n",
    "    - `XGBRegressor` with default settings:\n",
    "        - Validation RMSE: 150\n",
    "        - Fitting took less time than scikit-learn's implementation\n",
    "- This initial analysis revealed that the skewness of the data is contributing to high MSE values. Follow-up is required as to why some playgrounds have incredibly high play session counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "- https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html\n",
    "- https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "- http://www.chengli.io/tutorials/gradient_boosting.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_machine_learning",
   "language": "python",
   "name": "capstone_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
