{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Effects Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll use the `statsmodels` library to fit mixed effects models to our data. Be careful, there is one cell that is very long to run (you will find a caution before it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import altair as alt\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# import other functions\n",
    "from scripts_misc.imputer import *\n",
    "from scripts_misc.feature_eng import *\n",
    "from scripts_misc.drop import *\n",
    "from scripts_misc.preprocessing_old import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_performance(model, X_train, y_train, X_valid, y_valid, mode='mean', floor=False):\n",
    "    \"\"\"\n",
    "    Evaluate train and validation performance on a fitted model.\n",
    "    \n",
    "    Parameters\n",
    "    ---------     \n",
    "    model: sklearn.ensemble._gb.GradientBoostingRegressor\n",
    "        scikit-learn model\n",
    "    X_train: pandas.core.frame.DataFrame\n",
    "        X of training set\n",
    "    y_train: pandas.core.series.Series\n",
    "        y of training set\n",
    "    X_valid: pandas.core.frame.DataFrame        \n",
    "        X of validation set\n",
    "    y_valid: pandas.core.series.Series\n",
    "        y of validation set     \n",
    "    mode: string\n",
    "        'mean' or 'median'\n",
    "    floor : boolean\n",
    "        if true, all the negative values are turned into 0s\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    errors: list\n",
    "        \n",
    "    \"\"\"\n",
    "    if mode == 'mean':\n",
    "        if floor:\n",
    "            errors = [np.sqrt(metrics.mean_squared_error(y_train, list(map(lambda x: 0 if x<0 else x, model.predict(X_train))))), \n",
    "                  np.sqrt(metrics.mean_squared_error(y_valid, list(map(lambda x: 0 if x<0 else x, model.predict(X_valid)))))]\n",
    "            metric = 'root mean squared'\n",
    "        else:\n",
    "            errors = [np.sqrt(metrics.mean_squared_error(y_train, model.predict(X_train))), \n",
    "                      np.sqrt(metrics.mean_squared_error(y_valid, model.predict(X_valid)))]\n",
    "            metric = 'root mean squared'\n",
    "        \n",
    "    elif mode == 'median':\n",
    "        if floor:\n",
    "            errors = [metrics.mean_absolute_error(y_train, list(map(lambda x: 0 if x<0 else x, model.predict(X_train)))), \n",
    "                      metrics.mean_absolute_error(y_valid, list(map(lambda x: 0 if x<0 else x, model.predict(X_valid))))]\n",
    "            metric= 'mean absolute'\n",
    "        else:\n",
    "            errors = [metrics.mean_absolute_error(y_train, model.predict(X_train)), \n",
    "                      metrics.mean_absolute_error(y_valid, model.predict(X_valid))]\n",
    "            metric= 'mean absolute'\n",
    "    \n",
    "    print('Training', metric, 'error:', errors[0])\n",
    "    print('Validation', metric, 'error:', errors[1])\n",
    "        \n",
    "    return(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>monthly_number_of_sessions</th>\n",
       "      <th>monthly_unique_sessions</th>\n",
       "      <th>monthly_repeated_sessions</th>\n",
       "      <th>monthly_avg_length_of_session</th>\n",
       "      <th>monthly_avg_light_activity</th>\n",
       "      <th>monthly_avg_moderate_activity</th>\n",
       "      <th>monthly_avg_vigorous_activity</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_wind_9_10</th>\n",
       "      <th>avg_wind_10_11</th>\n",
       "      <th>avg_wind_11_12</th>\n",
       "      <th>avg_wind_12_above</th>\n",
       "      <th>perfect_days</th>\n",
       "      <th>unacast_session_count</th>\n",
       "      <th>hpi</th>\n",
       "      <th>state_and_local_amount_per_capita</th>\n",
       "      <th>state_amount_per_capita</th>\n",
       "      <th>local_amount_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1804425</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>244.20</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1812706</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1812706</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1812706</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1812706</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  external_id  month  year  monthly_number_of_sessions  \\\n",
       "0     1804425      8  2018                           0   \n",
       "1     1812706      2  2019                           0   \n",
       "2     1812706      3  2019                           0   \n",
       "3     1812706     11  2018                           0   \n",
       "4     1812706      9  2018                           0   \n",
       "\n",
       "   monthly_unique_sessions  monthly_repeated_sessions  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   monthly_avg_length_of_session  monthly_avg_light_activity  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "\n",
       "   monthly_avg_moderate_activity  monthly_avg_vigorous_activity  ...  \\\n",
       "0                            0.0                            0.0  ...   \n",
       "1                            0.0                            0.0  ...   \n",
       "2                            0.0                            0.0  ...   \n",
       "3                            0.0                            0.0  ...   \n",
       "4                            0.0                            0.0  ...   \n",
       "\n",
       "   avg_wind_9_10  avg_wind_10_11  avg_wind_11_12  avg_wind_12_above  \\\n",
       "0            0.0             0.0             0.0                0.0   \n",
       "1            0.0             0.0             0.0                0.0   \n",
       "2            0.0             0.0             0.0                0.0   \n",
       "3            0.0             0.0             0.0                0.0   \n",
       "4            0.0             0.0             0.0                0.0   \n",
       "\n",
       "   perfect_days  unacast_session_count     hpi  \\\n",
       "0           0.0                   90.0  244.20   \n",
       "1           4.0                   27.0  258.95   \n",
       "2           4.0                   27.0  258.95   \n",
       "3           3.0                   24.0  258.95   \n",
       "4           0.0                   12.0  258.95   \n",
       "\n",
       "   state_and_local_amount_per_capita  state_amount_per_capita  \\\n",
       "0                           0.157475                 0.009783   \n",
       "1                           0.157475                 0.009783   \n",
       "2                           0.157475                 0.009783   \n",
       "3                           0.157475                 0.009783   \n",
       "4                           0.157475                 0.009783   \n",
       "\n",
       "   local_amount_per_capita  \n",
       "0                 0.147692  \n",
       "1                 0.147692  \n",
       "2                 0.147692  \n",
       "3                 0.147692  \n",
       "4                 0.147692  \n",
       "\n",
       "[5 rows x 861 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download the data\n",
    "df = pd.read_csv('../data/train_data.zip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(group=[]):\n",
    "    \"\"\"\n",
    "    Preprocess the data but doesn't run OHE on the column used as an argument\n",
    "    \n",
    "    Parameters\n",
    "    ---------     \n",
    "    group : list of one string representing either 'income_class', 'density_class' or 'climate'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (X_train_valid, y_train, y_valid) : a tuple with a tuple containing the preprocessed X_train and X_valid, \n",
    "                                        the preprocessed y_train and the preprocessed y_valid\n",
    "        \n",
    "    \"\"\"\n",
    "    df = pd.read_csv('../data/train_data.zip')\n",
    "    df = drop_missing_unacast(df)\n",
    "    # create X and y\n",
    "    X = df.drop('unacast_session_count', axis=1)\n",
    "    y = df.loc[:, 'unacast_session_count']\n",
    "    # split the data\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                        test_size=0.2,\n",
    "                                                          random_state=2020)\n",
    "    # impute NaN values\n",
    "    result = impute_data(X_train, X_valid)\n",
    "    X_train = result[0]\n",
    "    X_valid = result[1] \n",
    "    # perform feature eng\n",
    "    X_train = comb_cols(X_train)\n",
    "    X_valid = comb_cols(X_valid)\n",
    "    # perform dropping\n",
    "    X_train = drop_columns(X_train)\n",
    "    X_valid = drop_columns(X_valid)\n",
    "    X_train = X_train.drop(columns=['monthly_rain', 'monthly_avg_rain_length'])\n",
    "    X_valid = X_valid.drop(columns=['monthly_rain', 'monthly_avg_rain_length'])\n",
    "\n",
    "    #perform scaling of the numerical variables\n",
    "    categorical_features = X_train.loc[:, X_train.dtypes == \"object\"]\n",
    "    categorical_features.columns\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train.drop(columns = list(categorical_features.columns)))\n",
    "    X_valid_scaled = scaler.transform(X_valid.drop(columns = list(categorical_features.columns)))\n",
    "\n",
    "    X_train = pd.concat([pd.DataFrame(X_train_scaled, \n",
    "                                      index=X_train.index, \n",
    "                                      columns=X_train.drop(columns = list(categorical_features.columns)).columns), \n",
    "                         X_train[list(categorical_features.columns)]], axis=1)\n",
    "    X_valid = pd.concat([pd.DataFrame(X_valid_scaled, \n",
    "                                      index=X_valid.index, \n",
    "                                      columns=X_train.drop(columns = list(categorical_features.columns)).columns), \n",
    "                         X_valid[list(categorical_features.columns)]], axis=1)\n",
    "\n",
    "\n",
    "    # perform OHE (climate, density_class, income_class)\n",
    "    list_cat = ['income_class', 'density_class', 'climate']\n",
    "    for cat in list_cat:\n",
    "        if cat in group:\n",
    "            list_cat.remove(cat)\n",
    "    X_train_valid = clean_categorical(X_train, X_valid, list_cat)\n",
    "    return(X_train_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39592, 628)\n",
      "(9898, 628)\n"
     ]
    }
   ],
   "source": [
    "X_train_valid=preprocessing(['climate'])\n",
    "X_train = X_train_valid[0]\n",
    "X_valid = X_train_valid[1]\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate X and y for the train\n",
    "train = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caution** : The following cell takes a very long time to run (2 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-fdf664597cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixedlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unacast_session_count ~ \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_var\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"climate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mmdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mto_drop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, reml, niter_sa, do_cg, fe_pen, cov_pen, free, full_output, method, **kwargs)\u001b[0m\n\u001b[1;32m   2104\u001b[0m                                                 \u001b[0mskip_hessian\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m                                                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m                                                 **kwargs)\n\u001b[0m\u001b[1;32m   2107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrslt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmle_retvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'converged'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m                                                        \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                                                        \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m                                                        full_output=full_output)\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# NOTE: this is for fit_regularized and should be generalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                             \u001b[0mretall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                             hess=hessian)\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         optim_settings = {'optimizer': method, 'start_params': start_params,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/optimizer.py\u001b[0m in \u001b[0;36m_fit_bfgs\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                  \u001b[0mgtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                                  \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                                  disp=disp, retall=retall, callback=callback)\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mretall\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfmin_bfgs\u001b[0;34m(f, x0, fprime, args, gtol, norm, epsilon, maxiter, full_output, disp, retall, callback)\u001b[0m\n\u001b[1;32m    950\u001b[0m             'return_all': retall}\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0malpha_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n\u001b[0;32m-> 1028\u001b[0;31m                                           old_fval, old_old_fval, amin=1e-100, amax=1e100)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;31m# Line search failed to find a better solution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m    844\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mextra_condition\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[1;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mderphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mderphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnewargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, params, profile_fe)\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_sqrt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             score_fe, score_re, score_vc = self.score_sqrt(\n\u001b[0;32m-> 1569\u001b[0;31m                 params, calc_fe=not profile_fe)\n\u001b[0m\u001b[1;32m   1570\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m             score_fe, score_re, score_vc = self.score_full(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py\u001b[0m in \u001b[0;36mscore_sqrt\u001b[0;34m(self, params, calc_fe)\u001b[0m\n\u001b[1;32m   1768\u001b[0m         \"\"\"\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m         \u001b[0mscore_fe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_re\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_vc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_fe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_fe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1771\u001b[0m         \u001b[0mparams_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_sqrt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_fe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py\u001b[0m in \u001b[0;36mscore_full\u001b[0;34m(self, params, calc_fe)\u001b[0m\n\u001b[1;32m   1679\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m                 \u001b[0mviexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m                 \u001b[0mxtvix\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mviexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m             \u001b[0;31m# Contributions to the covariance parameter gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Find the columns that make the fit function fail\n",
    "# i and to_drop were updated with the last values the function would gave everytime the connection with the kernel would stop and the algorithm would stop running\n",
    "i= 142\n",
    "to_drop=['unacast_session_count', 'monthly_repeated_sessions', 'B23008e21', 'B23008e23', 'B12001e11', 'B23008e26', \n",
    "         'B11005e14', 'B11005e17', 'B20004e9', 'B19101e7', 'B19101e4', 'B12001e15', 'B09002e19', 'B23008e27', 'B20004e7', \n",
    "         'B11016e10', 'B17012e31', 'B19101e8', 'C18108e5', 'B25012e8', 'B25012e15', 'B17020e4', 'B25012e16', 'B25012e10', \n",
    "         'B25012e6', 'B09002e17', 'B25012e12', 'B25012e11', 'B08301e6', 'B17012e6', 'B19101e6', 'B25012e4', 'B19101e12', \n",
    "         'B17020e5', 'B23008e18', 'B19101e5', 'B12001e16', 'B08303e12', 'B17020e11', 'B10010e1', 'B19101e11', 'B08303e13', \n",
    "         'B16007e5', 'B19101e16', 'B11016e12', 'B17020e3', 'B19101e3', 'B25012e14', 'B09002e18', 'B17012e2', 'B19101e2', \n",
    "         'B25012e5', 'B17012e5', 'B10010e2', 'B11005e4', 'B19101e15', 'B11005e5', 'B19101e17', 'B17012e4', 'B17012e7', \n",
    "         'B20004e8', 'B17020e10', 'B09018e8', 'B20004e6', 'B17020e6', 'B10002e5', 'B11016e11', 'B10002e3', 'B17012e26', \n",
    "         'B25012e3', 'B11005e10', 'B08301e5', 'B17012e25', 'B17012e20', 'B08301e4', 'B19101e13', 'B10002e4', 'B23008e13', \n",
    "         'C18108e3', 'B09018e7', 'B11001e9', 'B10002e1', 'C18108e4', 'B23008e19', 'B10010e3', 'B16007e7', 'B23008e12', \n",
    "         'B15003e23', 'B15003e25', 'B11005e6', 'B11003e7', 'B27003e1', 'B15003e20', 'B09018e1', 'B11016e3', 'B01001e4', \n",
    "         'B11016e2', 'B15003e21', 'B15003e22', 'B19083e1', 'B15003e24', 'B23020e1', 'B11016e4', 'B09018e5', 'B19125e2', \n",
    "         'B16007e3', 'B01001e28', 'B23020e3', 'B23020e2', 'B12001e6', 'B27001e30', 'B01001e29', 'B25103e2', 'B16007e4', \n",
    "         'B12001e9', 'B23008e10', 'B09018e4', 'B01001e30', 'B11003e5', 'B23008e2', 'B23008e5', 'B09002e16', 'B25012e9', \n",
    "         'B01002e3', 'B20004e5', 'B25012e2', 'B08303e1', 'B23025e4', 'B23008e4', 'B23025e7', 'B12001e1', 'B15003e17', \n",
    "         'B11005e7', 'B01001e3', 'B23025e2', 'B09002e8', 'B22003e5', 'B08301e1']\n",
    "\n",
    "columns=list(train.columns)\n",
    "# remove the columns that have been dropped during the previous iterations of the program, before the connection with the kernel stopped\n",
    "for name in to_drop:\n",
    "    columns.remove(name)\n",
    "\n",
    "#ML_MAE is going to store the MAE every time the mixed effects model runs\n",
    "ML_MAE = {'number_col':[], 'MAE':[]}\n",
    "\n",
    "while i < (train.shape[1] - len(to_drop)):\n",
    "    #col contains the features we want to train our model on\n",
    "    col = columns[:i+1]\n",
    "    col = '+'.join(col)\n",
    "    print(i)\n",
    "    #run the mixed effect model\n",
    "    try:\n",
    "        md = smf.mixedlm(\"unacast_session_count ~ \" + col, train, groups=train[\"climate\"])\n",
    "        mdf = md.fit(method=['bfgs', 'lbfgs', 'cg', 'bfgs'])\n",
    "    #if the model throws an error when it runs\n",
    "    except np.linalg.LinAlgError:\n",
    "        #drop the last feature that was added\n",
    "        to_drop.append(columns[i])\n",
    "        print('removed', to_drop[1:])\n",
    "        columns.remove(columns[i])\n",
    "    else:\n",
    "        MAE = metrics.mean_absolute_error(y_train, mdf.predict(train))\n",
    "        ML_MAE['number_col'].append(i)\n",
    "        ML_MAE['MAE'].append(MAE)\n",
    "        i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete the columns found in the previous cell from the list of features\n",
    "to_delete = ['monthly_repeated_sessions', 'B23008e21', 'B23008e23', 'B12001e11', 'B23008e26', 'B11005e14', 'B11005e17', \n",
    "             'B20004e9', 'B19101e7', 'B19101e4', 'B12001e15', 'B09002e19', 'B23008e27', 'B20004e7', 'B11016e10', 'B17012e31', \n",
    "             'B19101e8', 'C18108e5', 'B25012e8', 'B25012e15', 'B17020e4', 'B25012e16', 'B25012e10', 'B25012e6', 'B09002e17',\n",
    "             'B25012e12', 'B25012e11', 'B08301e6', 'B17012e6', 'B19101e6', 'B25012e4', 'B19101e12', 'B17020e5', 'B23008e18', \n",
    "             'B19101e5', 'B12001e16', 'B08303e12', 'B17020e11', 'B10010e1', 'B19101e11', 'B08303e13', 'B16007e5', 'B19101e16', \n",
    "             'B11016e12', 'B17020e3', 'B19101e3', 'B25012e14', 'B09002e18', 'B17012e2', 'B19101e2', 'B25012e5', 'B17012e5', \n",
    "             'B10010e2', 'B11005e4', 'B19101e15', 'B11005e5', 'B19101e17', 'B17012e4', 'B17012e7', 'B20004e8', 'B17020e10', \n",
    "             'B09018e8', 'B20004e6', 'B17020e6', 'B10002e5', 'B11016e11', 'B10002e3', 'B17012e26', 'B25012e3', 'B11005e10', \n",
    "             'B08301e5', 'B17012e25', 'B17012e20', 'B08301e4', 'B19101e13', 'B10002e4', 'B23008e13', 'C18108e3', 'B09018e7', \n",
    "             'B11001e9', 'B10002e1', 'C18108e4', 'B23008e19', 'B10010e3', 'B16007e7', 'B23008e12', 'B15003e23', 'B15003e25', \n",
    "             'B11005e6', 'B11003e7', 'B27003e1', 'B15003e20', 'B09018e1', 'B11016e3', 'B01001e4', 'B11016e2', 'B15003e21', \n",
    "             'B15003e22', 'B19083e1', 'B15003e24', 'B23020e1', 'B11016e4', 'B09018e5', 'B19125e2', 'B16007e3', 'B01001e28', \n",
    "             'B23020e3', 'B23020e2', 'B12001e6', 'B27001e30', 'B01001e29', 'B25103e2', 'B16007e4', 'B12001e9', 'B23008e10', \n",
    "             'B09018e4', 'B01001e30', 'B11003e5', 'B23008e2', 'B23008e5', 'B09002e16', 'B25012e9', 'B01002e3', 'B20004e5', \n",
    "             'B25012e2', 'B08303e1', 'B23025e4', 'B23008e4', 'B23025e7', 'B12001e1', 'B15003e17', 'B11005e7', 'B01001e3', \n",
    "             'B23025e2', 'B09002e8', 'B22003e5', 'B08301e1', 'B14002e1', 'B09002e11', 'B27001e2', 'B25064e1', 'B25001e1', \n",
    "             'B19058e2', 'B09001e5', 'B09002e10', 'B09002e13', 'B09002e12', 'B19301e1', 'B25119e2', 'B19125e3', 'B13016e4', \n",
    "             'B11001e5', 'B25119e3', 'B15003e18', 'B01001e27', 'B13016e5', 'B11005e9', 'B20004e2', 'B15003e1', 'B10001e4', \n",
    "             'B11001e6', 'B13016e7', 'B12001e7', 'B23008e9', 'B13016e6', 'B23008e7', 'B23008e6', 'B09002e14', 'B09001e10', \n",
    "             'B11005e8', 'B13016e3', 'male_60_69', 'male_80_over', 'female_22_29', 'female_30_39', 'female_40_49', \n",
    "             'female_50_59', 'female_60_69', 'female_70_79', 'female_80_over', 'total_enrolled', 'not_enrolled', \n",
    "             'enrolled_nursery_pre_private', 'enrolled_kinder_public', 'enrolled_kinder_private', 'enrolled_grades_1_4_public', \n",
    "             'enrolled_grades_1_4_private', 'enrolled_grades_5_8_public', 'enrolled_grades_9_12_private', \n",
    "             'enrolled_undergrad_public', 'enrolled_undergrad_private', 'enrolled_graduate_public', 'less_than_12_no_diploma', \n",
    "             'travel_15_minutes_less', 'travel_15_29_minutes', 'travel_30_44_minutes', 'single_under_6', 'single_0_to_17', \n",
    "             'single_6_to_17', 'single_no_kids', 'four_or_more_in_family_household', 'four_or_more_in_nonfamily_household', \n",
    "             'men_without_health_insurance', 'women_with_health_insurnace', 'women_without_health_insurance', \n",
    "             'avg_birth_weight', 'avg_age_of_mother', 'longitude', 'latitude', 'alcohol', 'amenity', 'bank', 'bar', 'cafe', \n",
    "             'camp_site', 'car_repair', 'childcare', 'clothes_store', 'convenience_store', 'fast_food', 'fire_station', \n",
    "             'fitness_or_sports_centre', 'fuel', 'healthcare', 'hotel', 'museum_or_gallery', 'restaurant', 'shop', \n",
    "             'supermarket', 'tourism', 'distance_to_U', 'distance_to_nearest_school', 'walk_score', 'bike_score', 'k_avg', \n",
    "             'streets_per_node_avg', 'edge_length_total', 'edge_length_avg', 'street_length_avg', \n",
    "             'streets_per_node_counts_2', 'streets_per_node_counts_3', 'streets_per_node_counts_5', 'n_osdw', \n",
    "             'k_avg_osdw', 'streets_per_node_avg_osdw', 'edge_length_total_osdw', 'streets_per_node_counts_1_osdw', \n",
    "             'streets_per_node_counts_3_osdw', 'streets_per_node_counts_5_osdw', 'intersection_count_osid', \n",
    "             'edge_length_total_osid', 'edge_length_avg_osid', 'street_length_total_osid', 'street_segments_count_osid', \n",
    "             'streets_per_node_counts_1_osid', 'streets_per_node_counts_2_osid', 'streets_per_node_counts_4_osid', \n",
    "             'streets_per_node_counts_5_osid', 'violent_crime', 'criminal_homicide', 'rape', 'robbery', \n",
    "             'aggravated_assault', 'property_crime', 'burglary', 'larceny_theft', 'motor_vehicle_theft', \n",
    "             'houses_per_sq_km', 'historic_number_of_sessions', 'historic_sessions_per_day', 'historic_unique_sessions', \n",
    "             'historic_unique_sessions_per_day', 'historic_repeat_sessions', 'historic_repeat_sessions_per_day', \n",
    "             'historic_total_session_length', 'historic_avg_session_length', 'historic_avg_light_activity', \n",
    "             'historic_avg_moderate_activity', 'historic_avg_vigorous_activity', 'historic_avg_mod_plus_vig', \n",
    "             'historic_hour_7', 'historic_hour_8', 'historic_hour_9', 'historic_hour_10', 'historic_hour_11', \n",
    "             'historic_hour_13', 'historic_hour_14', 'historic_hour_15', 'historic_hour_16', 'historic_hour_17', \n",
    "             'historic_hour_19', 'historic_hour_20', 'historic_rain', 'historic_foggy', 'historic_snow', 'Green_2016', \n",
    "             'Libertarians_2016', 'Poor_physical_health_days', 'Adult_smoking', 'Adult_obesity', 'weather_clear', \n",
    "             'weather_rain', 'weather_fog', 'temp_avg_35_below', 'temp_max_35_below', 'temp_max_45_55', \n",
    "             'state_amount_per_capita', 'historic_slide_count_comb', 'monthly_climb_count_comb', 'monthly_tube_count_comb', \n",
    "             'historic_tube_count_comb', 'monthly_overhang_count_comb', 'historic_overhang_count_comb', \n",
    "             'monthly_bridge_count_comb', 'historic_bridge_count_comb', 'monthly_swing_count_comb', \n",
    "             'historic_swing_count_comb', 'historic_obsta_count_comb', 'historic_crawls_count_comb', \n",
    "             'monthly_hour_night', 'historic_hour_night', 'avg_wind_calm', 'avg_wind_light_air', 'avg_wind_light_br', \n",
    "             'avg_wind_gentle_br', 'avg_wind_moderate_br', 'monthly_ws_calm', 'monthly_ws_light_air', 'monthly_ws_light_br', \n",
    "             'monthly_ws_gentle_br', 'monthly_ws_moderate_br', 'historic_ws_calm', 'historic_ws_light_air', \n",
    "             'historic_ws_light_br', 'historic_ws_gentle_br', 'historic_ws_moderate_br', 'avg_fertility_rate', 'HI', 'LI', \n",
    "             'MI', 'HD', 'LD', 'MD']\n",
    "train = train.drop(columns = to_delete)\n",
    "valid = X_valid.drop(columns=to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The new set of columns we are going to work with\n",
    "cols =  '+'.join(list(train.columns)[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['climate', 'unacast_session_count']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train.columns)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 39592 entries, 28601 to 42347\n",
      "Columns: 286 entries, month to climate\n",
      "dtypes: float64(285), object(1)\n",
      "memory usage: 87.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_var.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, all the features that are deleted were found in the cell above that tried to find all the columns that make the model not converge\n",
    "def run_MLE(group=[]):\n",
    "    \"\"\"\n",
    "    Run the Mixed effects model using the grouped passed as an argument\n",
    "    \n",
    "    Parameters\n",
    "    ---------     \n",
    "    group: list containing one categorical column to use to cluster the playgrounds\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple with 2 lists : the first list contains the train and validation RMSE, the seconde one contains the train and validation MAE\n",
    "    \"\"\"\n",
    "    #preprocess the data\n",
    "    X_train_valid_y=preprocessing(group)\n",
    "    X_train_valid =  X_train_valid_y[0]\n",
    "    y_train =  X_train_valid_y[1]\n",
    "    y_valid =  X_train_valid_y[2]\n",
    "    X_train = X_train_valid[0]\n",
    "    X_valid = X_train_valid[1]\n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    to_delete = ['monthly_repeated_sessions', 'B23008e21', 'B23008e23', 'B12001e11', 'B23008e26', 'B11005e14', 'B11005e17', \n",
    "                 'B20004e9', 'B19101e7', 'B19101e4', 'B12001e15', 'B09002e19', 'B23008e27', 'B20004e7', 'B11016e10', 'B17012e31', \n",
    "                 'B19101e8', 'C18108e5', 'B25012e8', 'B25012e15', 'B17020e4', 'B25012e16', 'B25012e10', 'B25012e6', 'B09002e17',\n",
    "                 'B25012e12', 'B25012e11', 'B08301e6', 'B17012e6', 'B19101e6', 'B25012e4', 'B19101e12', 'B17020e5', 'B23008e18', \n",
    "                 'B19101e5', 'B12001e16', 'B08303e12', 'B17020e11', 'B10010e1', 'B19101e11', 'B08303e13', 'B16007e5', 'B19101e16', \n",
    "                 'B11016e12', 'B17020e3', 'B19101e3', 'B25012e14', 'B09002e18', 'B17012e2', 'B19101e2', 'B25012e5', 'B17012e5', \n",
    "                 'B10010e2', 'B11005e4', 'B19101e15', 'B11005e5', 'B19101e17', 'B17012e4', 'B17012e7', 'B20004e8', 'B17020e10', \n",
    "                 'B09018e8', 'B20004e6', 'B17020e6', 'B10002e5', 'B11016e11', 'B10002e3', 'B17012e26', 'B25012e3', 'B11005e10', \n",
    "                 'B08301e5', 'B17012e25', 'B17012e20', 'B08301e4', 'B19101e13', 'B10002e4', 'B23008e13', 'C18108e3', 'B09018e7', \n",
    "                 'B11001e9', 'B10002e1', 'C18108e4', 'B23008e19', 'B10010e3', 'B16007e7', 'B23008e12', 'B15003e23', 'B15003e25', \n",
    "                 'B11005e6', 'B11003e7', 'B27003e1', 'B15003e20', 'B09018e1', 'B11016e3', 'B01001e4', 'B11016e2', 'B15003e21', \n",
    "                 'B15003e22', 'B19083e1', 'B15003e24', 'B23020e1', 'B11016e4', 'B09018e5', 'B19125e2', 'B16007e3', 'B01001e28', \n",
    "                 'B23020e3', 'B23020e2', 'B12001e6', 'B27001e30', 'B01001e29', 'B25103e2', 'B16007e4', 'B12001e9', 'B23008e10', \n",
    "                 'B09018e4', 'B01001e30', 'B11003e5', 'B23008e2', 'B23008e5', 'B09002e16', 'B25012e9', 'B01002e3', 'B20004e5', \n",
    "                 'B25012e2', 'B08303e1', 'B23025e4', 'B23008e4', 'B23025e7', 'B12001e1', 'B15003e17', 'B11005e7', 'B01001e3', \n",
    "                 'B23025e2', 'B09002e8', 'B22003e5', 'B08301e1', 'B14002e1', 'B09002e11', 'B27001e2', 'B25064e1', 'B25001e1', \n",
    "                 'B19058e2', 'B09001e5', 'B09002e10', 'B09002e13', 'B09002e12', 'B19301e1', 'B25119e2', 'B19125e3', 'B13016e4', \n",
    "                 'B11001e5', 'B25119e3', 'B15003e18', 'B01001e27', 'B13016e5', 'B11005e9', 'B20004e2', 'B15003e1', 'B10001e4', \n",
    "                 'B11001e6', 'B13016e7', 'B12001e7', 'B23008e9', 'B13016e6', 'B23008e7', 'B23008e6', 'B09002e14', 'B09001e10', \n",
    "                 'B11005e8', 'B13016e3', 'male_60_69', 'male_80_over', 'female_22_29', 'female_30_39', 'female_40_49', \n",
    "                 'female_50_59', 'female_60_69', 'female_70_79', 'female_80_over', 'total_enrolled', 'not_enrolled', \n",
    "                 'enrolled_nursery_pre_private', 'enrolled_kinder_public', 'enrolled_kinder_private', 'enrolled_grades_1_4_public', \n",
    "                 'enrolled_grades_1_4_private', 'enrolled_grades_5_8_public', 'enrolled_grades_9_12_private', \n",
    "                 'enrolled_undergrad_public', 'enrolled_undergrad_private', 'enrolled_graduate_public', 'less_than_12_no_diploma', \n",
    "                 'travel_15_minutes_less', 'travel_15_29_minutes', 'travel_30_44_minutes', 'single_under_6', 'single_0_to_17', \n",
    "                 'single_6_to_17', 'single_no_kids', 'four_or_more_in_family_household', 'four_or_more_in_nonfamily_household', \n",
    "                 'men_without_health_insurance', 'women_with_health_insurnace', 'women_without_health_insurance', \n",
    "                 'avg_birth_weight', 'avg_age_of_mother', 'longitude', 'latitude', 'alcohol', 'amenity', 'bank', 'bar', 'cafe', \n",
    "                 'camp_site', 'car_repair', 'childcare', 'clothes_store', 'convenience_store', 'fast_food', 'fire_station', \n",
    "                 'fitness_or_sports_centre', 'fuel', 'healthcare', 'hotel', 'museum_or_gallery', 'restaurant', 'shop', \n",
    "                 'supermarket', 'tourism', 'distance_to_U', 'distance_to_nearest_school', 'walk_score', 'bike_score', 'k_avg', \n",
    "                 'streets_per_node_avg', 'edge_length_total', 'edge_length_avg', 'street_length_avg', \n",
    "                 'streets_per_node_counts_2', 'streets_per_node_counts_3', 'streets_per_node_counts_5', 'n_osdw', \n",
    "                 'k_avg_osdw', 'streets_per_node_avg_osdw', 'edge_length_total_osdw', 'streets_per_node_counts_1_osdw', \n",
    "                 'streets_per_node_counts_3_osdw', 'streets_per_node_counts_5_osdw', 'intersection_count_osid', \n",
    "                 'edge_length_total_osid', 'edge_length_avg_osid', 'street_length_total_osid', 'street_segments_count_osid', \n",
    "                 'streets_per_node_counts_1_osid', 'streets_per_node_counts_2_osid', 'streets_per_node_counts_4_osid', \n",
    "                 'streets_per_node_counts_5_osid', 'violent_crime', 'criminal_homicide', 'rape', 'robbery', \n",
    "                 'aggravated_assault', 'property_crime', 'burglary', 'larceny_theft', 'motor_vehicle_theft', \n",
    "                 'houses_per_sq_km', 'historic_number_of_sessions', 'historic_sessions_per_day', 'historic_unique_sessions', \n",
    "                 'historic_unique_sessions_per_day', 'historic_repeat_sessions', 'historic_repeat_sessions_per_day', \n",
    "                 'historic_total_session_length', 'historic_avg_session_length', 'historic_avg_light_activity', \n",
    "                 'historic_avg_moderate_activity', 'historic_avg_vigorous_activity', 'historic_avg_mod_plus_vig', \n",
    "                 'historic_hour_7', 'historic_hour_8', 'historic_hour_9', 'historic_hour_10', 'historic_hour_11', \n",
    "                 'historic_hour_13', 'historic_hour_14', 'historic_hour_15', 'historic_hour_16', 'historic_hour_17', \n",
    "                 'historic_hour_19', 'historic_hour_20', 'historic_rain', 'historic_foggy', 'historic_snow', 'Green_2016', \n",
    "                 'Libertarians_2016', 'Poor_physical_health_days', 'Adult_smoking', 'Adult_obesity', 'weather_clear', \n",
    "                 'weather_rain', 'weather_fog', 'temp_avg_35_below', 'temp_max_35_below', 'temp_max_45_55', \n",
    "                 'state_amount_per_capita', 'historic_slide_count_comb', 'monthly_climb_count_comb', 'monthly_tube_count_comb', \n",
    "                 'historic_tube_count_comb', 'monthly_overhang_count_comb', 'historic_overhang_count_comb', \n",
    "                 'monthly_bridge_count_comb', 'historic_bridge_count_comb', 'monthly_swing_count_comb', \n",
    "                 'historic_swing_count_comb', 'historic_obsta_count_comb', 'historic_crawls_count_comb', \n",
    "                 'monthly_hour_night', 'historic_hour_night', 'avg_wind_calm', 'avg_wind_light_air', 'avg_wind_light_br', \n",
    "                 'avg_wind_gentle_br', 'avg_wind_moderate_br', 'monthly_ws_calm', 'monthly_ws_light_air', 'monthly_ws_light_br', \n",
    "                 'monthly_ws_gentle_br', 'monthly_ws_moderate_br', 'historic_ws_calm', 'historic_ws_light_air', \n",
    "                 'historic_ws_light_br', 'historic_ws_gentle_br', 'historic_ws_moderate_br', 'avg_fertility_rate', 'HI', 'LI', \n",
    "                 'MI', 'HD', 'LD', 'MD', 'A', 'C', 'D']\n",
    "    \n",
    "    if 'income_class' in group:\n",
    "        for feat in ['MI', 'HD', 'LD', 'MD', 'HI', 'LI']:\n",
    "            to_delete.remove(feat)\n",
    "    elif 'density_class' in group:\n",
    "        for feat in ['HD', 'LD', 'MD']:\n",
    "            to_delete.remove(feat)\n",
    "    elif 'climate' in group:\n",
    "        for feat in ['A', 'C', 'D']:\n",
    "            to_delete.remove(feat)\n",
    "    \n",
    "    train = train.drop(columns = to_delete)\n",
    "    valid = X_valid.drop(columns=to_delete)\n",
    "    \n",
    "    cols = list(train.columns)\n",
    "    cols.remove('unacast_session_count')\n",
    "    for col in group:\n",
    "        cols.remove(col)\n",
    "    cols =  '+'.join(cols)\n",
    "    #run the model\n",
    "    md = smf.mixedlm('unacast_session_count ~ ' + cols, data = train, groups=train[group[0]])\n",
    "    mdf = md.fit(method=['bfgs', 'lbfgs', 'cg', 'bfgs'])\n",
    "    \n",
    "    return(report_performance(mdf, X_train, y_train, X_valid, y_valid, mode='mean', floor=True),\n",
    "    report_performance(mdf, X_train, y_train, X_valid, y_valid, mode='median', floor=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['climate', 'unacast_session_count']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with cg\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with bfgs\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2118: ConvergenceWarning: MixedLM optimization failed, trying a different optimizer may help.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2130: ConvergenceWarning: Gradient optimization failed, |grad| = 1.265963\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2170: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training root mean squared error: 198.08289093303287\n",
      "Validation root mean squared error: 203.1055499417757\n",
      "Training mean absolute error: 99.0338783002849\n",
      "Validation mean absolute error: 99.73981748123848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([198.08289093303287, 203.1055499417757],\n",
       " [99.0338783002849, 99.73981748123848])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_MLE(['climate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with cg\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with bfgs\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2118: ConvergenceWarning: MixedLM optimization failed, trying a different optimizer may help.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2130: ConvergenceWarning: Gradient optimization failed, |grad| = 2.393701\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2170: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training root mean squared error: 198.49880816751818\n",
      "Validation root mean squared error: 203.87057935663918\n",
      "Training mean absolute error: 101.07085398250304\n",
      "Validation mean absolute error: 101.8901470520564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with cg\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with bfgs\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2118: ConvergenceWarning: MixedLM optimization failed, trying a different optimizer may help.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2130: ConvergenceWarning: Gradient optimization failed, |grad| = 4.447124\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2170: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training root mean squared error: 198.52776081779135\n",
      "Validation root mean squared error: 203.55110773018416\n",
      "Training mean absolute error: 100.06061172546366\n",
      "Validation mean absolute error: 100.68693529498546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with cg\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2114: ConvergenceWarning: Retrying MixedLM optimization with bfgs\n",
      "  ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2118: ConvergenceWarning: MixedLM optimization failed, trying a different optimizer may help.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2130: ConvergenceWarning: Gradient optimization failed, |grad| = 1.265963\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/ubuntu/.local/share/virtualenvs/capstone_machine_learning-9cUIoDBU/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2170: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training root mean squared error: 198.08289093303287\n",
      "Validation root mean squared error: 203.1055499417757\n",
      "Training mean absolute error: 99.0338783002849\n",
      "Validation mean absolute error: 99.73981748123848\n"
     ]
    }
   ],
   "source": [
    "results={'group':[], 'data':[], 'type':[], 'error':[]}\n",
    "list_type=['RMSE', 'MAE']\n",
    "list_data=['train', 'validation']\n",
    "for var in [['income_class'], ['density_class'], ['climate']]:\n",
    "    error = run_MLE(var)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            results['group'].append(var[0])\n",
    "            results['data'].append(list_data[j])\n",
    "            results['type'].append(list_type[i])\n",
    "            results['error'].append(error[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>data</th>\n",
       "      <th>type</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>income_class</td>\n",
       "      <td>train</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>198.498808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>income_class</td>\n",
       "      <td>validation</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>203.870579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>income_class</td>\n",
       "      <td>train</td>\n",
       "      <td>MAE</td>\n",
       "      <td>101.070854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>income_class</td>\n",
       "      <td>validation</td>\n",
       "      <td>MAE</td>\n",
       "      <td>101.890147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>density_class</td>\n",
       "      <td>train</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>198.527761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>density_class</td>\n",
       "      <td>validation</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>203.551108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>density_class</td>\n",
       "      <td>train</td>\n",
       "      <td>MAE</td>\n",
       "      <td>100.060612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>density_class</td>\n",
       "      <td>validation</td>\n",
       "      <td>MAE</td>\n",
       "      <td>100.686935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>climate</td>\n",
       "      <td>train</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>198.082891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>climate</td>\n",
       "      <td>validation</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>203.105550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>climate</td>\n",
       "      <td>train</td>\n",
       "      <td>MAE</td>\n",
       "      <td>99.033878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>climate</td>\n",
       "      <td>validation</td>\n",
       "      <td>MAE</td>\n",
       "      <td>99.739817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            group        data  type       error\n",
       "0    income_class       train  RMSE  198.498808\n",
       "1    income_class  validation  RMSE  203.870579\n",
       "2    income_class       train   MAE  101.070854\n",
       "3    income_class  validation   MAE  101.890147\n",
       "4   density_class       train  RMSE  198.527761\n",
       "5   density_class  validation  RMSE  203.551108\n",
       "6   density_class       train   MAE  100.060612\n",
       "7   density_class  validation   MAE  100.686935\n",
       "8         climate       train  RMSE  198.082891\n",
       "9         climate  validation  RMSE  203.105550\n",
       "10        climate       train   MAE   99.033878\n",
       "11        climate  validation   MAE   99.739817"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** : So far, I only ran the MLE model grouping by the 'income_class', 'density_class' and 'climate' features, but the results were not very good (validation RMSE around 200 and validation MAE around 100). Future improvements could be made, for example it could be a good idea to try to cluster the playgrounds using more than one feature (or use some numerical features and binning them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_machine_learning",
   "language": "python",
   "name": "capstone_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
