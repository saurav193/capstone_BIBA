{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('unacast_session_count', axis=1)\n",
    "y = df.loc[:, 'unacast_session_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imputer(X_train):\n",
    "\n",
    "    \"\"\"\n",
    "    Fit all transformers using `X_train`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: pd.DataFrame\n",
    "        Training set\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sklearn.compose._column_transformer.ColumnTransformer\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #======================================\n",
    "    # IMPORT DATA FRAME\n",
    "    #======================================\n",
    "\n",
    "    df = pd.read_csv('../data/train_data.zip')\n",
    "\n",
    "    #======================================\n",
    "    # IDENTIFY COLUMNS TO IMPUTE\n",
    "    #======================================\n",
    "\n",
    "    # Impute with 0\n",
    "    monthly_count_equipment = df.loc[:, 'monthly_count_slide_single':'monthly_count_climber'].columns.to_list()\n",
    "    historic_session = df.loc[:, 'historic_number_of_sessions':'historic_avg_mod_plus_vig'].columns.to_list()\n",
    "    historic_hour = df.loc[:, 'historic_hour_0':'historic_hour_23'].columns.to_list()\n",
    "    historic_count_equipment = df.loc[:, 'historic_count_bridge':'historic_count_zipline'].columns.to_list()\n",
    "    historic_weather = df.loc[:, 'historic_cloudy':'historic_snow'].columns.to_list()\n",
    "    OSM = df.loc[:, 'n': 'streets_per_node_proportion_7_osid'].columns.to_list()\n",
    "    zero_misc = ['days_since_first_sess', 'perfect_days', 'Green_2016', 'Number_of_holidays']\n",
    "\n",
    "    zero_imp_features = monthly_count_equipment + historic_session + historic_hour \\\n",
    "                        + historic_count_equipment + historic_weather + OSM + zero_misc\n",
    "\n",
    "    # Impute with mean\n",
    "    weather = df.loc[:, 'weather_clear':'avg_wind_12_above'].columns.to_list()\n",
    "    mean_misc = ['walk_score', 'bike_score', 'Poor_physical_health_days', 'Poor_mental_health_days', 'Adult_smoking']\n",
    "\n",
    "    mean_imp_features = weather + mean_misc\n",
    "\n",
    "    #======================================\n",
    "    # CREATE TRANSFORMERS\n",
    "    #======================================\n",
    "\n",
    "    # Create transformer for 0 imputation\n",
    "    zero_transformer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "    # Create transformer for mean imputation\n",
    "    mean_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "    # Create transformer for `Republicans_08_Votes`\n",
    "    rep_08_votes_transformer = SimpleImputer(strategy='constant', fill_value=193841)\n",
    "\n",
    "    # Create transformer for `Democrats_08_Votes`\n",
    "    dem_08_votes_transformer = SimpleImputer(strategy='constant', fill_value=123594)\n",
    "\n",
    "    # Create transformer for `Republican_12_Votes`\n",
    "    rep_12_votes_transformer = SimpleImputer(strategy='constant', fill_value=164676)\n",
    "\n",
    "    # Create transformer for `Democrats_12_Votes`\n",
    "    dem_12_votes_transformer = SimpleImputer(strategy='constant', fill_value=122640)\n",
    "\n",
    "    # Create transformer for `Republicans_2016`\n",
    "    rep_2016_transformer = SimpleImputer(strategy='constant', fill_value=163387)\n",
    "\n",
    "    # Create transformer for `Democrats_2016`\n",
    "    dem_2016_transformer = SimpleImputer(strategy='constant', fill_value=116454)\n",
    "\n",
    "    # Create transformer for `Libertarians_2016`\n",
    "    lib_2016_transformer = SimpleImputer(strategy='constant', fill_value=18725)\n",
    "\n",
    "    #======================================\n",
    "    # PUTTING IT ALL TOGETHER\n",
    "    #======================================\n",
    "\n",
    "    imputer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('zero', zero_transformer, zero_imp_features),\n",
    "            ('mean', mean_transformer, mean_imp_features),\n",
    "            ('rep_08_votes', rep_08_votes_transformer, ['Republican_08_Votes']),\n",
    "            ('dem_08_votes', dem_08_votes_transformer, ['Democrats_08_Votes']),\n",
    "            ('rep_12_votes', rep_12_votes_transformer, ['Republican_12_Votes']),\n",
    "            ('dem_12_votes', dem_12_votes_transformer, ['Democrats_12_Votes']),\n",
    "            ('rep_2016', rep_2016_transformer, ['Republicans_2016']),\n",
    "            ('dem_2016', dem_2016_transformer, ['Democrats_2016']),\n",
    "            ('lib_2016', lib_2016_transformer, ['Libertarians_2016'])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    return imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(imputer, X_train, X_valid):\n",
    "    \"\"\"\n",
    "    Given a transformer fit on `X_train`, return the imputed dataframes.\n",
    "    \n",
    "    Note: add code later if you want to impute `X_test`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    imputer: sklearn.compose._column_transformer.ColumnTransformer\n",
    "        imputer\n",
    "    \n",
    "    X_train: pd.DataFrame\n",
    "        `X_train`\n",
    "        \n",
    "    X_valid: pd.DataFrame\n",
    "        `X_valid`\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "    \n",
    "    \"\"\"\n",
    "    imp_X_train = imputer.fit_transform(X_train)\n",
    "    imp_X_valid = imputer.transform(X_valid)\n",
    "        \n",
    "    cols = []\n",
    "    \n",
    "    # Grab column names of imputed features\n",
    "    for i in range(len(imputer.transformers_) - 1):\n",
    "        cols += imputer.transformers_[i][2]\n",
    "    \n",
    "    # Grab column names of features that were passed through unchanged\n",
    "    cols += [X_train.columns[i] for i in imputer.transformers_[-1][2]]\n",
    "    \n",
    "    # Grab old order of columns\n",
    "    old_cols = X_train.columns.to_list()\n",
    "    \n",
    "    # Create new dataframes\n",
    "    # Reshuffle column order of new dataframes to match old one\n",
    "    imp_X_train = pd.DataFrame(imp_X_train, columns=cols).reindex(columns=old_cols)\n",
    "    imp_X_valid = pd.DataFrame(imp_X_valid, columns=cols).reindex(columns=old_cols)\n",
    "    \n",
    "    imputed_dfs = (imp_X_train, imp_X_valid)\n",
    "    \n",
    "    return imputed_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_cols(input_df):\n",
    "\n",
    "    \"\"\"\n",
    "    This function takes the entire data(all cols) and combines some of them\n",
    "    into new features using expert knowledge.\n",
    "\n",
    "    Parameters\n",
    "    ---------------\n",
    "    input_df : pandas.DataFrame\n",
    "       the entire dataframe with all the columns that has been imputed\n",
    "        \n",
    "    Returns\n",
    "    ---------------\n",
    "    pandas.DataFrame\n",
    "        with new features combining some existing features\n",
    "    \"\"\"\n",
    "    output_df = input_df.copy()\n",
    "    \n",
    "    # create a list of equipments to group together\n",
    "    equipments = ['slide', 'climb', 'tube', 'overhang', 'bridge', 'swing', 'obsta', 'crawls']\n",
    "    \n",
    "    # create a dictionary of lists of columns to combine. \n",
    "    # 2 (monthly and historic) for each type of equipment\n",
    "    new_cols_list = {}\n",
    "    cols_to_drop = []\n",
    "    \n",
    "    for equipment in equipments:\n",
    "        new_cols_list[\"monthly_\"+equipment] = [i for i in input_df.columns if re.match('monthly_.*'+equipment+'.*', i)]\n",
    "        new_cols_list[\"historic_\"+equipment] = [i for i in input_df.columns if re.match('historic_.*'+equipment+'.*', i)]\n",
    "        if new_cols_list[\"monthly_\"+equipment] == []:\n",
    "            new_cols_list.pop(\"monthly_\"+equipment)\n",
    "            \n",
    "    for key, val in new_cols_list.items():\n",
    "        output_df[key+\"_count_comb\"] = np.sum(output_df.loc[:, val], axis=1)\n",
    "        cols_to_drop = cols_to_drop + val # add previous columns to list to drop\n",
    "        \n",
    "    \n",
    "    # combine wind speed columns by Beaufort scale\n",
    "    \n",
    "    # group together `avg_wind_*` columns\n",
    "    avg_wind_calm = 'avg_wind_0_1'\n",
    "    avg_wind_light_air = ['avg_wind_1_2','avg_wind_2_3','avg_wind_3_4']\n",
    "    avg_wind_light_br = ['avg_wind_4_5','avg_wind_5_6','avg_wind_6_7','avg_wind_7_8']\n",
    "    avg_wind_gentle_br = ['avg_wind_8_9','avg_wind_9_10','avg_wind_10_11','avg_wind_11_12']\n",
    "    avg_wind_moderate_br = 'avg_wind_12_above'\n",
    "    \n",
    "    output_df['avg_wind_calm'] = input_df[avg_wind_calm]\n",
    "    output_df['avg_wind_light_air'] = np.sum(input_df.loc[:, avg_wind_light_air], axis=1)\n",
    "    output_df['avg_wind_light_br'] = np.sum(input_df.loc[:, avg_wind_light_br], axis=1)\n",
    "    output_df['avg_wind_gentle_br'] = np.sum(input_df.loc[:, avg_wind_gentle_br], axis=1)\n",
    "    output_df['avg_wind_moderate_br'] = input_df[avg_wind_moderate_br]\n",
    "    \n",
    "    # group together `monthly_ws_*` columns\n",
    "    monthly_ws_calm = 'monthly_ws_below_2'\n",
    "    monthly_ws_light_air = 'monthly_ws_2_to_4'\n",
    "    monthly_ws_light_br = ['monthly_ws_4_to_6','monthly_ws_6_to_8']\n",
    "    monthly_ws_gentle_br = ['monthly_ws_8_to_10','monthly_ws_10_to_12']\n",
    "    monthly_ws_moderate_br = ['monthly_ws_12_to_14','monthly_ws_14_to_16','monthly_ws_above_16']\n",
    "    \n",
    "    output_df['monthly_ws_calm'] = input_df[monthly_ws_calm]\n",
    "    output_df['monthly_ws_light_air'] = input_df[monthly_ws_light_air]\n",
    "    output_df['monthly_ws_light_br'] = np.sum(input_df.loc[:, monthly_ws_light_br], axis=1)\n",
    "    output_df['monthly_ws_gentle_br'] = np.sum(input_df.loc[:, monthly_ws_gentle_br], axis=1)\n",
    "    output_df['monthly_ws_moderate_br'] = np.sum(input_df.loc[:, monthly_ws_moderate_br], axis=1)\n",
    "    \n",
    "    # group together `historic_ws_*` columns\n",
    "    historic_ws_calm = 'historic_ws_calm'\n",
    "    historic_ws_light_air = 'historic_ws_2_to_4'\n",
    "    historic_ws_light_br = ['historic_ws_4_to_6','historic_ws_6_to_8']\n",
    "    historic_ws_gentle_br = ['historic_ws_8_to_10','historic_ws_10_to_12']\n",
    "    historic_ws_moderate_br = ['historic_ws_12_to_14','historic_ws_14_to_16','historic_ws_above_16']\n",
    "    \n",
    "    output_df['historic_ws_calm'] = input_df[historic_ws_calm]\n",
    "    output_df['historic_ws_light_air'] = input_df[historic_ws_light_air]\n",
    "    output_df['historic_ws_light_br'] = np.sum(input_df.loc[:, historic_ws_light_br], axis=1)\n",
    "    output_df['historic_ws_gentle_br'] = np.sum(input_df.loc[:, historic_ws_gentle_br], axis=1)\n",
    "    output_df['historic_ws_moderate_br'] = np.sum(input_df.loc[:, historic_ws_moderate_br], axis=1)\n",
    "    \n",
    "    wind_cols_to_drop = avg_wind_calm + avg_wind_light_air + avg_wind_light_br + avg_wind_gentle_br + avg_wind_moderate_br \\\n",
    "                        + monthly_ws_calm + monthly_ws_light_air + monthly_ws_light_br + monthly_ws_gentle_br + monthly_ws_moderate_br \\\n",
    "                        + historic_ws_calm + historic_ws_light_air + historic_ws_light_br + historic_ws_gentle_br + historic_ws_moderate_br\n",
    "    \n",
    "    # drop wind-related columns    \n",
    "    output_df = output_df.drop(columns = wind_cols_to_drop)\n",
    "    \n",
    "    # drop old equipment count columns\n",
    "    output_df = output_df.drop(columns = cols_to_drop)                        \n",
    "    \n",
    "    # re-order columns so they match order of input data\n",
    "    \n",
    "    return len(wind_cols_to_drop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_machine_learning",
   "language": "python",
   "name": "capstone_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
