{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download libraries\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>monthly_number_of_sessions</th>\n",
       "      <th>monthly_unique_sessions</th>\n",
       "      <th>monthly_repeated_sessions</th>\n",
       "      <th>monthly_avg_length_of_session</th>\n",
       "      <th>monthly_avg_light_activity</th>\n",
       "      <th>monthly_avg_moderate_activity</th>\n",
       "      <th>monthly_avg_vigorous_activity</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_wind_9_10</th>\n",
       "      <th>avg_wind_10_11</th>\n",
       "      <th>avg_wind_11_12</th>\n",
       "      <th>avg_wind_12_above</th>\n",
       "      <th>perfect_days</th>\n",
       "      <th>unacast_session_count</th>\n",
       "      <th>hpi</th>\n",
       "      <th>state_and_local_amount_per_capita</th>\n",
       "      <th>state_amount_per_capita</th>\n",
       "      <th>local_amount_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900203</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>323.61</td>\n",
       "      <td>0.132207</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.113688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900203</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>323.61</td>\n",
       "      <td>0.132207</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.113688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900203</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>323.61</td>\n",
       "      <td>0.132207</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.113688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR00101775</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.38</td>\n",
       "      <td>0.076247</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.064281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MR00101775</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>110.38</td>\n",
       "      <td>0.076247</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.064281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  external_id  month  year  monthly_number_of_sessions  \\\n",
       "0     1900203      3  2019                           0   \n",
       "1     1900203      6  2018                           0   \n",
       "2     1900203      8  2018                           0   \n",
       "3  MR00101775      1  2019                           0   \n",
       "4  MR00101775      8  2019                           0   \n",
       "\n",
       "   monthly_unique_sessions  monthly_repeated_sessions  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   monthly_avg_length_of_session  monthly_avg_light_activity  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "\n",
       "   monthly_avg_moderate_activity  monthly_avg_vigorous_activity  ...  \\\n",
       "0                            0.0                            0.0  ...   \n",
       "1                            0.0                            0.0  ...   \n",
       "2                            0.0                            0.0  ...   \n",
       "3                            0.0                            0.0  ...   \n",
       "4                            0.0                            0.0  ...   \n",
       "\n",
       "   avg_wind_9_10  avg_wind_10_11  avg_wind_11_12  avg_wind_12_above  \\\n",
       "0            0.0             0.0             0.0                0.0   \n",
       "1            0.0             0.0             0.0                0.0   \n",
       "2            0.0             0.0             0.0                0.0   \n",
       "3            0.0             0.0             0.0                0.0   \n",
       "4            0.0             0.0             0.0                0.0   \n",
       "\n",
       "   perfect_days  unacast_session_count     hpi  \\\n",
       "0           0.0                   78.0  323.61   \n",
       "1           4.0                  111.0  323.61   \n",
       "2           2.0                  110.0  323.61   \n",
       "3           0.0                   10.0  110.38   \n",
       "4           0.0                   11.0  110.38   \n",
       "\n",
       "   state_and_local_amount_per_capita  state_amount_per_capita  \\\n",
       "0                           0.132207                 0.018519   \n",
       "1                           0.132207                 0.018519   \n",
       "2                           0.132207                 0.018519   \n",
       "3                           0.076247                 0.011966   \n",
       "4                           0.076247                 0.011966   \n",
       "\n",
       "   local_amount_per_capita  \n",
       "0                 0.113688  \n",
       "1                 0.113688  \n",
       "2                 0.113688  \n",
       "3                 0.064281  \n",
       "4                 0.064281  \n",
       "\n",
       "[5 rows x 861 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download the data\n",
    "df = pd.read_csv('../data/train_data.zip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_weather(input_data):\n",
    "    \"\"\"\n",
    "    Given the original dataframe, preprocess the columns\n",
    "    related to weather information (`Democrats_08_Votes` to\n",
    "    the end + `climate`). Impute NaN of `Number_of_holidays` \n",
    "    by using the values the we have for the same month,\n",
    "    impute NaN of `Green_2016` by using values found online, or 0, \n",
    "    and replace remaining NaN values with 0.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : pandas.core.frame.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output_data : pandas.core.frame.DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #drop the rows with NaNs in the 'unacast_session_count` column\n",
    "    input_data = input_data.dropna(subset=['unacast_session_count'])\n",
    "    \n",
    "    df_weather = input_data.loc[:, 'Democrats_08_Votes':]\n",
    "    df_weather['state'] = input_data['state']\n",
    "    df_weather['climate'] = input_data['climate']\n",
    "    df_weather['external_id'] = input_data['external_id']\n",
    "    df_weather['month'] = input_data['month']\n",
    "    df_weather['year'] = input_data['year']\n",
    "    \n",
    "    \n",
    "    #fill up NaNs for `Number_of_holidays` column\n",
    "    #I sorted the values so that the values are ordered by time, and the NaNs are at the end of each time period\n",
    "    df_weather = df_weather.sort_values(['month', 'year', 'Number_of_holidays'])\n",
    "    df_weather['Number_of_holidays'] = df_weather['Number_of_holidays'].fillna(method='ffill')\n",
    "    \n",
    "    #fill up NaNs for the `Green_2016` column\n",
    "    #I only found values for Alaska and North Carolina, so I just put 0 for the other states\n",
    "    df_weather['Green_2016'] = np.where(\n",
    "     df_weather['state'] == 'Alaska', 5735, \n",
    "         np.where(\n",
    "            df_weather['state'] == 'North Carolina', 12105,  \n",
    "             np.where(\n",
    "                df_weather['Green_2016'].isnull(), 0, df_weather['Green_2016'] \n",
    "             )\n",
    "         )\n",
    "    )\n",
    "    \n",
    "    #Substitute every remaining NaNs by 0\n",
    "    df_weather = df_weather.fillna(value=0)\n",
    "    \n",
    "    output_data = input_data.copy()\n",
    "    output_data.loc[:, 'Democrats_08_Votes':] = df_weather.loc[:, 'Democrats_08_Votes':]\n",
    "    output_data['climate'] = df_weather['climate']\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [page](https://en.wikipedia.org/wiki/2016_United_States_presidential_election_in_North_Carolina) is where I found the value for North Carolina, and [this](https://www.nytimes.com/elections/2016/results/alaska) is where I found the results for Alaska."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for the preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = preprocess_weather(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49503, 861)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that there are no missing values in the `Number_of_holidays` column\n",
    "clean_df['Number_of_holidays'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Check that every month has only one value for the `Number_of_holiday` column\n",
    "number_of_error = 0\n",
    "for month in range(12):\n",
    "    for year in [2018, 2019]:\n",
    "        df_jan_19 = clean_df[(clean_df['month'] == month+1) & (clean_df['year'] == year)]\n",
    "        if len(df_jan_19['Number_of_holidays'].unique()) > 1:\n",
    "            number_of_error += 1 \n",
    "print(number_of_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60    12105.0\n",
      "Name: Green_2016, dtype: float64\n",
      "3121    5735.0\n",
      "Name: Green_2016, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Check that the values in the `Green_2016` column for the states of North Carolina and Alaska are the right ones\n",
    "for state in ['North Carolina', 'Alaska']:\n",
    "    print(clean_df[clean_df['state'] == state]['Green_2016'].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state         Mississippi\n",
       "Green_2016       0.255869\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that the values that were not NaNs in the `Green_2016` column remained the same\n",
    "clean_df[['state', 'Green_2016']].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state         Mississippi\n",
       "Green_2016       0.255869\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['state', 'Green_2016']].iloc[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
