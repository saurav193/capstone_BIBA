{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download libraries\n",
    "import re\n",
    "#from collections import defaultdict\n",
    "import pandas as pd\n",
    "#import altair as alt\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.svm import SVR\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#from preprocessing import preprocessing_na, clean_categorical\n",
    "#import time\n",
    "from drop import drop_columns\n",
    "from PCA_data import *\n",
    "from imputer import *\n",
    "from drop import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>monthly_number_of_sessions</th>\n",
       "      <th>monthly_unique_sessions</th>\n",
       "      <th>monthly_repeated_sessions</th>\n",
       "      <th>monthly_avg_length_of_session</th>\n",
       "      <th>monthly_avg_light_activity</th>\n",
       "      <th>monthly_avg_moderate_activity</th>\n",
       "      <th>monthly_avg_vigorous_activity</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_wind_9_10</th>\n",
       "      <th>avg_wind_10_11</th>\n",
       "      <th>avg_wind_11_12</th>\n",
       "      <th>avg_wind_12_above</th>\n",
       "      <th>perfect_days</th>\n",
       "      <th>unacast_session_count</th>\n",
       "      <th>hpi</th>\n",
       "      <th>state_and_local_amount_per_capita</th>\n",
       "      <th>state_amount_per_capita</th>\n",
       "      <th>local_amount_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1804425</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>244.20</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1812706</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1812706</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1812706</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1812706</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>258.95</td>\n",
       "      <td>0.157475</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.147692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  external_id  month  year  monthly_number_of_sessions  \\\n",
       "0     1804425      8  2018                           0   \n",
       "1     1812706      2  2019                           0   \n",
       "2     1812706      3  2019                           0   \n",
       "3     1812706     11  2018                           0   \n",
       "4     1812706      9  2018                           0   \n",
       "\n",
       "   monthly_unique_sessions  monthly_repeated_sessions  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   monthly_avg_length_of_session  monthly_avg_light_activity  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "\n",
       "   monthly_avg_moderate_activity  monthly_avg_vigorous_activity  ...  \\\n",
       "0                            0.0                            0.0  ...   \n",
       "1                            0.0                            0.0  ...   \n",
       "2                            0.0                            0.0  ...   \n",
       "3                            0.0                            0.0  ...   \n",
       "4                            0.0                            0.0  ...   \n",
       "\n",
       "   avg_wind_9_10  avg_wind_10_11  avg_wind_11_12  avg_wind_12_above  \\\n",
       "0            0.0             0.0             0.0                0.0   \n",
       "1            0.0             0.0             0.0                0.0   \n",
       "2            0.0             0.0             0.0                0.0   \n",
       "3            0.0             0.0             0.0                0.0   \n",
       "4            0.0             0.0             0.0                0.0   \n",
       "\n",
       "   perfect_days  unacast_session_count     hpi  \\\n",
       "0           0.0                   90.0  244.20   \n",
       "1           4.0                   27.0  258.95   \n",
       "2           4.0                   27.0  258.95   \n",
       "3           3.0                   24.0  258.95   \n",
       "4           0.0                   12.0  258.95   \n",
       "\n",
       "   state_and_local_amount_per_capita  state_amount_per_capita  \\\n",
       "0                           0.157475                 0.009783   \n",
       "1                           0.157475                 0.009783   \n",
       "2                           0.157475                 0.009783   \n",
       "3                           0.157475                 0.009783   \n",
       "4                           0.157475                 0.009783   \n",
       "\n",
       "   local_amount_per_capita  \n",
       "0                 0.147692  \n",
       "1                 0.147692  \n",
       "2                 0.147692  \n",
       "3                 0.147692  \n",
       "4                 0.147692  \n",
       "\n",
       "[5 rows x 861 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download the data\n",
    "df = pd.read_csv('../data/train_data.zip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = create_imputer(df)\n",
    "df1, df2 = impute_data(df, df)\n",
    "clean_df = drop_columns(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_null = clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "monthly_weekday_counts          45322\n",
       "monthly_survey                  45322\n",
       "name                            48762\n",
       "total_events_across_state       48762\n",
       "positive_events_across_state    48762\n",
       "                                ...  \n",
       "historic_revisit                32260\n",
       "historic_safety                 30320\n",
       "historic_travel                 32640\n",
       "historic_variety                32940\n",
       "unacast_session_count             617\n",
       "Length: 66, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_null[is_null>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-41aebfc32310>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m  \u001b[1;34m'density_class'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m  \u001b[1;34m'climate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m  'county']), 0.95)\n\u001b[0m",
      "\u001b[1;32m~\\documents\\capstone_machine_learning\\src\\PCA_data.py\u001b[0m in \u001b[0;36mget_pca_trans_data\u001b[1;34m(input_df, var_per_rqd)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m#Run PCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mvar_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\capstone_machine_learning-ViU5C1zf\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \"\"\"\n\u001b[1;32m--> 351\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\capstone_machine_learning-ViU5C1zf\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         X = self._validate_data(X, dtype=[np.float64, np.float32],\n\u001b[1;32m--> 398\u001b[1;33m                                 ensure_2d=True, copy=self.copy)\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[1;31m# Handle n_components==None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\capstone_machine_learning-ViU5C1zf\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\capstone_machine_learning-ViU5C1zf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\capstone_machine_learning-ViU5C1zf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 646\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\capstone_machine_learning-ViU5C1zf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     (type_err,\n\u001b[1;32m--> 100\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m    101\u001b[0m             )\n\u001b[0;32m    102\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "imputer = create_imputer(df)\n",
    "df1, df2 = impute_data(df, df)\n",
    "clean_data = get_pca_trans_data(df1.drop(columns=['external_id','monthly_weekday_counts','monthly_survey',\n",
    " 'name',\n",
    " 'date',\n",
    " 'city',\n",
    " 'state',\n",
    " 'country',\n",
    " 'closest_place_category',\n",
    " 'income_class',\n",
    " 'density_class',\n",
    " 'climate',\n",
    " 'county']), 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50120, 861)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df1.loc[:, df1.dtypes == \"object\"]\n",
    "print(categorical_features.shape)\n",
    "data = df1.copy()\n",
    "numerical_data = data.drop(columns=list(categorical_features.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_bis = df1.infer_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50120 entries, 0 to 50119\n",
      "Columns: 861 entries, external_id to local_amount_per_capita\n",
      "dtypes: float64(421), int64(427), object(13)\n",
      "memory usage: 329.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df1_bis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50120 entries, 0 to 50119\n",
      "Columns: 861 entries, external_id to local_amount_per_capita\n",
      "dtypes: float64(393), int64(455), object(13)\n",
      "memory usage: 329.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['external_id',\n",
       " 'monthly_weekday_counts',\n",
       " 'monthly_survey',\n",
       " 'name',\n",
       " 'date',\n",
       " 'city',\n",
       " 'state',\n",
       " 'country',\n",
       " 'closest_place_category',\n",
       " 'income_class',\n",
       " 'density_class',\n",
       " 'climate',\n",
       " 'county']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.loc[:, df.dtypes == \"object\"].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am waiting for the preprocessing to be done to run this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(clean_data.drop(columns=['unacast_session_count', 'state', 'external_id']),\n",
    "                                                    clean_data[['unacast_session_count']],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit basic SVR with default values\n",
    "t0 = time.time()\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train.to_numpy().ravel())\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the train and validation score\n",
    "print(svr.score(X_train, y_train.to_numpy().ravel())\n",
    "svr.score(X_valid, y_valid.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t1 - t0)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svr.score(X_train, y_train.to_numpy().ravel()))\n",
    "#Took roughly 1h30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR takes a long time to run, and gave really poor results. We will keep it aside for now, and see latter if we want to use it or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I kept the following code for when we will have more computational power to run SVR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Kernel = â€˜linearâ€™\n",
    "t0 = time.time()\n",
    "parameters = {'C':np.logspace(-5,5,40), 'gamma':np.logspace(-10,10,40)}\n",
    "svr = SVR(kernel='linear')\n",
    "svr_opt = RandomizedSearchCV(svr, parameters, cv=5, iid=False, n_iter=100)\n",
    "svr_opt.fit(X_train, y_train.to_numpy().ravel())\n",
    "t1 = time.time()\n",
    "print('The best parameter combination is {}.'.format(svc_opt.best_params_))\n",
    "print('The accuracy on the test split is {:.2f}.'.format(svc_opt.score(X_test,y_test)))\n",
    "total = t1-t0\n",
    "print(total)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=100, learning_rate=1, depth=10, verbose=False)\n",
    "# Fit model\n",
    "t0 = time.time()\n",
    "model.fit(X_train, y_train.to_numpy().ravel())\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t1-t0)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get R2 score\n",
    "model.score(X_train, y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_valid, y_valid.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop categorical features\n",
    "categorical_features = X_train.loc[:, clean_data.dtypes == \"object\"]\n",
    "categorical_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(columns = list(categorical_features.columns)))\n",
    "X_valid_scaled = scaler.transform(X_valid.drop(columns = list(categorical_features.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=100, learning_rate=1, depth=10, verbose=False)\n",
    "# Fit model\n",
    "t0 = time.time()\n",
    "model.fit(X_train_scaled, y_train.to_numpy().ravel())\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t1-t0)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get R2 score\n",
    "model.score(X_train_scaled, y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_valid_scaled, y_valid.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log transformed response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = np.log(np.where(y_train==0, 1, y_train))\n",
    "y_valid_log = np.log(np.where(y_valid==0, 1, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=100, learning_rate=1, depth=10, verbose=False)\n",
    "# Fit model\n",
    "t0 = time.time()\n",
    "model.fit(X_train, y_train_log.ravel())\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t1-t0)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get R2 score\n",
    "model.score(X_train, y_train_log.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_valid, y_valid_log.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters tuning : Random search (Waiting for the EC2 to run the rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = CatBoostRegressor(verbose=False, loss_function='MAE')\n",
    "parameters = {'iterations':range(1,1000,100), 'learning_rate':np.logspace(-10,0,40), 'depth':range(1,100,10)}\n",
    "catboost_opt = RandomizedSearchCV(catboost, parameters, cv=5, iid=False, n_iter=5)\n",
    "catboost_opt.fit(X_train_scaled, y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best parameter combination is {}.'.format(catboost_opt.best_params_))\n",
    "print('The accuracy on the validation split is {:.2f}.'.format(catboost_opt.score(X_valid_scaled,y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log transformation of the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = CatBoostRegressor(verbose=False, loss_function='MAE')\n",
    "parameters = {'iterations':range(1,1000,100), 'learning_rate':np.logspace(-10,0,40), 'depth':range(1,100,10)}\n",
    "catboost_opt = RandomizedSearchCV(catboost, parameters, cv=5, iid=False, n_iter=5)\n",
    "catboost_opt.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best parameter combination is {}.'.format(catboost_opt.best_params_))\n",
    "print('The accuracy on the validation split is {:.2f}.'.format(catboost_opt.score(X_valid,y_valid_log)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log transformation of the response + Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = CatBoostRegressor(verbose=False, loss_function='MAE')\n",
    "parameters = {'iterations':range(1,1000,100), 'learning_rate':np.logspace(-10,0,40), 'depth':range(1,100,10)}\n",
    "catboost_opt = RandomizedSearchCV(catboost, parameters, cv=5, iid=False, n_iter=5)\n",
    "catboost_opt.fit(X_train_scaled, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best parameter combination is {}.'.format(catboost_opt.best_params_))\n",
    "print('The accuracy on the validation split is {:.2f}.'.format(catboost_opt.score(X_valid_scaled,y_valid_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_machine_learning",
   "language": "python",
   "name": "capstone_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
