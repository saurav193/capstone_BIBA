{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "|Model| Comments|\n",
    "|-----|---------|\n",
    "| Simple LR w/o scaling| Test $R^2$ = 4.1%|\n",
    "| Lasso w/o scaling| Test $R^2$ = 3.5%|\n",
    "| Ridge w/o scaling| Test $R^2$ = 3.7%|\n",
    "| ElasticNet w/o scaling| Test $R^2$ = 3.4%|\n",
    "| LR with Minmax(0,1) scaling| Test $R^2$ = 3.7%|\n",
    "| Lasso with Minmax(0,1) scaling| Test $R^2$ = 0.9%|\n",
    "| Ridge with Minmax(0,1) scaling| Test $R^2$ = 3.6%|\n",
    "| ElasticNet with Minmax(0,1) scaling| Test $R^2$ = 0.1%|\n",
    "| LR with Standard scaling| Test $R^2$ = 4.0%|\n",
    "| Lasso with Standard scaling| Test $R^2$ = 3.3%|\n",
    "| Ridge with Standard scaling| Test $R^2$ = 3.7%|\n",
    "| Lasso with Standard scaling and gridsearch| Test $R^2$ = 3.3%|\n",
    "| Ridge with Standard scaling and gridsearch| Test $R^2$ = 4.2%|\n",
    "| Random Forest with Standard scaling | Test $R^2$ = 28.5%|\n",
    "\n",
    "\n",
    "> Simple LR or Ridge regression is best without feature selection or any data imputation\n",
    "> PCA will have reduced the number of columns from 260 to 190 with 99% variance.\n",
    "> Random forest works better than others and can be improved with gridsearch but will take lot of time to train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train_data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>monthly_number_of_sessions</th>\n",
       "      <th>monthly_unique_sessions</th>\n",
       "      <th>monthly_repeated_sessions</th>\n",
       "      <th>monthly_avg_length_of_session</th>\n",
       "      <th>monthly_avg_light_activity</th>\n",
       "      <th>monthly_avg_moderate_activity</th>\n",
       "      <th>monthly_avg_vigorous_activity</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_wind_9_10</th>\n",
       "      <th>avg_wind_10_11</th>\n",
       "      <th>avg_wind_11_12</th>\n",
       "      <th>avg_wind_12_above</th>\n",
       "      <th>perfect_days</th>\n",
       "      <th>unacast_session_count</th>\n",
       "      <th>hpi</th>\n",
       "      <th>state_and_local_amount_per_capita</th>\n",
       "      <th>state_amount_per_capita</th>\n",
       "      <th>local_amount_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900203</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>323.61</td>\n",
       "      <td>0.132207</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.113688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900203</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>323.61</td>\n",
       "      <td>0.132207</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.113688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900203</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>323.61</td>\n",
       "      <td>0.132207</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.113688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR00101775</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.38</td>\n",
       "      <td>0.076247</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.064281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MR00101775</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>110.38</td>\n",
       "      <td>0.076247</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.064281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  external_id  month  year  monthly_number_of_sessions  \\\n",
       "0     1900203      3  2019                           0   \n",
       "1     1900203      6  2018                           0   \n",
       "2     1900203      8  2018                           0   \n",
       "3  MR00101775      1  2019                           0   \n",
       "4  MR00101775      8  2019                           0   \n",
       "\n",
       "   monthly_unique_sessions  monthly_repeated_sessions  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   monthly_avg_length_of_session  monthly_avg_light_activity  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "\n",
       "   monthly_avg_moderate_activity  monthly_avg_vigorous_activity  ...  \\\n",
       "0                            0.0                            0.0  ...   \n",
       "1                            0.0                            0.0  ...   \n",
       "2                            0.0                            0.0  ...   \n",
       "3                            0.0                            0.0  ...   \n",
       "4                            0.0                            0.0  ...   \n",
       "\n",
       "   avg_wind_9_10  avg_wind_10_11  avg_wind_11_12  avg_wind_12_above  \\\n",
       "0            0.0             0.0             0.0                0.0   \n",
       "1            0.0             0.0             0.0                0.0   \n",
       "2            0.0             0.0             0.0                0.0   \n",
       "3            0.0             0.0             0.0                0.0   \n",
       "4            0.0             0.0             0.0                0.0   \n",
       "\n",
       "   perfect_days  unacast_session_count     hpi  \\\n",
       "0           0.0                   78.0  323.61   \n",
       "1           4.0                  111.0  323.61   \n",
       "2           2.0                  110.0  323.61   \n",
       "3           0.0                   10.0  110.38   \n",
       "4           0.0                   11.0  110.38   \n",
       "\n",
       "   state_and_local_amount_per_capita  state_amount_per_capita  \\\n",
       "0                           0.132207                 0.018519   \n",
       "1                           0.132207                 0.018519   \n",
       "2                           0.132207                 0.018519   \n",
       "3                           0.076247                 0.011966   \n",
       "4                           0.076247                 0.011966   \n",
       "\n",
       "   local_amount_per_capita  \n",
       "0                 0.113688  \n",
       "1                 0.113688  \n",
       "2                 0.113688  \n",
       "3                 0.064281  \n",
       "4                 0.064281  \n",
       "\n",
       "[5 rows x 861 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for pre-processing biba data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def dict_to_columns_df(col, key, val):\n",
    "    \"\"\"\n",
    "    This functions takes a dataframe column which is in the\n",
    "    form of list of dictionaries and creates a dataframe\n",
    "    from the keys of the in the inner list of dictionaries \n",
    "    e.g. \"[{'key': A, 'val': 1}, {'key': B, 'val': 2}]\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    col : DataFrame Series, the columns whose values are the in the format\n",
    "    of a list of dictionaries.\n",
    "    \n",
    "    key : the keys in the inner dictionary from which column names are to be extracted\n",
    "    \n",
    "    val : the keys in the inner dictionary from which values in the column needs to\n",
    "    be extracted\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------------\n",
    "    DataFrame\n",
    "        With the new columns created from the keys of the inner dictionary\n",
    "        \n",
    "    \"\"\"\n",
    "    key_list = set()\n",
    "    i=0\n",
    "    # getting all the new column names\n",
    "    while i < len(col):\n",
    "        if type(col[i]) != float:\n",
    "            dic_list = eval(col[i]) #converting col value from string to list\n",
    "            for dic in range(len(dic_list)):\n",
    "                if re.match('[a-zA-Z]', dic_list[dic][str(key)][0]): #removing spanish names\n",
    "                    key_list.add(\"monthly_\"+dic_list[dic][str(key)])\n",
    "        i+=1\n",
    "    \n",
    "    all_cols_dict = defaultdict(list)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(col):\n",
    "        if type(col[i]) != float:\n",
    "            dic_list = eval(col[i]) #converting col value from string to list\n",
    "\n",
    "            for col_names in list(key_list):\n",
    "                flag = 0 #to check if a column name exists in the dictionary\n",
    "                for dic in range(len(dic_list)):\n",
    "                    if dic_list[dic][str(key)] == col_names[8:]: #getting values from the inner dictionary matching the key\n",
    "                        all_cols_dict[col_names].append(dic_list[dic][str(val)]) #putting inner dict values to new default dict\n",
    "                        flag = 1\n",
    "                        break\n",
    "                \n",
    "                if flag==0:\n",
    "                    all_cols_dict[col_names].append(None)\n",
    "\n",
    "        else:\n",
    "            for col_names in list(key_list):\n",
    "                all_cols_dict[col_names].append(None)\n",
    "\n",
    "        i+=1\n",
    "    new_cols_df = pd.DataFrame(all_cols_dict)\n",
    "    \n",
    "    # checking new df has same number of columns as given column\n",
    "    if new_cols_df.shape[0] == col.shape[0]:\n",
    "        return new_cols_df\n",
    "    else:\n",
    "        print(\"Column dimensions don't match\")\n",
    "\n",
    "\n",
    "def biba_pp(full_data):  \n",
    "    \n",
    "    \"\"\"\n",
    "    Performs the pre-processing of the columns for the biba data\n",
    "    \n",
    "    Paramters\n",
    "    ---------------\n",
    "    \n",
    "    full_data : DataFrame, with no operations done on the biba columns\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    DataFrame\n",
    "        with processed biba columns\n",
    "    \n",
    "    \"\"\"\n",
    "    biba_games_df = pd.DataFrame()\n",
    "    biba_games_df = pd.concat([full_data.loc[:, 'monthly_number_of_sessions':'distance_to_nearest_bus_stop'],\n",
    "                               full_data.loc[:, 'historic_number_of_sessions':'historic_snow']], axis = 1)\n",
    "    \n",
    "    #extracting categorical features\n",
    "    categorical_features = biba_games_df.loc[:, biba_games_df.dtypes == \"object\"]\n",
    "     \n",
    "    # creating cols from list of dictionaries\n",
    "    monthly_survey_df = dict_to_columns_df(categorical_features['monthly_survey'], 'question', 'avg_answer')\n",
    "    monthly_weekday_counts_df = dict_to_columns_df(categorical_features['monthly_weekday_counts'], 'weekday', 'count')\n",
    "    \n",
    "    biba_games_df = pd.concat([biba_games_df, monthly_survey_df, monthly_weekday_counts_df], axis = 1)\n",
    "    \n",
    "    #dropping categorical features\n",
    "    biba_games_df = biba_games_df.drop(columns = list(categorical_features.columns))\n",
    "    \n",
    "    #dropping historic hours with low fill rate\n",
    "    numerical_cols_to_remove = ['historic_hour_0', 'historic_hour_23', 'historic_hour_22', 'historic_hour_21',\n",
    "                                'historic_hour_7','historic_hour_6','historic_hour_5','historic_hour_4', \n",
    "                                'historic_hour_3','historic_hour_2','historic_hour_1', 'MonthYear']\n",
    "    \n",
    "    biba_games_df = biba_games_df.drop(columns = numerical_cols_to_remove)\n",
    "    \n",
    "    impute_biba_games_df =  biba_games_df.fillna(0)\n",
    "    \n",
    "    #removing the previous columns in the input data\n",
    "    cols_to_drop = list(df.loc[:, 'monthly_number_of_sessions': 'distance_to_nearest_bus_stop'].columns) +\\\n",
    "                    list(df.loc[:, 'historic_number_of_sessions' : 'historic_snow'].columns)\n",
    "    \n",
    "    \n",
    "    full_data = full_data.drop(columns = cols_to_drop)\n",
    "    \n",
    "    #adding processed columns\n",
    "    full_data = pd.concat([full_data, impute_biba_games_df], axis = 1)\n",
    "    \n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_weather(input_data):\n",
    "    \"\"\"\n",
    "    Given the original dataframe, preprocess the columns\n",
    "    related to weather information (`Democrats_08_Votes` to\n",
    "    the end + `climate`). Impute NaN of `Number_of_holidays`\n",
    "    by using the values the we have for the same month,\n",
    "    impute NaN of `Green_2016` by using values found online, or 0,\n",
    "    and replace remaining NaN values with 0.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : pandas.core.frame.DataFrame\n",
    "    Returns\n",
    "    -------\n",
    "    output_data : pandas.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "    df_weather = input_data.loc[:, 'Democrats_08_Votes':]\n",
    "    df_weather['state'] = input_data['state']\n",
    "    df_weather['climate'] = input_data['climate']\n",
    "    df_weather['external_id'] = input_data['external_id']\n",
    "    df_weather['month'] = input_data['month']\n",
    "    df_weather['year'] = input_data['year']\n",
    "    #fill up NaNs for `Number_of_holidays` column\n",
    "    #I sorted the values so that the values are ordered by time, and the NaNs are at the end of each time period\n",
    "    df_weather = df_weather.sort_values(['month', 'year', 'Number_of_holidays'])\n",
    "    df_weather['Number_of_holidays'] = df_weather['Number_of_holidays'].fillna(method='ffill')\n",
    "    #fill up NaNs for the `Green_2016` column\n",
    "    #I only found values for Alaska and North Carolina, so I just put 0 for the other states\n",
    "    df_weather['Green_2016'] = np.where(\n",
    "     df_weather['state'] == 'Alaska', 5735,\n",
    "         np.where(\n",
    "            df_weather['state'] == 'North Carolina', 12105,\n",
    "             np.where(\n",
    "                df_weather['Green_2016'].isnull(), 0, df_weather['Green_2016']\n",
    "             )\n",
    "         )\n",
    "    )\n",
    "    df_weather['climate'] = df_weather['climate'].fillna(df_weather['climate'].mode()[0])\n",
    "    #Substitute every remaining NaNs by 0\n",
    "    df_weather = df_weather.fillna(value=0)\n",
    "    output_data = input_data.copy()\n",
    "    output_data.loc[:, 'Democrats_08_Votes':] = df_weather.loc[:, 'Democrats_08_Votes':]\n",
    "    output_data['climate'] = df_weather['climate']\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_neighbour(input_data):\n",
    "    \"\"\"\n",
    "    Given the original dataframe, preprocess the columns\n",
    "    related to locale information (`city` to\n",
    "    `houses_per_sq_km`). Drop columns with >30%\n",
    "    NaN values and replace remaining NaN values with 0.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : pandas.core.frame.DataFrame\n",
    "    Returns\n",
    "    -------\n",
    "    output_data : pandas.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "    df_neighbour = input_data.loc[:, 'city':'houses_per_sq_km']\n",
    "    missing = df_neighbour.isna()\n",
    "    # Count number of missing values for each column\n",
    "    num_missing = missing.sum().sort_values(ascending=False)\n",
    "    # Calculate proportion of missing values for each column\n",
    "    prop_missing = num_missing / df.shape[0]\n",
    "    # Create a list of columns with >30% of values missing\n",
    "    to_drop = prop_missing[prop_missing > 0.3].index.to_list()\n",
    "    # Add `country` to the list since all playgrounds are in the U.S.\n",
    "    # Add `city` and `county` since lat. and long. should take care of them\n",
    "    to_drop.append('country')\n",
    "    to_drop.append('city')\n",
    "    to_drop.append('county')\n",
    "    # Drop columns with names in list\n",
    "    output_data = input_data.drop(to_drop, axis=1)\n",
    "    # Fill in remaining NaN values in locale-related columns with 0\n",
    "    to_impute = prop_missing[(0 < prop_missing) & (prop_missing <= 0.3)].index.to_list()\n",
    "    to_impute.remove('city')\n",
    "    to_impute.remove('county')\n",
    "    to_impute.remove('climate')\n",
    "    output_data[to_impute] = output_data[to_impute].fillna(0)\n",
    "    #output_data.loc[:, to_impute] = output_data.loc[:, to_impute].fillna(0)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_df1 = biba_pp(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df2 = preprocess_weather(clean_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c32f48088578>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclean_df3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_neighbour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_df2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-6f993b434f4a>\u001b[0m in \u001b[0;36mpreprocess_neighbour\u001b[1;34m(input_data)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mto_impute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'city'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mto_impute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'county'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mto_impute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'climate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0moutput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_impute\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_impute\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m#output_data.loc[:, to_impute] = output_data.loc[:, to_impute].fillna(0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "clean_df3 = preprocess_neighbour(clean_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>B20004e10</th>\n",
       "      <th>B11016e1</th>\n",
       "      <th>B12001e12</th>\n",
       "      <th>B20004e11</th>\n",
       "      <th>B19125e1</th>\n",
       "      <th>B12001e13</th>\n",
       "      <th>B23008e22</th>\n",
       "      <th>...</th>\n",
       "      <th>monthly_Wednesday</th>\n",
       "      <th>monthly_Sunday</th>\n",
       "      <th>monthly_Monday</th>\n",
       "      <th>monthly_Thursday</th>\n",
       "      <th>monthly_Friday</th>\n",
       "      <th>monthly_Saturday</th>\n",
       "      <th>monthly_Tuesday</th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900203</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>51111</td>\n",
       "      <td>1868</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>78934</td>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900203</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>51111</td>\n",
       "      <td>1868</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>78934</td>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900203</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>51111</td>\n",
       "      <td>1868</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>78934</td>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR00101775</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>45484</td>\n",
       "      <td>2613</td>\n",
       "      <td>980</td>\n",
       "      <td>30417</td>\n",
       "      <td>45578</td>\n",
       "      <td>1097</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MR00101775</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "      <td>45484</td>\n",
       "      <td>2613</td>\n",
       "      <td>980</td>\n",
       "      <td>30417</td>\n",
       "      <td>45578</td>\n",
       "      <td>1097</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50115</th>\n",
       "      <td>MR00101116</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>84079</td>\n",
       "      <td>2295</td>\n",
       "      <td>361</td>\n",
       "      <td>135721</td>\n",
       "      <td>145595</td>\n",
       "      <td>1965</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50116</th>\n",
       "      <td>FM00171280</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>37473</td>\n",
       "      <td>2460</td>\n",
       "      <td>1097</td>\n",
       "      <td>20307</td>\n",
       "      <td>46094</td>\n",
       "      <td>1052</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50117</th>\n",
       "      <td>FM00167991</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>48462</td>\n",
       "      <td>2005</td>\n",
       "      <td>772</td>\n",
       "      <td>62037</td>\n",
       "      <td>93603</td>\n",
       "      <td>1443</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50118</th>\n",
       "      <td>MR00098241</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>40571</td>\n",
       "      <td>2104</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>36340</td>\n",
       "      <td>834</td>\n",
       "      <td>308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50119</th>\n",
       "      <td>MR00098241</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "      <td>40571</td>\n",
       "      <td>2104</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>36340</td>\n",
       "      <td>834</td>\n",
       "      <td>308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50120 rows × 819 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      external_id  month  year  B20004e10  B11016e1  B12001e12  B20004e11  \\\n",
       "0         1900203      3  2019      51111      1868        688          0   \n",
       "1         1900203      6  2018      51111      1868        688          0   \n",
       "2         1900203      8  2018      51111      1868        688          0   \n",
       "3      MR00101775      1  2019      45484      2613        980      30417   \n",
       "4      MR00101775      8  2019      45484      2613        980      30417   \n",
       "...           ...    ...   ...        ...       ...        ...        ...   \n",
       "50115  MR00101116      4  2019      84079      2295        361     135721   \n",
       "50116  FM00171280      2  2018      37473      2460       1097      20307   \n",
       "50117  FM00167991      7  2018      48462      2005        772      62037   \n",
       "50118  MR00098241      6  2019      40571      2104        700          0   \n",
       "50119  MR00098241      9  2019      40571      2104        700          0   \n",
       "\n",
       "       B19125e1  B12001e13  B23008e22  ...  monthly_Wednesday  monthly_Sunday  \\\n",
       "0         78934       1342          0  ...                0.0             0.0   \n",
       "1         78934       1342          0  ...                0.0             0.0   \n",
       "2         78934       1342          0  ...                0.0             0.0   \n",
       "3         45578       1097         66  ...                0.0             0.0   \n",
       "4         45578       1097         66  ...                0.0             0.0   \n",
       "...         ...        ...        ...  ...                ...             ...   \n",
       "50115    145595       1965          7  ...                0.0             0.0   \n",
       "50116     46094       1052         65  ...                0.0             0.0   \n",
       "50117     93603       1443         42  ...                0.0             0.0   \n",
       "50118     36340        834        308  ...                0.0             0.0   \n",
       "50119     36340        834        308  ...                0.0             0.0   \n",
       "\n",
       "       monthly_Monday  monthly_Thursday  monthly_Friday  monthly_Saturday  \\\n",
       "0                 0.0               0.0             0.0               0.0   \n",
       "1                 0.0               0.0             0.0               0.0   \n",
       "2                 0.0               0.0             0.0               0.0   \n",
       "3                 0.0               0.0             0.0               0.0   \n",
       "4                 0.0               0.0             0.0               0.0   \n",
       "...               ...               ...             ...               ...   \n",
       "50115             0.0               0.0             0.0               0.0   \n",
       "50116             0.0               0.0             0.0               0.0   \n",
       "50117             0.0               0.0             0.0               0.0   \n",
       "50118             0.0               0.0             0.0               0.0   \n",
       "50119             0.0               0.0             0.0               0.0   \n",
       "\n",
       "       monthly_Tuesday  A  C  D  \n",
       "0                  0.0  0  1  0  \n",
       "1                  0.0  0  1  0  \n",
       "2                  0.0  0  1  0  \n",
       "3                  0.0  0  1  0  \n",
       "4                  0.0  0  1  0  \n",
       "...                ... .. .. ..  \n",
       "50115              0.0  0  1  0  \n",
       "50116              0.0  1  0  0  \n",
       "50117              0.0  0  1  0  \n",
       "50118              0.0  0  1  0  \n",
       "50119              0.0  0  1  0  \n",
       "\n",
       "[50120 rows x 819 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19       [{'question': 'allages', 'avg_answer': 5.0}, {...\n",
       "34       [{'question': 'variety', 'avg_answer': 3.0}, {...\n",
       "35       [{'question': 'condition', 'avg_answer': 3.0},...\n",
       "69       [{'question': 'accessible', 'avg_answer': 3.5}...\n",
       "70       [{'question': 'cleanliness', 'avg_answer': 4.0...\n",
       "                               ...                        \n",
       "50057    [{'question': 'variety', 'avg_answer': 5.0}, {...\n",
       "50058    [{'question': 'regular', 'avg_answer': 0.5}, {...\n",
       "50083    [{'question': 'accessible', 'avg_answer': 5.0}...\n",
       "50100    [{'question': 'revisit', 'avg_answer': 1.0}, {...\n",
       "50114    [{'question': 'safety', 'avg_answer': 0.0}, {'...\n",
       "Name: monthly_survey, Length: 4798, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treating categorical features\n",
    "categorical_features = biba_games_df.loc[:, biba_games_df.dtypes == \"object\"]\n",
    "categorical_features.loc[categorical_features['monthly_weekday_counts'].notnull(), 'monthly_weekday_counts']\n",
    "categorical_features.loc[categorical_features['monthly_survey'].notnull(), 'monthly_survey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weekday': 'Sunday', 'count': 1},\n",
       " {'weekday': 'Monday', 'count': 8},\n",
       " {'weekday': 'Thursday', 'count': 1},\n",
       " {'weekday': 'Saturday', 'count': 1}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(categorical_features.loc[69, 'monthly_weekday_counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_survey_df = dict_to_columns_df(categorical_features['monthly_survey'], 'question', 'avg_answer')\n",
    "monthly_weekday_counts_df = dict_to_columns_df(categorical_features['monthly_weekday_counts'], 'weekday', 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monthly_Thursday</th>\n",
       "      <th>monthly_Saturday</th>\n",
       "      <th>monthly_Monday</th>\n",
       "      <th>monthly_Tuesday</th>\n",
       "      <th>monthly_Friday</th>\n",
       "      <th>monthly_Wednesday</th>\n",
       "      <th>monthly_Sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49937</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49969</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50027</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50045</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50058</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2115 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       monthly_Thursday  monthly_Saturday  monthly_Monday  monthly_Tuesday  \\\n",
       "19                  2.0               6.0             3.0              2.0   \n",
       "35                  NaN               2.0             1.0              NaN   \n",
       "69                  1.0               1.0             8.0              NaN   \n",
       "70                  NaN               2.0             1.0              4.0   \n",
       "128                 NaN               NaN             1.0              NaN   \n",
       "...                 ...               ...             ...              ...   \n",
       "49937               NaN               4.0             2.0              NaN   \n",
       "49969               2.0               2.0             1.0              NaN   \n",
       "50027               NaN               2.0             1.0              NaN   \n",
       "50045               1.0               NaN             1.0              NaN   \n",
       "50058               2.0               NaN             1.0              1.0   \n",
       "\n",
       "       monthly_Friday  monthly_Wednesday  monthly_Sunday  \n",
       "19                NaN                1.0             1.0  \n",
       "35                NaN                NaN             NaN  \n",
       "69                NaN                NaN             1.0  \n",
       "70                NaN                5.0             3.0  \n",
       "128               NaN                NaN             NaN  \n",
       "...               ...                ...             ...  \n",
       "49937             1.0                NaN             NaN  \n",
       "49969             4.0                3.0             2.0  \n",
       "50027             NaN                NaN             NaN  \n",
       "50045             2.0                2.0             1.0  \n",
       "50058             3.0                NaN             3.0  \n",
       "\n",
       "[2115 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_weekday_counts_df[monthly_weekday_counts_df['monthly_Monday'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the new columns to whole dataframe\n",
    "\n",
    "biba_games_df = pd.concat([biba_games_df, monthly_survey_df, monthly_weekday_counts_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>monthly_number_of_sessions</th>\n",
       "      <th>monthly_unique_sessions</th>\n",
       "      <th>monthly_repeated_sessions</th>\n",
       "      <th>monthly_avg_length_of_session</th>\n",
       "      <th>monthly_avg_light_activity</th>\n",
       "      <th>monthly_avg_moderate_activity</th>\n",
       "      <th>monthly_avg_vigorous_activity</th>\n",
       "      <th>monthly_count_slide_single</th>\n",
       "      <th>...</th>\n",
       "      <th>monthly_cleanliness</th>\n",
       "      <th>monthly_regular</th>\n",
       "      <th>monthly_condition</th>\n",
       "      <th>monthly_Thursday</th>\n",
       "      <th>monthly_Saturday</th>\n",
       "      <th>monthly_Monday</th>\n",
       "      <th>monthly_Tuesday</th>\n",
       "      <th>monthly_Friday</th>\n",
       "      <th>monthly_Wednesday</th>\n",
       "      <th>monthly_Sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  year  monthly_number_of_sessions  monthly_unique_sessions  \\\n",
       "0      3  2019                           0                        0   \n",
       "1      6  2018                           0                        0   \n",
       "2      8  2018                           0                        0   \n",
       "3      1  2019                           0                        0   \n",
       "4      8  2019                           0                        0   \n",
       "\n",
       "   monthly_repeated_sessions  monthly_avg_length_of_session  \\\n",
       "0                          0                            0.0   \n",
       "1                          0                            0.0   \n",
       "2                          0                            0.0   \n",
       "3                          0                            0.0   \n",
       "4                          0                            0.0   \n",
       "\n",
       "   monthly_avg_light_activity  monthly_avg_moderate_activity  \\\n",
       "0                         0.0                            0.0   \n",
       "1                         0.0                            0.0   \n",
       "2                         0.0                            0.0   \n",
       "3                         0.0                            0.0   \n",
       "4                         0.0                            0.0   \n",
       "\n",
       "   monthly_avg_vigorous_activity  monthly_count_slide_single  ...  \\\n",
       "0                            0.0                           0  ...   \n",
       "1                            0.0                           0  ...   \n",
       "2                            0.0                           0  ...   \n",
       "3                            0.0                           0  ...   \n",
       "4                            0.0                           0  ...   \n",
       "\n",
       "   monthly_cleanliness  monthly_regular  monthly_condition  monthly_Thursday  \\\n",
       "0                  NaN              NaN                NaN               NaN   \n",
       "1                  NaN              NaN                NaN               NaN   \n",
       "2                  NaN              NaN                NaN               NaN   \n",
       "3                  NaN              NaN                NaN               NaN   \n",
       "4                  NaN              NaN                NaN               NaN   \n",
       "\n",
       "   monthly_Saturday  monthly_Monday  monthly_Tuesday  monthly_Friday  \\\n",
       "0               NaN             NaN              NaN             NaN   \n",
       "1               NaN             NaN              NaN             NaN   \n",
       "2               NaN             NaN              NaN             NaN   \n",
       "3               NaN             NaN              NaN             NaN   \n",
       "4               NaN             NaN              NaN             NaN   \n",
       "\n",
       "   monthly_Wednesday  monthly_Sunday  \n",
       "0                NaN             NaN  \n",
       "1                NaN             NaN  \n",
       "2                NaN             NaN  \n",
       "3                NaN             NaN  \n",
       "4                NaN             NaN  \n",
       "\n",
       "[5 rows x 264 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the original catergorical columns with dictionaries\n",
    "biba_games_df = biba_games_df.drop(columns = list(categorical_features.columns))\n",
    "biba_games_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scores(model, X, y, show = True):\n",
    "    \"\"\"\n",
    "    Shows classification and regression scores\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: The sklearn model\n",
    "    X: numpy.ndarray        \n",
    "        The X part of the data\n",
    "    y: numpy.ndarray\n",
    "        The y part of the data\n",
    "    Returns\n",
    "    -------\n",
    "        rmse: (float)\n",
    "        r2: (float)\n",
    "            \n",
    "    \"\"\"        \n",
    "        \n",
    "    y_preds = model.predict(X)                 \n",
    "    rmse = mean_squared_error(y, y_preds, squared=False)\n",
    "    r2 = r2_score(y, y_preds)\n",
    "    if show: \n",
    "        print(\"Root mean squared error: %0.3f and r^2 score: %0.3f\" % (rmse,r2))\n",
    "    return rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50120, 264)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_biba_games_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with all biba variables without any changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = impute_biba_games_df.drop(columns = ['target'])\n",
    "y = impute_biba_games_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple linear regression scores: \n",
      "Train error: \n",
      "Root mean squared error: 455.458 and r^2 score: 0.090\n",
      "Test error: \n",
      "Root mean squared error: 699.593 and r^2 score: 0.041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(699.5930797124148, 0.04053007326469338)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('Simple linear regression scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(lr, X_train, y_train)\n",
    "\n",
    "print('Test error: ')    \n",
    "show_scores(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations \n",
    "\n",
    "- Very poor model with $R^2 = 4.1 \\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple linear regression scores: \n",
      "Train error: \n",
      "Root mean squared error: 483.367 and r^2 score: -0.024\n",
      "Test error: \n",
      "Root mean squared error: 719.283 and r^2 score: -0.014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(719.2832836305175, -0.01423896628865462)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "print('Simple linear regression scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(svr, X_train, y_train)\n",
    "\n",
    "print('Test error: ')    \n",
    "show_scores(svr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- Very long train runtime. Not feasible on whole dataset\n",
    "- Very Poor model with negative $R^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lasso L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression scores: \n",
      "Train error: \n",
      "Root mean squared error: 458.633 and r^2 score: 0.078\n",
      "Test error: \n",
      "Root mean squared error: 701.577 and r^2 score: 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4251858555.791079, tolerance: 914430.1085296788\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(701.5773181102657, 0.03507971362012974)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_lr = Lasso(max_iter = 2000, random_state = 2020)\n",
    "lasso_lr.fit(X_train, y_train)\n",
    "print('Lasso regression scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(lasso_lr, X_train, y_train)\n",
    "\n",
    "print('Test error: ')\n",
    "show_scores(lasso_lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- Same performance as simple LR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ridge L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression scores: \n",
      "Train error: \n",
      "Root mean squared error: 455.481 and r^2 score: 0.090\n",
      "Test error: \n",
      "Root mean squared error: 699.447 and r^2 score: 0.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.70787e-20): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(699.4472076641025, 0.04093014941199169)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_lr = Ridge(max_iter=2000, random_state = 2020)\n",
    "ridge_lr.fit(X_train, y_train)\n",
    "print('Ridge regression scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(ridge_lr, X_train, y_train)\n",
    "\n",
    "print('Test error: ')    \n",
    "show_scores(ridge_lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- Same performance as Simple LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ElasticNet L1 and L2 Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic regression scores: \n",
      "Train error: \n",
      "Root mean squared error: 460.542 and r^2 score: 0.070\n",
      "Test error: \n",
      "Root mean squared error: 702.101 and r^2 score: 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4278359258.551601, tolerance: 914430.1085296788\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(702.100988553132, 0.03363870689591786)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_lr = ElasticNet(max_iter= 2000, random_state = 2020)\n",
    "elastic_lr.fit(X_train, y_train)\n",
    "print('Elastic regression scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(elastic_lr, X_train, y_train)\n",
    "\n",
    "print('Test error: ')    \n",
    "show_scores(elastic_lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- Same performance as Simple LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Scaling all columns with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler((0,1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- Simple LR - slight improvement from last case\n",
    "- Lasso performs worse than previous case\n",
    "- Ridge performs same as w/o scaling\n",
    "- Elastic net performs worse than all models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Scaling all columns with Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- All model performs worse than the minmax scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Scaling all columns with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- Standard Scaler works best for all models among other scalers\n",
    "- Moving on to grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple linear regression scores: \n",
      "Train error: \n",
      "Root mean squared error: 455.465 and r^2 score: 0.090\n",
      "Test error: \n",
      "Root mean squared error: 699.617 and r^2 score: 0.040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(699.6173545864126, 0.04046348765561891)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "print('Simple linear regression scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(lr, X_train_scaled, y_train)\n",
    "\n",
    "print('Test error: ')    \n",
    "show_scores(lr, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha' : [0.001, 0.1, 1, 10, 100]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression scores: \n",
      "Train error: \n",
      "Root mean squared error: 455.757 and r^2 score: 0.089\n",
      "Test error: \n",
      "Root mean squared error: 699.204 and r^2 score: 0.042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(699.2038649219163, 0.04159736800138891)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_lr = Ridge(max_iter=2000, random_state = 2020)\n",
    "\n",
    "clf_ridge = GridSearchCV(ridge_lr, params, cv =5)\n",
    "\n",
    "clf_ridge.fit(X_train_scaled, y_train)\n",
    "print('Ridge regression scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(clf_ridge, X_train_scaled, y_train)\n",
    "\n",
    "print('Test error: ')\n",
    "show_scores(clf_ridge, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 100}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ridge.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA().fit(X_scaled)\n",
    "| Ridge with Standard scaling and gridsearch| Test $R^2$ = 4.2%|\n",
    " = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of principal components to get 99% variance =  190\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pca.explained_variance_ratio_)):\n",
    "    if np.sum(pca.explained_variance_ratio_[0:i]) >=0.99:\n",
    "        print(\"Number of principal components to get 99% variance = \", i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of principal components to get 95% variance =  135\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pca.explained_variance_ratio_)):\n",
    "    if np.sum(pca.explained_variance_ratio_[0:i]) >=0.95:\n",
    "        print(\"Number of principal components to get 95% variance = \", i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- PCA will not help in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Random Forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression scores: \n",
      "Train error: \n",
      "Root mean squared error: 139.954 and r^2 score: 0.914\n",
      "Test error: \n",
      "Root mean squared error: 615.272 and r^2 score: 0.258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(615.2720957918488, 0.257878872860947)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_depth' : [10, 100, 1000], 'n_estimators' : [100, 1000]}\n",
    "rf = RandomForestRegressor(max_depth = 30, random_state = 2020)\n",
    "\n",
    "# clf_rf = GridSearchCV(rf, params, cv =4)\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "print('Ridge regression scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(rf, X_train_scaled, y_train)\n",
    "\n",
    "print('Test error: ')\n",
    "show_scores(rf, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF with PCA columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_99_per_var = Z[:, 0:190]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Z_99_per_var, y, test_size = 0.2, random_state = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression scores: \n",
      "Train error: \n",
      "Root mean squared error: 155.343 and r^2 score: 0.894\n",
      "Test error: \n",
      "Root mean squared error: 681.761 and r^2 score: 0.089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(681.7608337063552, 0.08881942403011678)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(max_depth = 50, random_state = 2020)\n",
    "\n",
    "# clf_rf = GridSearchCV(rf, params, cv =4)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print('Ridge regression scores: ')\n",
    "print('Train error: ')\n",
    "show_scores(rf, X_train, y_train)\n",
    "\n",
    "print('Test error: ')\n",
    "show_scores(rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
